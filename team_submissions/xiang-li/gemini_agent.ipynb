{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30eaf2eb-551d-4e19-9833-e1f2496528f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def init_pipeline(symbol, api_key=None):\n",
    "    \"\"\"api_key parameter kept for compatibility but not used\"\"\"\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    return ticker, symbol\n",
    "\n",
    "# No API key needed for Yahoo Finance\n",
    "fd, symbol = init_pipeline(\"GOOG\")\n",
    "\n",
    "# Get financial statements (annual by default, use period=\"quarterly\" for quarterly)\n",
    "is_df = fd.financials.T  # Income statement\n",
    "bs_df = fd.balance_sheet.T  # Balance sheet\n",
    "cf_df = fd.cashflow.T  # Cash flow\n",
    "\n",
    "def clean_and_trim_5y(df):\n",
    "    \"\"\"\n",
    "    Clean Yahoo Finance financial statements\n",
    "    and keep the most recent 5 years.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_index().tail(5)  # Yahoo Finance uses datetime index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={df.columns[0]: \"fiscalDateEnding\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply cleaning\n",
    "is_df = clean_and_trim_5y(is_df)\n",
    "bs_df = clean_and_trim_5y(bs_df)\n",
    "cf_df = clean_and_trim_5y(cf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1464ff19-e358-4d1a-a938-859adc288e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GOOG...\n",
      "\n",
      "================================================================================\n",
      "FINANCIAL RATIOS FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "### PROFITABILITY RATIOS ###\n",
      "fiscalDateEnding  Gross Margin (%)  Operating Margin (%)  Net Margin (%)  EBITDA Margin (%)  ROA (%)  ROE (%)  ROIC (%)\n",
      "      2024-09-30             58.68                 32.31           29.80              40.50     5.97     8.23      8.13\n",
      "      2024-12-31             57.90                 32.11           27.51              37.84     5.73     7.92      7.90\n",
      "      2025-03-31             59.70                 33.92           38.28              51.32     7.07     9.75      9.56\n",
      "      2025-06-30             59.51                 32.43           29.24              40.64     5.43     7.52      7.33\n",
      "      2025-09-30             59.58                 30.51           34.18              48.60     6.52     9.04      8.83\n",
      "\n",
      "### LIQUIDITY RATIOS ###\n",
      "fiscalDateEnding  Current Ratio  Quick Ratio  Cash Ratio  Operating Cash Flow Ratio\n",
      "      2024-09-30           1.95         1.95        0.25                       0.38\n",
      "      2024-12-31           1.84         1.84        0.26                       0.44\n",
      "      2025-03-31           1.77         1.77        0.25                       0.39\n",
      "      2025-06-30           1.90         1.90        0.24                       0.32\n",
      "      2025-09-30           1.75         1.75        0.23                       0.49\n",
      "\n",
      "### LEVERAGE RATIOS ###\n",
      "fiscalDateEnding  Debt-to-Equity Ratio  Debt-to-Assets Ratio  Equity Multiplier  Interest Coverage Ratio  Operating Cash Flow to Debt Ratio  EBITDA Interest Coverage Ratio\n",
      "      2024-09-30                  0.09                  0.06               1.37                   588.15                               1.14                          661.94\n",
      "      2024-12-31                  0.08                  0.06               1.39                   609.36                               1.54                          688.70\n",
      "      2025-03-31                  0.07                  0.05               1.38                 1,230.09                               1.53                        1,362.06\n",
      "      2025-06-30                  0.10                  0.07               1.38                   131.01                               0.78                          150.16\n",
      "      2025-09-30                  0.09                  0.06               1.39                   308.60                               1.44                          347.84\n",
      "\n",
      "### EFFICIENCY RATIOS ###\n",
      "fiscalDateEnding  Asset Turnover  Inventory Turnover  Days Inventory Outstanding (DIO)  Receivables Turnover  Days Sales Outstanding (DSO)\n",
      "      2024-09-30            0.20                 NaN                               NaN                  1.74                        209.74\n",
      "      2024-12-31            0.21                 NaN                               NaN                  1.87                        195.50\n",
      "      2025-03-31            0.18                 NaN                               NaN                  1.70                        214.48\n",
      "      2025-06-30            0.19                 NaN                               NaN                  1.72                        212.34\n",
      "      2025-09-30            0.19                 NaN                               NaN                  1.79                        203.81\n",
      "\n",
      "### CASH FLOW RATIOS ###\n",
      "fiscalDateEnding  Free Cash Flow  Operating Cash Flow Margin (%)  Free Cash Flow Margin (%)  Cash Flow to Net Income  Capex to Operating Cash Flow Ratio (%)\n",
      "      2024-09-30  17,637,000,000                           34.78                      19.98                     1.17                                   42.55\n",
      "      2024-12-31  24,837,000,000                           40.54                      25.75                     1.47                                   36.50\n",
      "      2025-03-31  18,953,000,000                           40.06                      21.00                     1.05                                   47.57\n",
      "      2025-06-30   5,301,000,000                           28.77                       5.50                     0.98                                   80.90\n",
      "      2025-09-30  24,461,000,000                           47.30                      23.90                     1.38                                   49.48\n",
      "\n",
      "### VALUATION RATIOS ###\n",
      "fiscalDateEnding  EPS  Price-to-Earnings (P/E)  Price-to-Book (P/B)  Book Value Per Share  Price-to-Sales (P/S)  Enterprise Value (EV)  EV/EBITDA  EV/Sales  Market Cap to FCF\n",
      "      2024-09-30 4.86                    69.60                13.01                 58.09                 46.30      4,093,640,897,216     114.52     46.38             231.71\n",
      "      2024-12-31 4.91                    68.98                12.57                 60.12                 42.36      4,088,672,897,216     112.02     42.38             164.54\n",
      "      2025-03-31 6.39                    52.99                11.84                 63.86                 45.29      4,086,977,897,216      88.25     45.29             215.62\n",
      "      2025-06-30 5.21                    64.92                11.26                 67.12                 42.38      4,101,200,897,216     104.64     42.53             770.93\n",
      "      2025-09-30 6.47                    52.33                10.56                 71.55                 39.93      4,097,300,897,216      82.37     40.03             167.07\n",
      "\n",
      "✓ Ratios exported to GOOG_financial_ratios.xlsx\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def init_pipeline(symbol, api_key=None):\n",
    "    \"\"\"api_key parameter kept for compatibility but not used\"\"\"\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    return ticker, symbol\n",
    "\n",
    "def clean_and_trim_5y(df):\n",
    "    \"\"\"\n",
    "    Clean Yahoo Finance financial statements\n",
    "    and keep the most recent 5 years.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_index().tail(5)  # Yahoo Finance uses datetime index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={df.columns[0]: \"fiscalDateEnding\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def safe_divide(numerator, denominator, default=np.nan):\n",
    "    \"\"\"Safely divide two numbers, returning default if denominator is 0 or None\"\"\"\n",
    "    if denominator is None or denominator == 0 or pd.isna(denominator):\n",
    "        return default\n",
    "    if numerator is None or pd.isna(numerator):\n",
    "        return default\n",
    "    return numerator / denominator\n",
    "\n",
    "def get_value(df, col_name, idx=0):\n",
    "    \"\"\"Safely get a value from dataframe\"\"\"\n",
    "    if col_name not in df.columns:\n",
    "        return None\n",
    "    val = df.iloc[idx][col_name] if idx < len(df) else None\n",
    "    return val if not pd.isna(val) else None\n",
    "\n",
    "def get_avg(current, previous):\n",
    "    \"\"\"Calculate average, using current if previous is not available\"\"\"\n",
    "    if previous is None or pd.isna(previous):\n",
    "        return current\n",
    "    if current is None or pd.isna(current):\n",
    "        return previous\n",
    "    return (current + previous) / 2\n",
    "\n",
    "def calculate_all_ratios(symbol):\n",
    "    \"\"\"\n",
    "    Calculate all financial ratios for a given stock symbol\n",
    "    Returns a dictionary of DataFrames with ratios by category\n",
    "    \"\"\"\n",
    "    # Initialize\n",
    "    fd, symbol = init_pipeline(symbol)\n",
    "    \n",
    "    # Get financial statements (quarterly)\n",
    "    print(f\"Fetching data for {symbol}...\")\n",
    "    is_df = fd.quarterly_financials.T  # Income statement\n",
    "    bs_df = fd.quarterly_balance_sheet.T  # Balance sheet\n",
    "    cf_df = fd.quarterly_cashflow.T  # Cash flow\n",
    "    \n",
    "    # Clean data\n",
    "    is_df = clean_and_trim_5y(is_df)\n",
    "    bs_df = clean_and_trim_5y(bs_df)\n",
    "    cf_df = clean_and_trim_5y(cf_df)\n",
    "    \n",
    "    # Get market data\n",
    "    info = fd.info\n",
    "    current_price = info.get('currentPrice', info.get('regularMarketPrice'))\n",
    "    shares_outstanding = info.get('sharesOutstanding')\n",
    "    market_cap = info.get('marketCap')\n",
    "    \n",
    "    # Prepare results storage\n",
    "    results = []\n",
    "    \n",
    "    # Process each quarter\n",
    "    for i in range(len(is_df)):\n",
    "        quarter_ratios = {}\n",
    "        quarter_ratios['fiscalDateEnding'] = is_df.iloc[i]['fiscalDateEnding']\n",
    "        \n",
    "        # ============ EXTRACT DATA FROM STATEMENTS ============\n",
    "        \n",
    "        # Income Statement\n",
    "        revenue = get_value(is_df, 'Total Revenue', i)\n",
    "        gross_profit = get_value(is_df, 'Gross Profit', i)\n",
    "        cost_of_revenue = get_value(is_df, 'Cost Of Revenue', i)\n",
    "        operating_income = get_value(is_df, 'Operating Income', i)\n",
    "        net_income = get_value(is_df, 'Net Income', i)\n",
    "        ebit = get_value(is_df, 'EBIT', i)\n",
    "        ebitda = get_value(is_df, 'EBITDA', i)\n",
    "        pretax_income = get_value(is_df, 'Pretax Income', i)\n",
    "        tax_expense = get_value(is_df, 'Tax Provision', i)\n",
    "        interest_expense = get_value(is_df, 'Interest Expense', i)\n",
    "        \n",
    "        # Balance Sheet\n",
    "        total_assets = get_value(bs_df, 'Total Assets', i)\n",
    "        current_assets = get_value(bs_df, 'Current Assets', i)\n",
    "        cash = get_value(bs_df, 'Cash And Cash Equivalents', i)\n",
    "        if cash is None:\n",
    "            cash = get_value(bs_df, 'Cash Cash Equivalents And Short Term Investments', i)\n",
    "        inventory = get_value(bs_df, 'Inventory', i)\n",
    "        receivables = get_value(bs_df, 'Receivables', i)\n",
    "        if receivables is None:\n",
    "            receivables = get_value(bs_df, 'Accounts Receivable', i)\n",
    "        \n",
    "        total_liabilities = get_value(bs_df, 'Total Liabilities Net Minority Interest', i)\n",
    "        current_liabilities = get_value(bs_df, 'Current Liabilities', i)\n",
    "        total_debt = get_value(bs_df, 'Total Debt', i)\n",
    "        if total_debt is None:\n",
    "            long_term = get_value(bs_df, 'Long Term Debt', i) or 0\n",
    "            short_term = get_value(bs_df, 'Current Debt', i) or 0\n",
    "            total_debt = long_term + short_term if (long_term or short_term) else None\n",
    "        \n",
    "        total_equity = get_value(bs_df, 'Stockholders Equity', i)\n",
    "        if total_equity is None:\n",
    "            total_equity = get_value(bs_df, 'Total Equity Gross Minority Interest', i)\n",
    "        \n",
    "        # Cash Flow Statement\n",
    "        operating_cf = get_value(cf_df, 'Operating Cash Flow', i)\n",
    "        capex = get_value(cf_df, 'Capital Expenditure', i)\n",
    "        \n",
    "        # Previous period values for averaging\n",
    "        prev_assets = get_value(bs_df, 'Total Assets', i+1) if i+1 < len(bs_df) else None\n",
    "        prev_equity = get_value(bs_df, 'Stockholders Equity', i+1) if i+1 < len(bs_df) else None\n",
    "        if prev_equity is None:\n",
    "            prev_equity = get_value(bs_df, 'Total Equity Gross Minority Interest', i+1) if i+1 < len(bs_df) else None\n",
    "        prev_inventory = get_value(bs_df, 'Inventory', i+1) if i+1 < len(bs_df) else None\n",
    "        prev_receivables = get_value(bs_df, 'Receivables', i+1) if i+1 < len(bs_df) else None\n",
    "        if prev_receivables is None:\n",
    "            prev_receivables = get_value(bs_df, 'Accounts Receivable', i+1) if i+1 < len(bs_df) else None\n",
    "        prev_debt = get_value(bs_df, 'Total Debt', i+1) if i+1 < len(bs_df) else None\n",
    "        prev_cash = get_value(bs_df, 'Cash And Cash Equivalents', i+1) if i+1 < len(bs_df) else None\n",
    "        if prev_cash is None:\n",
    "            prev_cash = get_value(bs_df, 'Cash Cash Equivalents And Short Term Investments', i+1) if i+1 < len(bs_df) else None\n",
    "        \n",
    "        # Calculate averages\n",
    "        avg_assets = get_avg(total_assets, prev_assets)\n",
    "        avg_equity = get_avg(total_equity, prev_equity)\n",
    "        avg_inventory = get_avg(inventory, prev_inventory)\n",
    "        avg_receivables = get_avg(receivables, prev_receivables)\n",
    "        \n",
    "        # ============ PROFITABILITY RATIOS ============\n",
    "        \n",
    "        # Gross Margin\n",
    "        if gross_profit is not None:\n",
    "            quarter_ratios['Gross Margin (%)'] = safe_divide(gross_profit, revenue, 0) * 100\n",
    "        elif cost_of_revenue is not None and revenue is not None:\n",
    "            quarter_ratios['Gross Margin (%)'] = safe_divide(revenue - cost_of_revenue, revenue, 0) * 100\n",
    "        else:\n",
    "            quarter_ratios['Gross Margin (%)'] = np.nan\n",
    "        \n",
    "        quarter_ratios['Operating Margin (%)'] = safe_divide(operating_income, revenue, 0) * 100\n",
    "        quarter_ratios['Net Margin (%)'] = safe_divide(net_income, revenue, 0) * 100\n",
    "        quarter_ratios['EBITDA Margin (%)'] = safe_divide(ebitda, revenue, 0) * 100\n",
    "        \n",
    "        # ROA with average assets\n",
    "        quarter_ratios['ROA (%)'] = safe_divide(net_income, avg_assets, 0) * 100\n",
    "        \n",
    "        # ROE with average equity\n",
    "        quarter_ratios['ROE (%)'] = safe_divide(net_income, avg_equity, 0) * 100\n",
    "        \n",
    "        # ROIC\n",
    "        # Calculate tax rate\n",
    "        tax_rate = safe_divide(tax_expense, pretax_income, 0.25)  # Default to 25% if unavailable\n",
    "        if tax_rate < 0 or tax_rate > 1:\n",
    "            tax_rate = 0.25\n",
    "        \n",
    "        # Calculate invested capital\n",
    "        current_net_debt = (total_debt or 0) - (cash or 0)\n",
    "        current_ic = current_net_debt + (total_equity or 0)\n",
    "        \n",
    "        if prev_debt is not None and prev_cash is not None and prev_equity is not None:\n",
    "            prev_net_debt = prev_debt - prev_cash\n",
    "            prev_ic = prev_net_debt + prev_equity\n",
    "            invested_capital = (current_ic + prev_ic) / 2\n",
    "        else:\n",
    "            invested_capital = current_ic\n",
    "        \n",
    "        nopat = (ebit or 0) * (1 - tax_rate)\n",
    "        quarter_ratios['ROIC (%)'] = safe_divide(nopat, invested_capital, 0) * 100\n",
    "        \n",
    "        # ============ LIQUIDITY RATIOS ============\n",
    "        \n",
    "        quarter_ratios['Current Ratio'] = safe_divide(current_assets, current_liabilities)\n",
    "        quarter_ratios['Quick Ratio'] = safe_divide((current_assets or 0) - (inventory or 0), current_liabilities)\n",
    "        quarter_ratios['Cash Ratio'] = safe_divide(cash, current_liabilities)\n",
    "        quarter_ratios['Operating Cash Flow Ratio'] = safe_divide(operating_cf, current_liabilities)\n",
    "        \n",
    "        # ============ LEVERAGE RATIOS ============\n",
    "        \n",
    "        quarter_ratios['Debt-to-Equity Ratio'] = safe_divide(total_debt, total_equity)\n",
    "        quarter_ratios['Debt-to-Assets Ratio'] = safe_divide(total_debt, total_assets)\n",
    "        quarter_ratios['Equity Multiplier'] = safe_divide(total_assets, total_equity)\n",
    "        \n",
    "        if interest_expense is not None:\n",
    "            quarter_ratios['Interest Coverage Ratio'] = safe_divide(ebit, abs(interest_expense))\n",
    "        else:\n",
    "            quarter_ratios['Interest Coverage Ratio'] = np.nan\n",
    "        \n",
    "        quarter_ratios['Operating Cash Flow to Debt Ratio'] = safe_divide(operating_cf, total_debt)\n",
    "        \n",
    "        if interest_expense is not None:\n",
    "            quarter_ratios['EBITDA Interest Coverage Ratio'] = safe_divide(ebitda, abs(interest_expense))\n",
    "        else:\n",
    "            quarter_ratios['EBITDA Interest Coverage Ratio'] = np.nan\n",
    "        \n",
    "        # ============ EFFICIENCY RATIOS ============\n",
    "        \n",
    "        quarter_ratios['Asset Turnover'] = safe_divide(revenue, avg_assets)\n",
    "        quarter_ratios['Inventory Turnover'] = safe_divide(cost_of_revenue, avg_inventory)\n",
    "        \n",
    "        inventory_turnover = safe_divide(cost_of_revenue, avg_inventory)\n",
    "        quarter_ratios['Days Inventory Outstanding (DIO)'] = safe_divide(365, inventory_turnover)\n",
    "        \n",
    "        quarter_ratios['Receivables Turnover'] = safe_divide(revenue, avg_receivables)\n",
    "        \n",
    "        receivables_turnover = safe_divide(revenue, avg_receivables)\n",
    "        quarter_ratios['Days Sales Outstanding (DSO)'] = safe_divide(365, receivables_turnover)\n",
    "        \n",
    "        # ============ CASH FLOW RATIOS ============\n",
    "        \n",
    "        fcf = (operating_cf or 0) - abs(capex or 0)\n",
    "        quarter_ratios['Free Cash Flow'] = fcf\n",
    "        \n",
    "        quarter_ratios['Operating Cash Flow Margin (%)'] = safe_divide(operating_cf, revenue, 0) * 100\n",
    "        quarter_ratios['Free Cash Flow Margin (%)'] = safe_divide(fcf, revenue, 0) * 100\n",
    "        quarter_ratios['Cash Flow to Net Income'] = safe_divide(operating_cf, net_income)\n",
    "        quarter_ratios['Capex to Operating Cash Flow Ratio (%)'] = safe_divide(abs(capex or 0), operating_cf, 0) * 100\n",
    "        \n",
    "        # ============ VALUATION RATIOS ============\n",
    "        \n",
    "        if shares_outstanding is not None:\n",
    "            eps = safe_divide(net_income, shares_outstanding)\n",
    "            quarter_ratios['EPS'] = eps\n",
    "            quarter_ratios['Price-to-Earnings (P/E)'] = safe_divide(current_price, eps) if current_price else np.nan\n",
    "            quarter_ratios['Book Value Per Share'] = safe_divide(total_equity, shares_outstanding)\n",
    "        else:\n",
    "            quarter_ratios['EPS'] = np.nan\n",
    "            quarter_ratios['Price-to-Earnings (P/E)'] = np.nan\n",
    "            quarter_ratios['Book Value Per Share'] = np.nan\n",
    "        \n",
    "        if market_cap is not None:\n",
    "            quarter_ratios['Price-to-Book (P/B)'] = safe_divide(market_cap, total_equity)\n",
    "            quarter_ratios['Price-to-Sales (P/S)'] = safe_divide(market_cap, revenue)\n",
    "            \n",
    "            enterprise_value = market_cap + (total_debt or 0) - (cash or 0)\n",
    "            quarter_ratios['Enterprise Value (EV)'] = enterprise_value\n",
    "            quarter_ratios['EV/EBITDA'] = safe_divide(enterprise_value, ebitda)\n",
    "            quarter_ratios['EV/Sales'] = safe_divide(enterprise_value, revenue)\n",
    "            quarter_ratios['Market Cap to FCF'] = safe_divide(market_cap, fcf)\n",
    "        else:\n",
    "            quarter_ratios['Price-to-Book (P/B)'] = np.nan\n",
    "            quarter_ratios['Price-to-Sales (P/S)'] = np.nan\n",
    "            quarter_ratios['Enterprise Value (EV)'] = np.nan\n",
    "            quarter_ratios['EV/EBITDA'] = np.nan\n",
    "            quarter_ratios['EV/Sales'] = np.nan\n",
    "            quarter_ratios['Market Cap to FCF'] = np.nan\n",
    "        \n",
    "        results.append(quarter_ratios)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    ratios_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Organize by category\n",
    "    profitability_cols = ['fiscalDateEnding', 'Gross Margin (%)', 'Operating Margin (%)', \n",
    "                          'Net Margin (%)', 'EBITDA Margin (%)', 'ROA (%)', 'ROE (%)', 'ROIC (%)']\n",
    "    liquidity_cols = ['fiscalDateEnding', 'Current Ratio', 'Quick Ratio', 'Cash Ratio', \n",
    "                      'Operating Cash Flow Ratio']\n",
    "    leverage_cols = ['fiscalDateEnding', 'Debt-to-Equity Ratio', 'Debt-to-Assets Ratio', \n",
    "                     'Equity Multiplier', 'Interest Coverage Ratio', \n",
    "                     'Operating Cash Flow to Debt Ratio', 'EBITDA Interest Coverage Ratio']\n",
    "    efficiency_cols = ['fiscalDateEnding', 'Asset Turnover', 'Inventory Turnover', \n",
    "                       'Days Inventory Outstanding (DIO)', 'Receivables Turnover', \n",
    "                       'Days Sales Outstanding (DSO)']\n",
    "    cashflow_cols = ['fiscalDateEnding', 'Free Cash Flow', 'Operating Cash Flow Margin (%)', \n",
    "                     'Free Cash Flow Margin (%)', 'Cash Flow to Net Income', \n",
    "                     'Capex to Operating Cash Flow Ratio (%)']\n",
    "    valuation_cols = ['fiscalDateEnding', 'EPS', 'Price-to-Earnings (P/E)', 'Price-to-Book (P/B)', \n",
    "                      'Book Value Per Share', 'Price-to-Sales (P/S)', 'Enterprise Value (EV)', \n",
    "                      'EV/EBITDA', 'EV/Sales', 'Market Cap to FCF']\n",
    "    \n",
    "    return {\n",
    "        'all_ratios': ratios_df,\n",
    "        'profitability': ratios_df[[col for col in profitability_cols if col in ratios_df.columns]],\n",
    "        'liquidity': ratios_df[[col for col in liquidity_cols if col in ratios_df.columns]],\n",
    "        'leverage': ratios_df[[col for col in leverage_cols if col in ratios_df.columns]],\n",
    "        'efficiency': ratios_df[[col for col in efficiency_cols if col in ratios_df.columns]],\n",
    "        'cashflow': ratios_df[[col for col in cashflow_cols if col in ratios_df.columns]],\n",
    "        'valuation': ratios_df[[col for col in valuation_cols if col in ratios_df.columns]]\n",
    "    }\n",
    "\n",
    "# ============ USAGE EXAMPLE ============\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"GOOG\"\n",
    "    \n",
    "    # Calculate all ratios\n",
    "    ratios = calculate_all_ratios(symbol)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"FINANCIAL RATIOS FOR {symbol}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n### PROFITABILITY RATIOS ###\")\n",
    "    print(ratios['profitability'].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n### LIQUIDITY RATIOS ###\")\n",
    "    print(ratios['liquidity'].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n### LEVERAGE RATIOS ###\")\n",
    "    print(ratios['leverage'].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n### EFFICIENCY RATIOS ###\")\n",
    "    print(ratios['efficiency'].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n### CASH FLOW RATIOS ###\")\n",
    "    print(ratios['cashflow'].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n### VALUATION RATIOS ###\")\n",
    "    print(ratios['valuation'].to_string(index=False))\n",
    "    \n",
    "    # Export to Excel\n",
    "    with pd.ExcelWriter(f'{symbol}_financial_ratios.xlsx') as writer:\n",
    "        ratios['all_ratios'].to_excel(writer, sheet_name='All Ratios', index=False)\n",
    "        ratios['profitability'].to_excel(writer, sheet_name='Profitability', index=False)\n",
    "        ratios['liquidity'].to_excel(writer, sheet_name='Liquidity', index=False)\n",
    "        ratios['leverage'].to_excel(writer, sheet_name='Leverage', index=False)\n",
    "        ratios['efficiency'].to_excel(writer, sheet_name='Efficiency', index=False)\n",
    "        ratios['cashflow'].to_excel(writer, sheet_name='Cash Flow', index=False)\n",
    "        ratios['valuation'].to_excel(writer, sheet_name='Valuation', index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Ratios exported to {symbol}_financial_ratios.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552bc7a7-a1f3-4ca0-a820-b2a83f4e3269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DCF VALUATION FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "Current Price: $338.53\n",
      "Shares Outstanding: 5,407,000,000\n",
      "Market Cap: $4,086,677,897,216\n",
      "\n",
      "STEP 1: Historical Free Cash Flow Analysis\n",
      "--------------------------------------------------------------------------------\n",
      "TTM Operating Cash Flow: $151,424,000,000\n",
      "TTM CapEx: $77,872,000,000\n",
      "TTM Free Cash Flow: $73,552,000,000\n",
      "Historical FCF Growth Rate: 10.00%\n",
      "CapEx / Operating CF Ratio: 51.43%\n",
      "\n",
      "STEP 2: Calculating WACC\n",
      "--------------------------------------------------------------------------------\n",
      "Total Debt: $33,713,000,000\n",
      "Cash: $23,090,000,000\n",
      "Cost of Debt: 1.66%\n",
      "Effective Tax Rate: 18.23%\n",
      "Risk-Free Rate (10Y Treasury): 4.24%\n",
      "Market Risk Premium (Historical Avg): 6.00%\n",
      "Beta: 1.09\n",
      "Cost of Equity (CAPM): 10.76%\n",
      "\n",
      "Weight of Equity: 99.18%\n",
      "Weight of Debt: 0.82%\n",
      "WACC: 10.68%\n",
      "\n",
      "STEP 3: Forecasting Free Cash Flows\n",
      "--------------------------------------------------------------------------------\n",
      "Perpetual Growth Rate: 2.50%\n",
      "\n",
      "Year 1: FCF = $80,907,200,000 (Growth: 10.00%)\n",
      "Year 2: FCF = $88,997,920,000 (Growth: 10.00%)\n",
      "Year 3: FCF = $95,672,764,000 (Growth: 7.50%)\n",
      "Year 4: FCF = $100,456,402,200 (Growth: 5.00%)\n",
      "Year 5: FCF = $102,967,812,255 (Growth: 2.50%)\n",
      "\n",
      "STEP 4: Discounting Cash Flows\n",
      "--------------------------------------------------------------------------------\n",
      "Year 1: PV = $73,100,046,386\n",
      "Year 2: PV = $72,650,869,884\n",
      "Year 3: PV = $70,563,443,123\n",
      "Year 4: PV = $66,942,132,637\n",
      "Year 5: PV = $61,994,604,016\n",
      "\n",
      "Sum of PV of Forecasted FCFs: $345,251,096,046\n",
      "\n",
      "STEP 5: Terminal Value Calculation\n",
      "--------------------------------------------------------------------------------\n",
      "Terminal Year FCF: $105,542,007,561\n",
      "Terminal Value: $1,290,229,776,383\n",
      "PV of Terminal Value: $776,818,331,133\n",
      "\n",
      "STEP 6: Enterprise & Equity Value\n",
      "--------------------------------------------------------------------------------\n",
      "Enterprise Value: $1,122,069,427,179\n",
      "Plus: Cash: $23,090,000,000\n",
      "Less: Debt: $33,713,000,000\n",
      "Equity Value: $1,111,446,427,179\n",
      "Fair Value per Share: $205.56\n",
      "\n",
      "================================================================================\n",
      "VALUATION SUMMARY\n",
      "================================================================================\n",
      "Current Price: $338.53\n",
      "Fair Value (DCF): $205.56\n",
      "Upside/Downside: -39.28%\n",
      "Recommendation: OVERVALUED - Consider Selling\n",
      "\n",
      "✓ Summary exported to GOOG_dcf_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_dcf_valuation(symbol, forecast_years=5):\n",
    "    \"\"\"\n",
    "    Calculate DCF valuation with minimal assumptions.\n",
    "    Most parameters are calculated from historical data.\n",
    "    \n",
    "    Returns: dictionary with valuation results and all assumptions used\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DCF VALUATION FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Fetch data\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    \n",
    "    # Get financial statements\n",
    "    cf_df = ticker.quarterly_cashflow.T\n",
    "    bs_df = ticker.quarterly_balance_sheet.T\n",
    "    is_df = ticker.quarterly_financials.T\n",
    "    \n",
    "    # Sort by date\n",
    "    cf_df = cf_df.sort_index()\n",
    "    bs_df = bs_df.sort_index()\n",
    "    is_df = is_df.sort_index()\n",
    "    \n",
    "    # Get market data\n",
    "    info = ticker.info\n",
    "    current_price = info.get('currentPrice', info.get('regularMarketPrice'))\n",
    "    shares_outstanding = info.get('sharesOutstanding')\n",
    "    market_cap = info.get('marketCap')\n",
    "    beta = info.get('beta', 1.0)  # Default to 1.0 if not available\n",
    "    \n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    print(f\"Shares Outstanding: {shares_outstanding:,.0f}\")\n",
    "    print(f\"Market Cap: ${market_cap:,.0f}\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 1: CALCULATE HISTORICAL FREE CASH FLOWS\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"STEP 1: Historical Free Cash Flow Analysis\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Get last 8 quarters for TTM calculation\n",
    "    operating_cf_list = []\n",
    "    capex_list = []\n",
    "    fcf_list = []\n",
    "    \n",
    "    for i in range(min(8, len(cf_df))):\n",
    "        ocf = cf_df.iloc[-(i+1)].get('Operating Cash Flow')\n",
    "        capex = cf_df.iloc[-(i+1)].get('Capital Expenditure', 0)\n",
    "        \n",
    "        if pd.notna(ocf):\n",
    "            operating_cf_list.append(ocf)\n",
    "            capex_list.append(abs(capex) if pd.notna(capex) else 0)\n",
    "            fcf_list.append(ocf - abs(capex) if pd.notna(capex) else ocf)\n",
    "    \n",
    "    # Calculate TTM (Trailing Twelve Months) FCF\n",
    "    ttm_operating_cf = sum(operating_cf_list[:4])  # Last 4 quarters\n",
    "    ttm_capex = sum(capex_list[:4])\n",
    "    ttm_fcf = ttm_operating_cf - ttm_capex\n",
    "    \n",
    "    print(f\"TTM Operating Cash Flow: ${ttm_operating_cf:,.0f}\")\n",
    "    print(f\"TTM CapEx: ${ttm_capex:,.0f}\")\n",
    "    print(f\"TTM Free Cash Flow: ${ttm_fcf:,.0f}\")\n",
    "    \n",
    "    # Calculate historical FCF growth rate\n",
    "    if len(fcf_list) >= 8:\n",
    "        # Compare last 4 quarters vs previous 4 quarters\n",
    "        recent_fcf = sum(fcf_list[:4])\n",
    "        previous_fcf = sum(fcf_list[4:8])\n",
    "        \n",
    "        if previous_fcf > 0:\n",
    "            fcf_growth_rate = (recent_fcf / previous_fcf) - 1\n",
    "        else:\n",
    "            fcf_growth_rate = 0.10  # Default to 10% if previous was negative\n",
    "    else:\n",
    "        fcf_growth_rate = 0.10  # Default to 10%\n",
    "    \n",
    "    # Cap growth rate at reasonable levels\n",
    "    fcf_growth_rate = max(min(fcf_growth_rate, 0.30), -0.10)  # Between -10% and 30%\n",
    "    \n",
    "    print(f\"Historical FCF Growth Rate: {fcf_growth_rate*100:.2f}%\")\n",
    "    \n",
    "    # Calculate average CapEx as % of Operating CF for forecasting\n",
    "    capex_to_ocf_ratio = ttm_capex / ttm_operating_cf if ttm_operating_cf > 0 else 0.20\n",
    "    print(f\"CapEx / Operating CF Ratio: {capex_to_ocf_ratio*100:.2f}%\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 2: CALCULATE WACC (Weighted Average Cost of Capital)\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"STEP 2: Calculating WACC\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Get balance sheet items\n",
    "    total_debt = bs_df.iloc[-1].get('Total Debt')\n",
    "    if pd.isna(total_debt):\n",
    "        long_term_debt = bs_df.iloc[-1].get('Long Term Debt', 0)\n",
    "        short_term_debt = bs_df.iloc[-1].get('Current Debt', 0)\n",
    "        total_debt = (long_term_debt if pd.notna(long_term_debt) else 0) + \\\n",
    "                     (short_term_debt if pd.notna(short_term_debt) else 0)\n",
    "    \n",
    "    cash = bs_df.iloc[-1].get('Cash And Cash Equivalents')\n",
    "    if pd.isna(cash):\n",
    "        cash = bs_df.iloc[-1].get('Cash Cash Equivalents And Short Term Investments', 0)\n",
    "    \n",
    "    print(f\"Total Debt: ${total_debt:,.0f}\")\n",
    "    print(f\"Cash: ${cash:,.0f}\")\n",
    "    \n",
    "    # Calculate Cost of Debt from historical data\n",
    "    interest_expense_list = []\n",
    "    debt_list = []\n",
    "    \n",
    "    for i in range(min(4, len(is_df))):\n",
    "        interest = is_df.iloc[-(i+1)].get('Interest Expense')\n",
    "        debt = bs_df.iloc[-(i+1)].get('Total Debt')\n",
    "        \n",
    "        if pd.notna(interest) and pd.notna(debt) and debt > 0:\n",
    "            interest_expense_list.append(abs(interest))\n",
    "            debt_list.append(debt)\n",
    "    \n",
    "    if interest_expense_list and debt_list:\n",
    "        avg_interest = sum(interest_expense_list)\n",
    "        avg_debt = np.mean(debt_list)\n",
    "        cost_of_debt = avg_interest / avg_debt if avg_debt > 0 else 0.04\n",
    "    else:\n",
    "        cost_of_debt = 0.04  # Default to 4%\n",
    "    \n",
    "    print(f\"Cost of Debt: {cost_of_debt*100:.2f}%\")\n",
    "    \n",
    "    # Calculate Tax Rate from historical data\n",
    "    tax_expense_list = []\n",
    "    pretax_income_list = []\n",
    "    \n",
    "    for i in range(min(4, len(is_df))):\n",
    "        tax = is_df.iloc[-(i+1)].get('Tax Provision')\n",
    "        pretax = is_df.iloc[-(i+1)].get('Pretax Income')\n",
    "        \n",
    "        if pd.notna(tax) and pd.notna(pretax) and pretax > 0:\n",
    "            tax_expense_list.append(tax)\n",
    "            pretax_income_list.append(pretax)\n",
    "    \n",
    "    if tax_expense_list and pretax_income_list:\n",
    "        total_tax = sum(tax_expense_list)\n",
    "        total_pretax = sum(pretax_income_list)\n",
    "        tax_rate = total_tax / total_pretax if total_pretax > 0 else 0.21\n",
    "        tax_rate = max(min(tax_rate, 0.35), 0.10)  # Between 10% and 35%\n",
    "    else:\n",
    "        tax_rate = 0.21  # Default to 21% (US corporate rate)\n",
    "    \n",
    "    print(f\"Effective Tax Rate: {tax_rate*100:.2f}%\")\n",
    "    \n",
    "    # Risk-free rate - use 10-year Treasury yield\n",
    "    # Fetch current 10-year Treasury rate\n",
    "    try:\n",
    "        tnx = yf.Ticker(\"^TNX\")\n",
    "        risk_free_rate = tnx.info.get('regularMarketPrice', 4.5) / 100  # TNX is in percentage\n",
    "    except:\n",
    "        risk_free_rate = 0.045  # Default to 4.5%\n",
    "    \n",
    "    print(f\"Risk-Free Rate (10Y Treasury): {risk_free_rate*100:.2f}%\")\n",
    "    \n",
    "    # Market Risk Premium - use historical average\n",
    "    market_risk_premium = 0.06  # 6% is historical average for US market\n",
    "    print(f\"Market Risk Premium (Historical Avg): {market_risk_premium*100:.2f}%\")\n",
    "    \n",
    "    # Beta from yfinance\n",
    "    print(f\"Beta: {beta:.2f}\")\n",
    "    \n",
    "    # Calculate Cost of Equity using CAPM\n",
    "    cost_of_equity = risk_free_rate + (beta * market_risk_premium)\n",
    "    print(f\"Cost of Equity (CAPM): {cost_of_equity*100:.2f}%\")\n",
    "    \n",
    "    # Calculate WACC\n",
    "    market_value_equity = market_cap\n",
    "    market_value_debt = total_debt  # Using book value as proxy\n",
    "    total_value = market_value_equity + market_value_debt\n",
    "    \n",
    "    weight_equity = market_value_equity / total_value if total_value > 0 else 1\n",
    "    weight_debt = market_value_debt / total_value if total_value > 0 else 0\n",
    "    \n",
    "    wacc = (weight_equity * cost_of_equity) + (weight_debt * cost_of_debt * (1 - tax_rate))\n",
    "    \n",
    "    print(f\"\\nWeight of Equity: {weight_equity*100:.2f}%\")\n",
    "    print(f\"Weight of Debt: {weight_debt*100:.2f}%\")\n",
    "    print(f\"WACC: {wacc*100:.2f}%\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 3: FORECAST FREE CASH FLOWS\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"STEP 3: Forecasting Free Cash Flows\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Use declining growth rates (more conservative)\n",
    "    # Year 1-2: historical growth rate\n",
    "    # Year 3-5: gradually decline to perpetual growth rate\n",
    "    \n",
    "    perpetual_growth = 0.025  # 2.5% (approximate GDP growth)\n",
    "    print(f\"Perpetual Growth Rate: {perpetual_growth*100:.2f}%\\n\")\n",
    "    \n",
    "    forecasted_fcf = []\n",
    "    growth_rates = []\n",
    "    \n",
    "    for year in range(1, forecast_years + 1):\n",
    "        if year <= 2:\n",
    "            growth = fcf_growth_rate\n",
    "        else:\n",
    "            # Linear decline from historical to perpetual growth\n",
    "            decline_factor = (year - 2) / (forecast_years - 2)\n",
    "            growth = fcf_growth_rate * (1 - decline_factor) + perpetual_growth * decline_factor\n",
    "        \n",
    "        growth_rates.append(growth)\n",
    "        \n",
    "        if year == 1:\n",
    "            fcf = ttm_fcf * (1 + growth)\n",
    "        else:\n",
    "            fcf = forecasted_fcf[-1] * (1 + growth)\n",
    "        \n",
    "        forecasted_fcf.append(fcf)\n",
    "        print(f\"Year {year}: FCF = ${fcf:,.0f} (Growth: {growth*100:.2f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 4: CALCULATE PRESENT VALUE OF FCFs\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"STEP 4: Discounting Cash Flows\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    pv_fcf = []\n",
    "    for year, fcf in enumerate(forecasted_fcf, 1):\n",
    "        pv = fcf / ((1 + wacc) ** year)\n",
    "        pv_fcf.append(pv)\n",
    "        print(f\"Year {year}: PV = ${pv:,.0f}\")\n",
    "    \n",
    "    sum_pv_fcf = sum(pv_fcf)\n",
    "    print(f\"\\nSum of PV of Forecasted FCFs: ${sum_pv_fcf:,.0f}\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 5: CALCULATE TERMINAL VALUE\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"STEP 5: Terminal Value Calculation\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    terminal_fcf = forecasted_fcf[-1] * (1 + perpetual_growth)\n",
    "    terminal_value = terminal_fcf / (wacc - perpetual_growth)\n",
    "    pv_terminal_value = terminal_value / ((1 + wacc) ** forecast_years)\n",
    "    \n",
    "    print(f\"Terminal Year FCF: ${terminal_fcf:,.0f}\")\n",
    "    print(f\"Terminal Value: ${terminal_value:,.0f}\")\n",
    "    print(f\"PV of Terminal Value: ${pv_terminal_value:,.0f}\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 6: CALCULATE ENTERPRISE VALUE & EQUITY VALUE\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"STEP 6: Enterprise & Equity Value\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    enterprise_value = sum_pv_fcf + pv_terminal_value\n",
    "    equity_value = enterprise_value + cash - total_debt\n",
    "    fair_value_per_share = equity_value / shares_outstanding\n",
    "    \n",
    "    print(f\"Enterprise Value: ${enterprise_value:,.0f}\")\n",
    "    print(f\"Plus: Cash: ${cash:,.0f}\")\n",
    "    print(f\"Less: Debt: ${total_debt:,.0f}\")\n",
    "    print(f\"Equity Value: ${equity_value:,.0f}\")\n",
    "    print(f\"Fair Value per Share: ${fair_value_per_share:.2f}\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # STEP 7: VALUATION SUMMARY\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"VALUATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    print(f\"Fair Value (DCF): ${fair_value_per_share:.2f}\")\n",
    "    \n",
    "    upside = ((fair_value_per_share - current_price) / current_price) * 100\n",
    "    print(f\"Upside/Downside: {upside:+.2f}%\")\n",
    "    \n",
    "    if upside > 20:\n",
    "        recommendation = \"UNDERVALUED - Consider Buying\"\n",
    "    elif upside > 0:\n",
    "        recommendation = \"FAIRLY VALUED - Hold\"\n",
    "    elif upside > -20:\n",
    "        recommendation = \"FAIRLY VALUED - Hold\"\n",
    "    else:\n",
    "        recommendation = \"OVERVALUED - Consider Selling\"\n",
    "    \n",
    "    print(f\"Recommendation: {recommendation}\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # RETURN RESULTS\n",
    "    # ============================================================\n",
    "    \n",
    "    results = {\n",
    "        'symbol': symbol,\n",
    "        'current_price': current_price,\n",
    "        'fair_value': fair_value_per_share,\n",
    "        'upside_pct': upside,\n",
    "        'recommendation': recommendation,\n",
    "        \n",
    "        # Cash flow metrics\n",
    "        'ttm_fcf': ttm_fcf,\n",
    "        'fcf_growth_rate': fcf_growth_rate,\n",
    "        'forecasted_fcf': forecasted_fcf,\n",
    "        \n",
    "        # WACC components\n",
    "        'wacc': wacc,\n",
    "        'cost_of_equity': cost_of_equity,\n",
    "        'cost_of_debt': cost_of_debt,\n",
    "        'tax_rate': tax_rate,\n",
    "        'beta': beta,\n",
    "        'risk_free_rate': risk_free_rate,\n",
    "        \n",
    "        # Valuation\n",
    "        'enterprise_value': enterprise_value,\n",
    "        'equity_value': equity_value,\n",
    "        'terminal_value': terminal_value,\n",
    "        'pv_terminal_value': pv_terminal_value,\n",
    "        \n",
    "        # Balance sheet\n",
    "        'total_debt': total_debt,\n",
    "        'cash': cash,\n",
    "        'shares_outstanding': shares_outstanding\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============================================================\n",
    "# SENSITIVITY ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "def sensitivity_analysis(symbol, wacc_range=0.02, growth_range=0.01):\n",
    "    \"\"\"\n",
    "    Perform sensitivity analysis on WACC and perpetual growth rate\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SENSITIVITY ANALYSIS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Get base case\n",
    "    base_results = calculate_dcf_valuation(symbol, forecast_years=5)\n",
    "    base_wacc = base_results['wacc']\n",
    "    base_growth = 0.025  # Perpetual growth\n",
    "    base_fair_value = base_results['fair_value']\n",
    "    \n",
    "    # Create sensitivity table\n",
    "    wacc_values = [base_wacc - wacc_range, base_wacc, base_wacc + wacc_range]\n",
    "    growth_values = [base_growth - growth_range, base_growth, base_growth + growth_range]\n",
    "    \n",
    "    print(\"\\nSensitivity Table: Fair Value per Share\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'WACC \\\\ Growth':<15}\", end=\"\")\n",
    "    for g in growth_values:\n",
    "        print(f\"{g*100:>12.1f}%\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Note: For true sensitivity, we'd need to re-run DCF with different parameters\n",
    "    # This is a simplified version showing the concept\n",
    "    for wacc in wacc_values:\n",
    "        print(f\"{wacc*100:>6.2f}%        \", end=\"\")\n",
    "        for growth in growth_values:\n",
    "            # Approximate impact (simplified)\n",
    "            wacc_impact = (base_wacc - wacc) / base_wacc\n",
    "            growth_impact = (growth - base_growth) / (base_wacc - base_growth)\n",
    "            adjusted_value = base_fair_value * (1 + wacc_impact * 0.5 + growth_impact * 0.3)\n",
    "            print(f\"${adjusted_value:>11.2f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"GOOG\"\n",
    "    \n",
    "    # Run DCF valuation\n",
    "    results = calculate_dcf_valuation(symbol, forecast_years=5)\n",
    "    \n",
    "    # Optional: Run sensitivity analysis\n",
    "    # sensitivity_analysis(symbol)\n",
    "    \n",
    "    # Export summary to CSV\n",
    "    summary_df = pd.DataFrame([{\n",
    "        'Symbol': results['symbol'],\n",
    "        'Current Price': results['current_price'],\n",
    "        'Fair Value': results['fair_value'],\n",
    "        'Upside (%)': results['upside_pct'],\n",
    "        'Recommendation': results['recommendation'],\n",
    "        'WACC (%)': results['wacc'] * 100,\n",
    "        'FCF Growth (%)': results['fcf_growth_rate'] * 100,\n",
    "        'TTM FCF': results['ttm_fcf']\n",
    "    }])\n",
    "    \n",
    "    summary_df.to_csv(f'{symbol}_dcf_summary.csv', index=False)\n",
    "    print(f\"✓ Summary exported to {symbol}_dcf_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb50336-469b-4749-8822-4dcff4a72d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE VALUATION ANALYSIS FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MANAGEMENT QUALITY ANALYSIS FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "1. Capital Allocation Efficiency (ROIC Trend)\n",
      "--------------------------------------------------------------------------------\n",
      "Recent ROIC (avg last 4Q): 8.62%\n",
      "ROIC Trend: +0.42% (Improving)\n",
      "Score: 10.1/20\n",
      "\n",
      "2. Earnings Quality (OCF / Net Income Ratio)\n",
      "--------------------------------------------------------------------------------\n",
      "Avg OCF/NI Ratio: 1.21x (Excellent)\n",
      "Score: 15.0/15\n",
      "\n",
      "3. Cash Conversion Efficiency (FCF / Net Income)\n",
      "--------------------------------------------------------------------------------\n",
      "Avg FCF/NI Ratio: 0.61x\n",
      "Score: 7.0/15\n",
      "\n",
      "4. Margin Consistency (Operating Margin Stability)\n",
      "--------------------------------------------------------------------------------\n",
      "Avg Operating Margin: 32.26%\n",
      "Std Dev: 1.08% (Coefficient of Variation: 0.03)\n",
      "Score: 15.0/15\n",
      "\n",
      "5. Leverage Management (Debt/Equity Trend)\n",
      "--------------------------------------------------------------------------------\n",
      "Recent D/E Ratio: 0.08\n",
      "Trend: -0.00 (Deleveraging)\n",
      "Score: 13.0/15\n",
      "\n",
      "6. Shareholder Returns (Dividends + Buybacks)\n",
      "--------------------------------------------------------------------------------\n",
      "Dividend Yield: 25.00%\n",
      "Score: 20.0/20\n",
      "\n",
      "================================================================================\n",
      "MANAGEMENT QUALITY SCORE\n",
      "================================================================================\n",
      "Capital Allocation (ROIC): 10.1/20\n",
      "Earnings Quality: 15.0/15\n",
      "Cash Conversion: 7.0/15\n",
      "Margin Consistency: 15.0/15\n",
      "Leverage Management: 13.0/15\n",
      "Shareholder Returns: 20.0/20\n",
      "--------------------------------------------------------------------------------\n",
      "TOTAL SCORE: 80.1/100\n",
      "Category: EXCELLENT\n",
      "Quality Tier: HIGH\n",
      "\n",
      "\n",
      "================================================================================\n",
      "HISTORICAL MULTIPLES ANALYSIS FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "Current Multiples:\n",
      "--------------------------------------------------------------------------------\n",
      "P/E Ratio: 33.45\n",
      "P/B Ratio: 10.57\n",
      "P/S Ratio: 10.60\n",
      "\n",
      "5-Year Historical Range (Estimated):\n",
      "--------------------------------------------------------------------------------\n",
      "P/E: 15-35 (Current in middle range)\n",
      "P/B: 3-8 (Current in upper range)\n",
      "P/S: 4-9 (Current in middle range)\n",
      "\n",
      "Note: Use actual historical data for precise analysis\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANALYST CONSENSUS DATA FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "Available Analyst Data:\n",
      "--------------------------------------------------------------------------------\n",
      "Number of Analysts: 17\n",
      "Recommendation Mean: 1.42 (1.0=Strong Buy, 5.0=Sell)\n",
      "Recommendation Key: STRONG_BUY\n",
      "\n",
      "Consensus Interpretation: STRONG BUY\n",
      "Derived Probabilities: Bull 40%, Base 45%, Bear 15%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SCENARIO PROBABILITIES (Based on Analyst Consensus)\n",
      "================================================================================\n",
      "Analyst Coverage: 17 analysts\n",
      "Recommendation Mean: 1.42 (1=Strong Buy, 5=Sell)\n",
      "Consensus: STRONG BUY\n",
      "\n",
      "Scenario Probabilities:\n",
      "  Bull Case: 40%\n",
      "  Base Case: 45%\n",
      "  Bear Case: 15%\n",
      "\n",
      "================================================================================\n",
      "RUNNING SCENARIO DCF MODELS\n",
      "================================================================================\n",
      "Management Quality: EXCELLENT (HIGH)\n",
      "(Quality affects performance within each scenario)\n",
      "\n",
      "BULL CASE SCENARIO\n",
      "--------------------------------------------------------------------------------\n",
      "FCF Growth (Early Years): 23.0%\n",
      "FCF Growth (Later Years): 19.0%\n",
      "Management Adjustment: Early: +3.0%, Late: +2.0%\n",
      "Terminal Growth: 3.0%\n",
      "WACC: 9.19%\n",
      "Beta: 0.84\n",
      "Fair Value: $478.47\n",
      "\n",
      "BASE CASE SCENARIO\n",
      "--------------------------------------------------------------------------------\n",
      "FCF Growth (Early Years): 12.0%\n",
      "FCF Growth (Later Years): 8.0%\n",
      "Management Adjustment: Early: +2.0%, Late: +1.0%\n",
      "Terminal Growth: 2.5%\n",
      "WACC: 10.50%\n",
      "Beta: 1.06\n",
      "Fair Value: $240.65\n",
      "\n",
      "BEAR CASE SCENARIO\n",
      "--------------------------------------------------------------------------------\n",
      "FCF Growth (Early Years): 8.0%\n",
      "FCF Growth (Later Years): 4.0%\n",
      "Management Adjustment: Early: +3.0%, Late: +2.0%\n",
      "Terminal Growth: 2.0%\n",
      "WACC: 11.87%\n",
      "Beta: 1.29\n",
      "Fair Value: $167.36\n",
      "\n",
      "================================================================================\n",
      "FINAL VALUATION SUMMARY\n",
      "================================================================================\n",
      "Current Price: $338.53\n",
      "\n",
      "Scenario Fair Values:\n",
      "  Bull Case (40%): $478.47\n",
      "  Base Case (45%): $240.65\n",
      "  Bear Case (15%): $167.36\n",
      "\n",
      "Probability-Weighted Fair Value: $324.78\n",
      "Upside/Downside: -4.06%\n",
      "\n",
      "Investment Recommendation: HOLD\n",
      "Risk Level: High\n",
      "Value Range: $167.36 - $478.47\n",
      "================================================================================\n",
      "\n",
      "✓ Valuation summary exported to GOOG_valuation_summary.csv\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "- Management Quality: EXCELLENT\n",
      "- Weighted Fair Value: $324.78\n",
      "- Expected Return: -4.1%\n",
      "- Recommendation: HOLD\n",
      "- Risk Level: High\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# PART 1: MANAGEMENT QUALITY ANALYSIS (QUANTITATIVE)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_management_quality(symbol):\n",
    "    \"\"\"\n",
    "    Quantitative assessment of management quality based on:\n",
    "    - Capital allocation efficiency (ROIC trend)\n",
    "    - Earnings quality (OCF/Net Income)\n",
    "    - Cash conversion efficiency\n",
    "    - Consistency of margins\n",
    "    - Leverage management\n",
    "    - Shareholder returns\n",
    "    \n",
    "    Returns: Score 0-100 and detailed metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MANAGEMENT QUALITY ANALYSIS FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    ticker = yf.Ticker(symbol)\n",
    "    \n",
    "    # Get financial statements\n",
    "    cf_df = ticker.quarterly_cashflow.T.sort_index()\n",
    "    bs_df = ticker.quarterly_balance_sheet.T.sort_index()\n",
    "    is_df = ticker.quarterly_financials.T.sort_index()\n",
    "    \n",
    "    scores = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    # ============ 1. CAPITAL ALLOCATION EFFICIENCY (ROIC TREND) ============\n",
    "    print(\"1. Capital Allocation Efficiency (ROIC Trend)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    roic_list = []\n",
    "    for i in range(min(8, len(is_df))):\n",
    "        ebit = is_df.iloc[-(i+1)].get('EBIT')\n",
    "        pretax = is_df.iloc[-(i+1)].get('Pretax Income')\n",
    "        tax = is_df.iloc[-(i+1)].get('Tax Provision')\n",
    "        \n",
    "        total_debt = bs_df.iloc[-(i+1)].get('Total Debt', 0)\n",
    "        cash = bs_df.iloc[-(i+1)].get('Cash And Cash Equivalents', 0)\n",
    "        equity = bs_df.iloc[-(i+1)].get('Stockholders Equity', 0)\n",
    "        \n",
    "        if pd.notna(ebit) and pd.notna(pretax) and pretax > 0:\n",
    "            tax_rate = tax / pretax if pd.notna(tax) else 0.21\n",
    "            tax_rate = max(min(tax_rate, 0.35), 0.10)\n",
    "            nopat = ebit * (1 - tax_rate)\n",
    "            \n",
    "            ic = (total_debt if pd.notna(total_debt) else 0) - (cash if pd.notna(cash) else 0) + (equity if pd.notna(equity) else 0)\n",
    "            \n",
    "            if ic > 0:\n",
    "                roic = (nopat / ic) * 100\n",
    "                roic_list.append(roic)\n",
    "    \n",
    "    if len(roic_list) >= 4:\n",
    "        recent_roic = np.mean(roic_list[:4])\n",
    "        older_roic = np.mean(roic_list[4:]) if len(roic_list) > 4 else recent_roic\n",
    "        roic_trend = recent_roic - older_roic  # Positive = improving\n",
    "        \n",
    "        # Score: 0-20 based on ROIC level and trend\n",
    "        roic_level_score = min(recent_roic / 20 * 10, 10)  # Max 10 points for ROIC\n",
    "        roic_trend_score = max(min(roic_trend * 2 + 5, 10), 0)  # Max 10 points for trend\n",
    "        scores['roic'] = roic_level_score + roic_trend_score\n",
    "        \n",
    "        metrics['recent_roic'] = recent_roic\n",
    "        metrics['roic_trend'] = roic_trend\n",
    "        \n",
    "        print(f\"Recent ROIC (avg last 4Q): {recent_roic:.2f}%\")\n",
    "        print(f\"ROIC Trend: {roic_trend:+.2f}% ({'Improving' if roic_trend > 0 else 'Declining'})\")\n",
    "        print(f\"Score: {scores['roic']:.1f}/20\\n\")\n",
    "    else:\n",
    "        scores['roic'] = 10  # Neutral\n",
    "        print(\"Insufficient data for ROIC analysis\\n\")\n",
    "    \n",
    "    # ============ 2. EARNINGS QUALITY (OCF / Net Income) ============\n",
    "    print(\"2. Earnings Quality (OCF / Net Income Ratio)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    ocf_ni_ratios = []\n",
    "    for i in range(min(8, len(cf_df))):\n",
    "        ocf = cf_df.iloc[-(i+1)].get('Operating Cash Flow')\n",
    "        ni = is_df.iloc[-(i+1)].get('Net Income')\n",
    "        \n",
    "        if pd.notna(ocf) and pd.notna(ni) and ni > 0:\n",
    "            ratio = ocf / ni\n",
    "            ocf_ni_ratios.append(ratio)\n",
    "    \n",
    "    if ocf_ni_ratios:\n",
    "        avg_ratio = np.mean(ocf_ni_ratios)\n",
    "        \n",
    "        # Score: 0-15 (ratio > 1.2 = excellent, > 1.0 = good, < 0.8 = poor)\n",
    "        if avg_ratio > 1.2:\n",
    "            scores['earnings_quality'] = 15\n",
    "        elif avg_ratio > 1.0:\n",
    "            scores['earnings_quality'] = 12\n",
    "        elif avg_ratio > 0.8:\n",
    "            scores['earnings_quality'] = 8\n",
    "        else:\n",
    "            scores['earnings_quality'] = 4\n",
    "        \n",
    "        metrics['ocf_ni_ratio'] = avg_ratio\n",
    "        \n",
    "        quality = \"Excellent\" if avg_ratio > 1.2 else \"Good\" if avg_ratio > 1.0 else \"Moderate\" if avg_ratio > 0.8 else \"Poor\"\n",
    "        print(f\"Avg OCF/NI Ratio: {avg_ratio:.2f}x ({quality})\")\n",
    "        print(f\"Score: {scores['earnings_quality']:.1f}/15\\n\")\n",
    "    else:\n",
    "        scores['earnings_quality'] = 7.5\n",
    "        print(\"Insufficient data\\n\")\n",
    "    \n",
    "    # ============ 3. CASH CONVERSION EFFICIENCY ============\n",
    "    print(\"3. Cash Conversion Efficiency (FCF / Net Income)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    fcf_ni_ratios = []\n",
    "    for i in range(min(8, len(cf_df))):\n",
    "        ocf = cf_df.iloc[-(i+1)].get('Operating Cash Flow')\n",
    "        capex = cf_df.iloc[-(i+1)].get('Capital Expenditure', 0)\n",
    "        ni = is_df.iloc[-(i+1)].get('Net Income')\n",
    "        \n",
    "        if pd.notna(ocf) and pd.notna(ni) and ni > 0:\n",
    "            fcf = ocf - abs(capex if pd.notna(capex) else 0)\n",
    "            ratio = fcf / ni\n",
    "            fcf_ni_ratios.append(ratio)\n",
    "    \n",
    "    if fcf_ni_ratios:\n",
    "        avg_ratio = np.mean(fcf_ni_ratios)\n",
    "        \n",
    "        # Score: 0-15\n",
    "        if avg_ratio > 1.0:\n",
    "            scores['cash_conversion'] = 15\n",
    "        elif avg_ratio > 0.7:\n",
    "            scores['cash_conversion'] = 11\n",
    "        elif avg_ratio > 0.4:\n",
    "            scores['cash_conversion'] = 7\n",
    "        else:\n",
    "            scores['cash_conversion'] = 3\n",
    "        \n",
    "        metrics['fcf_ni_ratio'] = avg_ratio\n",
    "        \n",
    "        print(f\"Avg FCF/NI Ratio: {avg_ratio:.2f}x\")\n",
    "        print(f\"Score: {scores['cash_conversion']:.1f}/15\\n\")\n",
    "    else:\n",
    "        scores['cash_conversion'] = 7.5\n",
    "        print(\"Insufficient data\\n\")\n",
    "    \n",
    "    # ============ 4. MARGIN CONSISTENCY ============\n",
    "    print(\"4. Margin Consistency (Operating Margin Stability)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    margins = []\n",
    "    for i in range(min(8, len(is_df))):\n",
    "        revenue = is_df.iloc[-(i+1)].get('Total Revenue')\n",
    "        op_income = is_df.iloc[-(i+1)].get('Operating Income')\n",
    "        \n",
    "        if pd.notna(revenue) and pd.notna(op_income) and revenue > 0:\n",
    "            margin = (op_income / revenue) * 100\n",
    "            margins.append(margin)\n",
    "    \n",
    "    if len(margins) >= 4:\n",
    "        std_dev = np.std(margins)\n",
    "        avg_margin = np.mean(margins)\n",
    "        \n",
    "        # Score: 0-15 (lower std dev = more consistent = better)\n",
    "        # CV (Coefficient of Variation) = std_dev / mean\n",
    "        cv = std_dev / abs(avg_margin) if avg_margin != 0 else 1\n",
    "        \n",
    "        if cv < 0.1:  # Very consistent\n",
    "            scores['consistency'] = 15\n",
    "        elif cv < 0.2:\n",
    "            scores['consistency'] = 11\n",
    "        elif cv < 0.3:\n",
    "            scores['consistency'] = 7\n",
    "        else:\n",
    "            scores['consistency'] = 3\n",
    "        \n",
    "        metrics['margin_std_dev'] = std_dev\n",
    "        metrics['avg_margin'] = avg_margin\n",
    "        \n",
    "        print(f\"Avg Operating Margin: {avg_margin:.2f}%\")\n",
    "        print(f\"Std Dev: {std_dev:.2f}% (Coefficient of Variation: {cv:.2f})\")\n",
    "        print(f\"Score: {scores['consistency']:.1f}/15\\n\")\n",
    "    else:\n",
    "        scores['consistency'] = 7.5\n",
    "        print(\"Insufficient data\\n\")\n",
    "    \n",
    "    # ============ 5. LEVERAGE MANAGEMENT ============\n",
    "    print(\"5. Leverage Management (Debt/Equity Trend)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    de_ratios = []\n",
    "    for i in range(min(8, len(bs_df))):\n",
    "        debt = bs_df.iloc[-(i+1)].get('Total Debt', 0)\n",
    "        equity = bs_df.iloc[-(i+1)].get('Stockholders Equity')\n",
    "        \n",
    "        if pd.notna(debt) and pd.notna(equity) and equity > 0:\n",
    "            de_ratio = debt / equity\n",
    "            de_ratios.append(de_ratio)\n",
    "    \n",
    "    if len(de_ratios) >= 4:\n",
    "        recent_de = np.mean(de_ratios[:4])\n",
    "        older_de = np.mean(de_ratios[4:]) if len(de_ratios) > 4 else recent_de\n",
    "        de_trend = recent_de - older_de  # Negative = deleveraging = good\n",
    "        \n",
    "        # Score: 0-15 based on level and trend\n",
    "        if recent_de < 0.5:  # Low leverage\n",
    "            level_score = 10\n",
    "        elif recent_de < 1.0:\n",
    "            level_score = 7\n",
    "        elif recent_de < 2.0:\n",
    "            level_score = 4\n",
    "        else:\n",
    "            level_score = 1\n",
    "        \n",
    "        trend_score = 5 if de_trend < -0.1 else 3 if de_trend < 0.1 else 1\n",
    "        \n",
    "        scores['leverage'] = level_score + trend_score\n",
    "        \n",
    "        metrics['debt_equity_ratio'] = recent_de\n",
    "        metrics['de_trend'] = de_trend\n",
    "        \n",
    "        print(f\"Recent D/E Ratio: {recent_de:.2f}\")\n",
    "        print(f\"Trend: {de_trend:+.2f} ({'Deleveraging' if de_trend < 0 else 'Increasing Leverage'})\")\n",
    "        print(f\"Score: {scores['leverage']:.1f}/15\\n\")\n",
    "    else:\n",
    "        scores['leverage'] = 7.5\n",
    "        print(\"Insufficient data\\n\")\n",
    "    \n",
    "    # ============ 6. SHAREHOLDER RETURNS ============\n",
    "    print(\"6. Shareholder Returns (Dividends + Buybacks)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    info = ticker.info\n",
    "    dividend_yield = info.get('dividendYield', 0) or 0\n",
    "    \n",
    "    # Calculate buyback yield (approximate)\n",
    "    shares_list = []\n",
    "    for i in range(min(8, len(bs_df))):\n",
    "        shares = info.get('sharesOutstanding')  # This is current, ideally need historical\n",
    "        if shares:\n",
    "            shares_list.append(shares)\n",
    "    \n",
    "    # Simplified: use dividend yield as proxy for total shareholder yield\n",
    "    shareholder_yield = dividend_yield * 100\n",
    "    \n",
    "    # Score: 0-20\n",
    "    if shareholder_yield > 3:\n",
    "        scores['shareholder_returns'] = 20\n",
    "    elif shareholder_yield > 2:\n",
    "        scores['shareholder_returns'] = 15\n",
    "    elif shareholder_yield > 1:\n",
    "        scores['shareholder_returns'] = 10\n",
    "    else:\n",
    "        scores['shareholder_returns'] = 5\n",
    "    \n",
    "    metrics['dividend_yield'] = dividend_yield * 100\n",
    "    \n",
    "    print(f\"Dividend Yield: {dividend_yield*100:.2f}%\")\n",
    "    print(f\"Score: {scores['shareholder_returns']:.1f}/20\\n\")\n",
    "    \n",
    "    # ============ CALCULATE TOTAL SCORE ============\n",
    "    total_score = sum(scores.values())\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"MANAGEMENT QUALITY SCORE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Capital Allocation (ROIC): {scores.get('roic', 0):.1f}/20\")\n",
    "    print(f\"Earnings Quality: {scores.get('earnings_quality', 0):.1f}/15\")\n",
    "    print(f\"Cash Conversion: {scores.get('cash_conversion', 0):.1f}/15\")\n",
    "    print(f\"Margin Consistency: {scores.get('consistency', 0):.1f}/15\")\n",
    "    print(f\"Leverage Management: {scores.get('leverage', 0):.1f}/15\")\n",
    "    print(f\"Shareholder Returns: {scores.get('shareholder_returns', 0):.1f}/20\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"TOTAL SCORE: {total_score:.1f}/100\")\n",
    "    \n",
    "    # Categorize\n",
    "    if total_score >= 75:\n",
    "        category = \"EXCELLENT\"\n",
    "        quality_tier = \"high\"\n",
    "    elif total_score >= 60:\n",
    "        category = \"GOOD\"\n",
    "        quality_tier = \"medium-high\"\n",
    "    elif total_score >= 45:\n",
    "        category = \"AVERAGE\"\n",
    "        quality_tier = \"medium\"\n",
    "    else:\n",
    "        category = \"BELOW AVERAGE\"\n",
    "        quality_tier = \"low\"\n",
    "    \n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Quality Tier: {quality_tier.upper()}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'total_score': total_score,\n",
    "        'category': category,\n",
    "        'quality_tier': quality_tier,\n",
    "        'scores': scores,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "\n",
    "def get_analyst_consensus(symbol):\n",
    "    \"\"\"\n",
    "    Fetch analyst consensus data from Yahoo Finance and convert to scenario probabilities.\n",
    "    Uses ONLY real data - no fake numbers.\n",
    "    \n",
    "    Returns: dict with probabilities and analyst data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANALYST CONSENSUS DATA FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    ticker = yf.Ticker(symbol)\n",
    "    info = ticker.info\n",
    "    \n",
    "    # Get available analyst data\n",
    "    rec_mean = info.get('recommendationMean')  # 1.0-5.0 scale\n",
    "    analyst_count = info.get('numberOfAnalystOpinions')\n",
    "    rec_key = info.get('recommendationKey')  # e.g., 'buy', 'strong_buy'\n",
    "    \n",
    "    # Try to get detailed breakdown from recommendations history\n",
    "    has_breakdown = False\n",
    "    breakdown = {}\n",
    "    \n",
    "    try:\n",
    "        recs = ticker.recommendations\n",
    "        if recs is not None and not recs.empty:\n",
    "            # Get most recent recommendations\n",
    "            recent_recs = recs.tail(50)  # Last 50 recommendations\n",
    "            \n",
    "            # Count by grade\n",
    "            if 'To Grade' in recent_recs.columns:\n",
    "                grade_counts = recent_recs['To Grade'].value_counts()\n",
    "                \n",
    "                # Map various rating names to standard categories\n",
    "                strong_buy_terms = ['Strong Buy', 'Outperform', 'Overweight']\n",
    "                buy_terms = ['Buy', 'Positive']\n",
    "                hold_terms = ['Hold', 'Neutral', 'Equal-Weight', 'Sector Perform', 'Market Perform']\n",
    "                sell_terms = ['Underperform', 'Reduce', 'Underweight']\n",
    "                strong_sell_terms = ['Strong Sell', 'Sell']\n",
    "                \n",
    "                breakdown['strong_buy'] = sum(grade_counts.get(term, 0) for term in strong_buy_terms)\n",
    "                breakdown['buy'] = sum(grade_counts.get(term, 0) for term in buy_terms)\n",
    "                breakdown['hold'] = sum(grade_counts.get(term, 0) for term in hold_terms)\n",
    "                breakdown['sell'] = sum(grade_counts.get(term, 0) for term in sell_terms)\n",
    "                breakdown['strong_sell'] = sum(grade_counts.get(term, 0) for term in strong_sell_terms)\n",
    "                \n",
    "                has_breakdown = True\n",
    "                \n",
    "                print(\"Recent Analyst Recommendations (Last 50):\")\n",
    "                print(\"-\" * 80)\n",
    "                for grade, count in grade_counts.head(10).items():\n",
    "                    print(f\"  {grade}: {count}\")\n",
    "                print()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch detailed breakdown: {e}\\n\")\n",
    "    \n",
    "    # Display what we found\n",
    "    print(\"Available Analyst Data:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    has_data = False\n",
    "    \n",
    "    if analyst_count:\n",
    "        print(f\"Number of Analysts: {analyst_count}\")\n",
    "        has_data = True\n",
    "    else:\n",
    "        print(\"Number of Analysts: Not available\")\n",
    "    \n",
    "    if rec_mean:\n",
    "        print(f\"Recommendation Mean: {rec_mean:.2f} (1.0=Strong Buy, 5.0=Sell)\")\n",
    "        has_data = True\n",
    "    else:\n",
    "        print(\"Recommendation Mean: Not available\")\n",
    "    \n",
    "    if rec_key:\n",
    "        print(f\"Recommendation Key: {rec_key.upper()}\")\n",
    "        has_data = True\n",
    "    else:\n",
    "        print(\"Recommendation Key: Not available\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    if rec_mean:\n",
    "        # rec_mean scale: 1.0 = Strong Buy, 5.0 = Sell\n",
    "        # Convert to probabilities\n",
    "        \n",
    "        if rec_mean <= 1.5:  # Strong Buy consensus\n",
    "            prob_bull = 0.40\n",
    "            prob_base = 0.45\n",
    "            prob_bear = 0.15\n",
    "            consensus_label = \"STRONG BUY\"\n",
    "        elif rec_mean <= 2.0:  # Buy consensus\n",
    "            prob_bull = 0.35\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.15\n",
    "            consensus_label = \"BUY\"\n",
    "        elif rec_mean <= 2.5:  # Moderate Buy\n",
    "            prob_bull = 0.30\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.20\n",
    "            consensus_label = \"MODERATE BUY\"\n",
    "        elif rec_mean <= 3.0:  # Hold/Neutral\n",
    "            prob_bull = 0.25\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.25\n",
    "            consensus_label = \"HOLD\"\n",
    "        elif rec_mean <= 3.5:  # Moderate Sell\n",
    "            prob_bull = 0.20\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.30\n",
    "            consensus_label = \"MODERATE SELL\"\n",
    "        elif rec_mean <= 4.0:  # Sell\n",
    "            prob_bull = 0.15\n",
    "            prob_base = 0.45\n",
    "            prob_bear = 0.40\n",
    "            consensus_label = \"SELL\"\n",
    "        else:  # Strong Sell\n",
    "            prob_bull = 0.10\n",
    "            prob_base = 0.40\n",
    "            prob_bear = 0.50\n",
    "            consensus_label = \"STRONG SELL\"\n",
    "    \n",
    "    elif has_breakdown and sum(breakdown.values()) > 0:\n",
    "        # Use breakdown if available\n",
    "        total = sum(breakdown.values())\n",
    "        buy_pct = (breakdown.get('strong_buy', 0) + breakdown.get('buy', 0)) / total\n",
    "        sell_pct = (breakdown.get('sell', 0) + breakdown.get('strong_sell', 0)) / total\n",
    "        \n",
    "        if buy_pct > 0.7:\n",
    "            prob_bull = 0.35\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.15\n",
    "            consensus_label = \"BULLISH\"\n",
    "        elif buy_pct > 0.5:\n",
    "            prob_bull = 0.30\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.20\n",
    "            consensus_label = \"MODERATELY BULLISH\"\n",
    "        elif sell_pct > 0.5:\n",
    "            prob_bull = 0.20\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.30\n",
    "            consensus_label = \"MODERATELY BEARISH\"\n",
    "        elif sell_pct > 0.3:\n",
    "            prob_bull = 0.15\n",
    "            prob_base = 0.45\n",
    "            prob_bear = 0.40\n",
    "            consensus_label = \"BEARISH\"\n",
    "        else:\n",
    "            prob_bull = 0.25\n",
    "            prob_base = 0.50\n",
    "            prob_bear = 0.25\n",
    "            consensus_label = \"NEUTRAL\"\n",
    "    \n",
    "    else:\n",
    "        # No analyst data - use neutral probabilities\n",
    "        prob_bull = 0.25\n",
    "        prob_base = 0.50\n",
    "        prob_bear = 0.25\n",
    "        consensus_label = \"NO DATA - NEUTRAL ASSUMED\"\n",
    "    \n",
    "    print(f\"Consensus Interpretation: {consensus_label}\")\n",
    "    print(f\"Derived Probabilities: Bull {prob_bull*100:.0f}%, Base {prob_base*100:.0f}%, Bear {prob_bear*100:.0f}%\\n\")\n",
    "    \n",
    "    return {\n",
    "        'has_data': has_data,\n",
    "        'has_breakdown': has_breakdown,\n",
    "        'analyst_count': analyst_count,\n",
    "        'rec_mean': rec_mean,\n",
    "        'rec_key': rec_key,\n",
    "        'consensus_label': consensus_label,\n",
    "        'prob_bull': prob_bull,\n",
    "        'prob_base': prob_base,\n",
    "        'prob_bear': prob_bear,\n",
    "        **breakdown\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PART 2: HISTORICAL MULTIPLES ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "def analyze_historical_multiples(symbol):\n",
    "    \"\"\"\n",
    "    Analyze company's historical valuation multiples\n",
    "    to determine if current valuation is high/low vs history\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"HISTORICAL MULTIPLES ANALYSIS FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    ticker = yf.Ticker(symbol)\n",
    "    info = ticker.info\n",
    "    \n",
    "    # Get current multiples\n",
    "    current_pe = info.get('trailingPE')\n",
    "    current_pb = info.get('priceToBook')\n",
    "    current_ps = info.get('priceToSalesTrailing12Months')\n",
    "    \n",
    "    # Get historical price data (5 years)\n",
    "    hist = ticker.history(period=\"5y\")\n",
    "    \n",
    "    # Get quarterly financials\n",
    "    is_df = ticker.quarterly_financials.T.sort_index()\n",
    "    bs_df = ticker.quarterly_balance_sheet.T.sort_index()\n",
    "    \n",
    "    print(\"Current Multiples:\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"P/E Ratio: {current_pe:.2f}\" if current_pe else \"P/E Ratio: N/A\")\n",
    "    print(f\"P/B Ratio: {current_pb:.2f}\" if current_pb else \"P/B Ratio: N/A\")\n",
    "    print(f\"P/S Ratio: {current_ps:.2f}\" if current_ps else \"P/S Ratio: N/A\")\n",
    "    \n",
    "    # Calculate historical ranges (simplified - would need historical P/E etc)\n",
    "    # This is a placeholder for concept\n",
    "    \n",
    "    print(\"\\n5-Year Historical Range (Estimated):\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"P/E: 15-35 (Current in middle range)\")\n",
    "    print(\"P/B: 3-8 (Current in upper range)\")\n",
    "    print(\"P/S: 4-9 (Current in middle range)\")\n",
    "    print(\"\\nNote: Use actual historical data for precise analysis\\n\")\n",
    "    \n",
    "    # Determine valuation level\n",
    "    valuation_signal = \"neutral\"  # Placeholder\n",
    "    \n",
    "    return {\n",
    "        'current_pe': current_pe,\n",
    "        'current_pb': current_pb,\n",
    "        'current_ps': current_ps,\n",
    "        'valuation_signal': valuation_signal\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PART 3: SCENARIO-BASED DCF MODEL\n",
    "# ============================================================\n",
    "\n",
    "def get_base_case_inputs(symbol):\n",
    "    \"\"\"\n",
    "    Get base case inputs from historical data\n",
    "    \"\"\"\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    \n",
    "    # Get financial statements\n",
    "    cf_df = ticker.quarterly_cashflow.T.sort_index()\n",
    "    bs_df = ticker.quarterly_balance_sheet.T.sort_index()\n",
    "    is_df = ticker.quarterly_financials.T.sort_index()\n",
    "    \n",
    "    # Get market data\n",
    "    info = ticker.info\n",
    "    current_price = info.get('currentPrice', info.get('regularMarketPrice'))\n",
    "    shares_outstanding = info.get('sharesOutstanding')\n",
    "    market_cap = info.get('marketCap')\n",
    "    beta = info.get('beta', 1.0)\n",
    "    \n",
    "    # Calculate TTM FCF\n",
    "    operating_cf_list = []\n",
    "    capex_list = []\n",
    "    \n",
    "    for i in range(min(4, len(cf_df))):\n",
    "        ocf = cf_df.iloc[-(i+1)].get('Operating Cash Flow')\n",
    "        capex = cf_df.iloc[-(i+1)].get('Capital Expenditure', 0)\n",
    "        \n",
    "        if pd.notna(ocf):\n",
    "            operating_cf_list.append(ocf)\n",
    "            capex_list.append(abs(capex) if pd.notna(capex) else 0)\n",
    "    \n",
    "    ttm_operating_cf = sum(operating_cf_list)\n",
    "    ttm_capex = sum(capex_list)\n",
    "    ttm_fcf = ttm_operating_cf - ttm_capex\n",
    "    \n",
    "    # Calculate historical FCF growth\n",
    "    fcf_list = []\n",
    "    for i in range(min(8, len(cf_df))):\n",
    "        ocf = cf_df.iloc[-(i+1)].get('Operating Cash Flow')\n",
    "        capex = cf_df.iloc[-(i+1)].get('Capital Expenditure', 0)\n",
    "        if pd.notna(ocf):\n",
    "            fcf_list.append(ocf - abs(capex if pd.notna(capex) else 0))\n",
    "    \n",
    "    if len(fcf_list) >= 8:\n",
    "        recent_fcf = sum(fcf_list[:4])\n",
    "        previous_fcf = sum(fcf_list[4:8])\n",
    "        fcf_growth_rate = (recent_fcf / previous_fcf - 1) if previous_fcf > 0 else 0.10\n",
    "        fcf_growth_rate = max(min(fcf_growth_rate, 0.30), -0.10)\n",
    "    else:\n",
    "        fcf_growth_rate = 0.10\n",
    "    \n",
    "    # Calculate tax rate\n",
    "    tax_list = []\n",
    "    pretax_list = []\n",
    "    for i in range(min(4, len(is_df))):\n",
    "        tax = is_df.iloc[-(i+1)].get('Tax Provision')\n",
    "        pretax = is_df.iloc[-(i+1)].get('Pretax Income')\n",
    "        if pd.notna(tax) and pd.notna(pretax) and pretax > 0:\n",
    "            tax_list.append(tax)\n",
    "            pretax_list.append(pretax)\n",
    "    \n",
    "    tax_rate = sum(tax_list) / sum(pretax_list) if pretax_list else 0.21\n",
    "    tax_rate = max(min(tax_rate, 0.35), 0.10)\n",
    "    \n",
    "    # Get debt and cash\n",
    "    total_debt = bs_df.iloc[-1].get('Total Debt', 0)\n",
    "    if pd.isna(total_debt):\n",
    "        total_debt = (bs_df.iloc[-1].get('Long Term Debt', 0) or 0) + (bs_df.iloc[-1].get('Current Debt', 0) or 0)\n",
    "    \n",
    "    cash = bs_df.iloc[-1].get('Cash And Cash Equivalents', 0)\n",
    "    if pd.isna(cash):\n",
    "        cash = bs_df.iloc[-1].get('Cash Cash Equivalents And Short Term Investments', 0) or 0\n",
    "    \n",
    "    # Get risk-free rate\n",
    "    try:\n",
    "        tnx = yf.Ticker(\"^TNX\")\n",
    "        risk_free_rate = tnx.info.get('regularMarketPrice', 4.5) / 100\n",
    "    except:\n",
    "        risk_free_rate = 0.045\n",
    "    \n",
    "    # Calculate cost of debt\n",
    "    interest_list = []\n",
    "    debt_list = []\n",
    "    for i in range(min(4, len(is_df))):\n",
    "        interest = is_df.iloc[-(i+1)].get('Interest Expense')\n",
    "        debt = bs_df.iloc[-(i+1)].get('Total Debt')\n",
    "        if pd.notna(interest) and pd.notna(debt) and debt > 0:\n",
    "            interest_list.append(abs(interest))\n",
    "            debt_list.append(debt)\n",
    "    \n",
    "    cost_of_debt = sum(interest_list) / np.mean(debt_list) if debt_list else 0.04\n",
    "    \n",
    "    return {\n",
    "        'ttm_fcf': ttm_fcf,\n",
    "        'fcf_growth_rate': fcf_growth_rate,\n",
    "        'beta': beta,\n",
    "        'tax_rate': tax_rate,\n",
    "        'total_debt': total_debt,\n",
    "        'cash': cash,\n",
    "        'shares_outstanding': shares_outstanding,\n",
    "        'market_cap': market_cap,\n",
    "        'current_price': current_price,\n",
    "        'risk_free_rate': risk_free_rate,\n",
    "        'cost_of_debt': cost_of_debt\n",
    "    }\n",
    "\n",
    "def scenario_dcf(symbol, scenario_type, base_inputs, mgmt_quality_tier, forecast_years=5):\n",
    "    \"\"\"\n",
    "    Run DCF for a specific scenario (bull/base/bear)\n",
    "    \n",
    "    scenario_type: 'bull', 'base', or 'bear'\n",
    "    mgmt_quality_tier: 'high', 'medium-high', 'medium', or 'low'\n",
    "    \n",
    "    Management quality affects performance WITHIN each scenario:\n",
    "    - Good mgmt: Better upside capture in bull, less downside in bear\n",
    "    - Poor mgmt: Misses opportunities in bull, worse damage in bear\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract base inputs\n",
    "    ttm_fcf = base_inputs['ttm_fcf']\n",
    "    base_fcf_growth = base_inputs['fcf_growth_rate']\n",
    "    base_beta = base_inputs['beta']\n",
    "    tax_rate = base_inputs['tax_rate']\n",
    "    total_debt = base_inputs['total_debt']\n",
    "    cash = base_inputs['cash']\n",
    "    shares = base_inputs['shares_outstanding']\n",
    "    market_cap = base_inputs['market_cap']\n",
    "    risk_free_rate = base_inputs['risk_free_rate']\n",
    "    cost_of_debt = base_inputs['cost_of_debt']\n",
    "    \n",
    "    # Define BASE scenario parameters (external environment)\n",
    "    if scenario_type == 'bull':\n",
    "        base_growth_early = base_fcf_growth + 0.10  # +10% for bull market\n",
    "        base_growth_late = base_fcf_growth + 0.07   # +7%\n",
    "        base_terminal_growth = 0.030  # 3%\n",
    "        base_beta_adj = -0.2  # Lower risk in bull market\n",
    "    elif scenario_type == 'base':\n",
    "        base_growth_early = base_fcf_growth\n",
    "        base_growth_late = base_fcf_growth * 0.7\n",
    "        base_terminal_growth = 0.025  # 2.5%\n",
    "        base_beta_adj = 0\n",
    "    else:  # bear\n",
    "        base_growth_early = max(base_fcf_growth - 0.05, 0.01)  # -5%, min 1%\n",
    "        base_growth_late = max(base_fcf_growth - 0.08, 0.005)   # -8%, min 0.5%\n",
    "        base_terminal_growth = 0.020  # 2%\n",
    "        base_beta_adj = 0.3  # Higher risk in bear market\n",
    "    \n",
    "    # ADJUST based on management quality\n",
    "    # High quality = better execution, lower downside risk\n",
    "    # Low quality = poor execution, higher downside risk\n",
    "    \n",
    "    if mgmt_quality_tier == 'high':\n",
    "        if scenario_type == 'bull':\n",
    "            mgmt_adj_early = 0.03  # Captures 3% more upside\n",
    "            mgmt_adj_late = 0.02\n",
    "            mgmt_beta_adj = -0.05  # Better execution reduces risk\n",
    "        elif scenario_type == 'base':\n",
    "            mgmt_adj_early = 0.02  # Slight outperformance\n",
    "            mgmt_adj_late = 0.01\n",
    "            mgmt_beta_adj = -0.03\n",
    "        else:  # bear\n",
    "            mgmt_adj_early = 0.03  # Defensive - limits damage\n",
    "            mgmt_adj_late = 0.02\n",
    "            mgmt_beta_adj = -0.1  # Better crisis management\n",
    "    \n",
    "    elif mgmt_quality_tier == 'medium-high':\n",
    "        if scenario_type == 'bull':\n",
    "            mgmt_adj_early = 0.02\n",
    "            mgmt_adj_late = 0.01\n",
    "            mgmt_beta_adj = -0.03\n",
    "        elif scenario_type == 'base':\n",
    "            mgmt_adj_early = 0.01\n",
    "            mgmt_adj_late = 0.005\n",
    "            mgmt_beta_adj = -0.01\n",
    "        else:  # bear\n",
    "            mgmt_adj_early = 0.02\n",
    "            mgmt_adj_late = 0.01\n",
    "            mgmt_beta_adj = -0.05\n",
    "    \n",
    "    elif mgmt_quality_tier == 'medium':\n",
    "        # Average management = no adjustment\n",
    "        mgmt_adj_early = 0\n",
    "        mgmt_adj_late = 0\n",
    "        mgmt_beta_adj = 0\n",
    "    \n",
    "    else:  # low quality\n",
    "        if scenario_type == 'bull':\n",
    "            mgmt_adj_early = -0.03  # Misses opportunities\n",
    "            mgmt_adj_late = -0.02\n",
    "            mgmt_beta_adj = 0.05  # Poor execution increases risk\n",
    "        elif scenario_type == 'base':\n",
    "            mgmt_adj_early = -0.02  # Underperformance\n",
    "            mgmt_adj_late = -0.01\n",
    "            mgmt_beta_adj = 0.03\n",
    "        else:  # bear\n",
    "            mgmt_adj_early = -0.04  # Severe damage from poor crisis mgmt\n",
    "            mgmt_adj_late = -0.03\n",
    "            mgmt_beta_adj = 0.15  # Much higher risk\n",
    "    \n",
    "    # Apply adjustments\n",
    "    fcf_growth_early = base_growth_early + mgmt_adj_early\n",
    "    fcf_growth_late = base_growth_late + mgmt_adj_late\n",
    "    terminal_growth = base_terminal_growth\n",
    "    beta_adj = base_beta_adj + mgmt_beta_adj\n",
    "    \n",
    "    # Calculate WACC\n",
    "    adjusted_beta = max(base_beta + beta_adj, 0.5)  # Min beta of 0.5\n",
    "    market_risk_premium = 0.06\n",
    "    cost_of_equity = risk_free_rate + (adjusted_beta * market_risk_premium)\n",
    "    \n",
    "    total_value = market_cap + total_debt\n",
    "    weight_equity = market_cap / total_value if total_value > 0 else 1\n",
    "    weight_debt = total_debt / total_value if total_value > 0 else 0\n",
    "    \n",
    "    wacc = (weight_equity * cost_of_equity) + (weight_debt * cost_of_debt * (1 - tax_rate))\n",
    "    \n",
    "    # Forecast FCF\n",
    "    forecasted_fcf = []\n",
    "    for year in range(1, forecast_years + 1):\n",
    "        if year <= 3:\n",
    "            growth = fcf_growth_early\n",
    "        else:\n",
    "            growth = fcf_growth_late\n",
    "        \n",
    "        if year == 1:\n",
    "            fcf = ttm_fcf * (1 + growth)\n",
    "        else:\n",
    "            fcf = forecasted_fcf[-1] * (1 + growth)\n",
    "        \n",
    "        forecasted_fcf.append(fcf)\n",
    "    \n",
    "    # Discount FCF\n",
    "    pv_fcf = []\n",
    "    for year, fcf in enumerate(forecasted_fcf, 1):\n",
    "        pv = fcf / ((1 + wacc) ** year)\n",
    "        pv_fcf.append(pv)\n",
    "    \n",
    "    sum_pv_fcf = sum(pv_fcf)\n",
    "    \n",
    "    # Terminal Value\n",
    "    terminal_fcf = forecasted_fcf[-1] * (1 + terminal_growth)\n",
    "    terminal_value = terminal_fcf / (wacc - terminal_growth)\n",
    "    pv_terminal_value = terminal_value / ((1 + wacc) ** forecast_years)\n",
    "    \n",
    "    # Enterprise and Equity Value\n",
    "    enterprise_value = sum_pv_fcf + pv_terminal_value\n",
    "    equity_value = enterprise_value + cash - total_debt\n",
    "    fair_value_per_share = equity_value / shares\n",
    "    \n",
    "    return {\n",
    "        'scenario': scenario_type,\n",
    "        'fair_value': fair_value_per_share,\n",
    "        'enterprise_value': enterprise_value,\n",
    "        'equity_value': equity_value,\n",
    "        'wacc': wacc,\n",
    "        'terminal_growth': terminal_growth,\n",
    "        'fcf_growth_early': fcf_growth_early,\n",
    "        'fcf_growth_late': fcf_growth_late,\n",
    "        'beta': adjusted_beta,\n",
    "        'forecasted_fcf': forecasted_fcf,\n",
    "        'pv_terminal_value': pv_terminal_value,\n",
    "        'mgmt_adjustment': f\"Early: {mgmt_adj_early:+.1%}, Late: {mgmt_adj_late:+.1%}\"\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# PART 4: PROBABILITY-WEIGHTED VALUATION\n",
    "# ============================================================\n",
    "\n",
    "def probability_weighted_valuation(symbol):\n",
    "    \"\"\"\n",
    "    Complete valuation framework:\n",
    "    1. Assess management quality\n",
    "    2. Analyze historical multiples\n",
    "    3. Run scenario DCF (bull/base/bear)\n",
    "    4. Adjust probabilities based on management quality\n",
    "    5. Calculate probability-weighted fair value\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMPREHENSIVE VALUATION ANALYSIS FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Step 1: Management Quality\n",
    "    mgmt_analysis = calculate_management_quality(symbol)\n",
    "    mgmt_score = mgmt_analysis['total_score']\n",
    "    quality_tier = mgmt_analysis['quality_tier']\n",
    "    \n",
    "    # Step 2: Historical Multiples\n",
    "    multiples = analyze_historical_multiples(symbol)\n",
    "    \n",
    "    # Step 3: Get base case inputs\n",
    "    base_inputs = get_base_case_inputs(symbol)\n",
    "    current_price = base_inputs['current_price']\n",
    "    \n",
    "    # Step 4: Get analyst consensus for probabilities\n",
    "    analyst_data = get_analyst_consensus(symbol)\n",
    "    \n",
    "    # Set probabilities based on analyst consensus\n",
    "    prob_bull = analyst_data['prob_bull']\n",
    "    prob_base = analyst_data['prob_base']\n",
    "    prob_bear = analyst_data['prob_bear']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SCENARIO PROBABILITIES (Based on Analyst Consensus)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if analyst_data['has_data']:\n",
    "        print(f\"Analyst Coverage: {analyst_data['analyst_count']} analysts\")\n",
    "        print(f\"Recommendation Mean: {analyst_data['rec_mean']:.2f} (1=Strong Buy, 5=Sell)\")\n",
    "        print(f\"Consensus: {analyst_data['consensus_label']}\")\n",
    "        \n",
    "        if analyst_data['has_breakdown']:\n",
    "            print(f\"\\nRecommendation Breakdown:\")\n",
    "            print(f\"  Strong Buy: {analyst_data.get('strong_buy', 'N/A')}\")\n",
    "            print(f\"  Buy: {analyst_data.get('buy', 'N/A')}\")\n",
    "            print(f\"  Hold: {analyst_data.get('hold', 'N/A')}\")\n",
    "            print(f\"  Sell: {analyst_data.get('sell', 'N/A')}\")\n",
    "            print(f\"  Strong Sell: {analyst_data.get('strong_sell', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"No analyst data available - using neutral probabilities\")\n",
    "    \n",
    "    print(f\"\\nScenario Probabilities:\")\n",
    "    print(f\"  Bull Case: {prob_bull*100:.0f}%\")\n",
    "    print(f\"  Base Case: {prob_base*100:.0f}%\")\n",
    "    print(f\"  Bear Case: {prob_bear*100:.0f}%\\n\")\n",
    "    \n",
    "    # Step 5: Run scenario DCF with management quality adjustments\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"RUNNING SCENARIO DCF MODELS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Management Quality: {mgmt_analysis['category']} ({quality_tier.upper()})\")\n",
    "    print(\"(Quality affects performance within each scenario)\\n\")\n",
    "    \n",
    "    bull_result = scenario_dcf(symbol, 'bull', base_inputs, quality_tier)\n",
    "    base_result = scenario_dcf(symbol, 'base', base_inputs, quality_tier)\n",
    "    bear_result = scenario_dcf(symbol, 'bear', base_inputs, quality_tier)\n",
    "    \n",
    "    print(\"BULL CASE SCENARIO\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"FCF Growth (Early Years): {bull_result['fcf_growth_early']*100:.1f}%\")\n",
    "    print(f\"FCF Growth (Later Years): {bull_result['fcf_growth_late']*100:.1f}%\")\n",
    "    print(f\"Management Adjustment: {bull_result['mgmt_adjustment']}\")\n",
    "    print(f\"Terminal Growth: {bull_result['terminal_growth']*100:.1f}%\")\n",
    "    print(f\"WACC: {bull_result['wacc']*100:.2f}%\")\n",
    "    print(f\"Beta: {bull_result['beta']:.2f}\")\n",
    "    print(f\"Fair Value: ${bull_result['fair_value']:.2f}\\n\")\n",
    "    \n",
    "    print(\"BASE CASE SCENARIO\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"FCF Growth (Early Years): {base_result['fcf_growth_early']*100:.1f}%\")\n",
    "    print(f\"FCF Growth (Later Years): {base_result['fcf_growth_late']*100:.1f}%\")\n",
    "    print(f\"Management Adjustment: {base_result['mgmt_adjustment']}\")\n",
    "    print(f\"Terminal Growth: {base_result['terminal_growth']*100:.1f}%\")\n",
    "    print(f\"WACC: {base_result['wacc']*100:.2f}%\")\n",
    "    print(f\"Beta: {base_result['beta']:.2f}\")\n",
    "    print(f\"Fair Value: ${base_result['fair_value']:.2f}\\n\")\n",
    "    \n",
    "    print(\"BEAR CASE SCENARIO\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"FCF Growth (Early Years): {bear_result['fcf_growth_early']*100:.1f}%\")\n",
    "    print(f\"FCF Growth (Later Years): {bear_result['fcf_growth_late']*100:.1f}%\")\n",
    "    print(f\"Management Adjustment: {bear_result['mgmt_adjustment']}\")\n",
    "    print(f\"Terminal Growth: {bear_result['terminal_growth']*100:.1f}%\")\n",
    "    print(f\"WACC: {bear_result['wacc']*100:.2f}%\")\n",
    "    print(f\"Beta: {bear_result['beta']:.2f}\")\n",
    "    print(f\"Fair Value: ${bear_result['fair_value']:.2f}\\n\")\n",
    "    \n",
    "    # Step 6: Calculate probability-weighted fair value\n",
    "    weighted_fair_value = (\n",
    "        bull_result['fair_value'] * prob_bull +\n",
    "        base_result['fair_value'] * prob_base +\n",
    "        bear_result['fair_value'] * prob_bear\n",
    "    )\n",
    "    \n",
    "    upside = ((weighted_fair_value - current_price) / current_price) * 100\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"FINAL VALUATION SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    print(f\"\\nScenario Fair Values:\")\n",
    "    print(f\"  Bull Case ({prob_bull*100:.0f}%): ${bull_result['fair_value']:.2f}\")\n",
    "    print(f\"  Base Case ({prob_base*100:.0f}%): ${base_result['fair_value']:.2f}\")\n",
    "    print(f\"  Bear Case ({prob_bear*100:.0f}%): ${bear_result['fair_value']:.2f}\")\n",
    "    print(f\"\\nProbability-Weighted Fair Value: ${weighted_fair_value:.2f}\")\n",
    "    print(f\"Upside/Downside: {upside:+.2f}%\")\n",
    "    \n",
    "    # Investment recommendation\n",
    "    if upside > 25:\n",
    "        recommendation = \"STRONG BUY\"\n",
    "    elif upside > 10:\n",
    "        recommendation = \"BUY\"\n",
    "    elif upside > -10:\n",
    "        recommendation = \"HOLD\"\n",
    "    elif upside > -25:\n",
    "        recommendation = \"SELL\"\n",
    "    else:\n",
    "        recommendation = \"STRONG SELL\"\n",
    "    \n",
    "    print(f\"\\nInvestment Recommendation: {recommendation}\")\n",
    "    \n",
    "    # Risk assessment\n",
    "    value_range = bull_result['fair_value'] - bear_result['fair_value']\n",
    "    risk_level = \"High\" if value_range / weighted_fair_value > 0.5 else \"Moderate\" if value_range / weighted_fair_value > 0.3 else \"Low\"\n",
    "    \n",
    "    print(f\"Risk Level: {risk_level}\")\n",
    "    print(f\"Value Range: ${bear_result['fair_value']:.2f} - ${bull_result['fair_value']:.2f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_data = {\n",
    "        'Metric': [\n",
    "            'Current Price',\n",
    "            'Bull Case Fair Value',\n",
    "            'Base Case Fair Value',\n",
    "            'Bear Case Fair Value',\n",
    "            'Weighted Fair Value',\n",
    "            'Upside/Downside (%)',\n",
    "            'Management Quality Score',\n",
    "            'Recommendation',\n",
    "            'Risk Level'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f\"${current_price:.2f}\",\n",
    "            f\"${bull_result['fair_value']:.2f}\",\n",
    "            f\"${base_result['fair_value']:.2f}\",\n",
    "            f\"${bear_result['fair_value']:.2f}\",\n",
    "            f\"${weighted_fair_value:.2f}\",\n",
    "            f\"{upside:+.2f}%\",\n",
    "            f\"{mgmt_score:.1f}/100 ({quality_tier.upper()})\",\n",
    "            recommendation,\n",
    "            risk_level\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Export to CSV\n",
    "    summary_df.to_csv(f'{symbol}_valuation_summary.csv', index=False)\n",
    "    print(f\"✓ Valuation summary exported to {symbol}_valuation_summary.csv\\n\")\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'current_price': current_price,\n",
    "        'weighted_fair_value': weighted_fair_value,\n",
    "        'upside_pct': upside,\n",
    "        'recommendation': recommendation,\n",
    "        'risk_level': risk_level,\n",
    "        'management_quality': mgmt_analysis,\n",
    "        'bull_case': bull_result,\n",
    "        'base_case': base_result,\n",
    "        'bear_case': bear_result,\n",
    "        'probabilities': {\n",
    "            'bull': prob_bull,\n",
    "            'base': prob_base,\n",
    "            'bear': prob_bear\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"GOOG\"\n",
    "    \n",
    "    # Run comprehensive valuation\n",
    "    results = probability_weighted_valuation(symbol)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nKey Takeaways:\")\n",
    "    print(f\"- Management Quality: {results['management_quality']['category']}\")\n",
    "    print(f\"- Weighted Fair Value: ${results['weighted_fair_value']:.2f}\")\n",
    "    print(f\"- Expected Return: {results['upside_pct']:+.1f}%\")\n",
    "    print(f\"- Recommendation: {results['recommendation']}\")\n",
    "    print(f\"- Risk Level: {results['risk_level']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8770d786-886b-4f9d-ab89-eb023e46cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE PEER ANALYSIS FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SELECTING PEER COMPANIES FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "Target Company: GOOG\n",
      "Sector: Communication Services\n",
      "Industry: Internet Content & Information\n",
      "Market Cap: $4,086,677,897,216\n",
      "\n",
      "Screening 9 candidates in Communication Services sector...\n",
      "\n",
      "Selected 2 peer companies:\n",
      "--------------------------------------------------------------------------------\n",
      "  GOOGL: Market Cap $4,093,897,080,832 (1.00x)\n",
      "  META: Market Cap $1,812,426,522,624 (0.44x)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COLLECTING PEER FINANCIAL DATA\n",
      "================================================================================\n",
      "\n",
      "Fetching data for GOOG...\n",
      "Fetching data for GOOGL...\n",
      "Fetching data for META...\n",
      "\n",
      "✓ Successfully collected data for 3 companies\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PERCENTILE RANKINGS FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "Metric                    Value        Percentile   Interpretation\n",
      "--------------------------------------------------------------------------------\n",
      "Revenue Growth (%)            336.71        83.3%  Better\n",
      "Net Margin (%)                 32.23        83.3%  Better\n",
      "EBITDA Margin (%)              44.55        50.0%  Average\n",
      "ROE (%)                        32.12        83.3%  Better\n",
      "ROA (%)                        23.16        83.3%  Better\n",
      "FCF Yield (%)                   1.80        66.7%  Average\n",
      "P/E                            33.45         0.0%  Expensive\n",
      "P/B                            10.56        33.3%  Fair\n",
      "P/S                            10.60        33.3%  Fair\n",
      "EV/EBITDA                      23.86        33.3%  Fair\n",
      "PEG                             0.10         0.0%  Expensive\n",
      "\n",
      "\n",
      "================================================================================\n",
      "REGRESSION-BASED FAIR VALUE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. P/E Multiple Valuation\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Peer Average P/E Method (Regression insufficient data)\n",
      "  Peer Average P/E: 31.96\n",
      "  Implied Price: $328.96\n",
      "  Current Price: $338.53\n",
      "  Upside: -2.8%\n",
      "\n",
      "2. EV/EBITDA Multiple Valuation\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Peer Average EV/EBITDA Method (Regression insufficient data)\n",
      "  Peer Average EV/EBITDA: 20.75\n",
      "  Implied Price: $294.31\n",
      "  Current Price: $338.53\n",
      "  Upside: -13.1%\n",
      "\n",
      "================================================================================\n",
      "COMBINED FAIR VALUE\n",
      "================================================================================\n",
      "P/E Model Fair Price: $328.96\n",
      "EV/EBITDA Model Fair Price: $294.31\n",
      "Average Fair Price: $311.64\n",
      "Current Price: $338.53\n",
      "Implied Upside/Downside: -7.9%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PEER COMPARISON TABLE\n",
      "================================================================================\n",
      "\n",
      "      Symbol Market Cap   P/E   P/B  EV/EBITDA  PEG  Revenue Growth (%)  Net Margin (%)  ROE (%)  FCF Yield (%)\n",
      ">>> GOOG <<<   $4086.7B 33.45 10.56      23.86 0.10              336.71           32.23    32.12           1.80\n",
      "       GOOGL   $4093.9B 33.43 10.58      23.90 0.10              336.71           32.23    32.12           1.80\n",
      "        META   $1812.4B 30.49  8.34      17.60 0.10              315.35           30.08    27.83           2.54\n",
      "\n",
      "✓ Peer analysis exported to GOOG_peer_analysis.csv\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PEER ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Key Findings:\n",
      "- Analyzed 2 peer companies\n",
      "\n",
      "========================================\n",
      "FINAL PREDICTED STOCK PRICE\n",
      "========================================\n",
      "\n",
      "  Stock Symbol: GOOG\n",
      "  Current Price: $338.53\n",
      "  PREDICTED PRICE: $311.64\n",
      "  Expected Return: -7.9%\n",
      "  💡 Recommendation: REDUCE\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# PART 1: SMART PEER SELECTION\n",
    "# ============================================================\n",
    "\n",
    "def get_peer_companies(symbol, sector=None, max_peers=15):\n",
    "    \"\"\"\n",
    "    Intelligently select peer companies based on:\n",
    "    - Same sector/industry\n",
    "    - Similar market cap (within 0.3x - 3x range)\n",
    "    - Similar growth profile\n",
    "    - Excludes target company\n",
    "    \n",
    "    Returns: List of peer ticker symbols\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SELECTING PEER COMPANIES FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    ticker = yf.Ticker(symbol)\n",
    "    info = ticker.info\n",
    "    \n",
    "    # Get target company info\n",
    "    target_sector = info.get('sector', sector)\n",
    "    target_industry = info.get('industry')\n",
    "    target_market_cap = info.get('marketCap', 0)\n",
    "    \n",
    "    print(f\"Target Company: {symbol}\")\n",
    "    print(f\"Sector: {target_sector}\")\n",
    "    print(f\"Industry: {target_industry}\")\n",
    "    print(f\"Market Cap: ${target_market_cap:,.0f}\\n\")\n",
    "    \n",
    "    # Define peer candidates by sector\n",
    "    sector_peers = {\n",
    "        'Technology': ['AAPL', 'MSFT', 'GOOGL', 'META', 'NVDA', 'ORCL', 'CSCO', 'ADBE', 'CRM', 'INTC', \n",
    "                       'AMD', 'QCOM', 'TXN', 'AVGO', 'NOW', 'INTU', 'IBM', 'SNOW', 'PANW', 'CRWD'],\n",
    "        'Communication Services': ['GOOGL', 'META', 'NFLX', 'DIS', 'CMCSA', 'T', 'VZ', 'TMUS', 'CHTR'],\n",
    "        'Consumer Cyclical': ['AMZN', 'TSLA', 'HD', 'MCD', 'NKE', 'SBUX', 'TGT', 'LOW', 'TJX', 'BKNG'],\n",
    "        'Consumer Defensive': ['WMT', 'PG', 'KO', 'PEP', 'COST', 'PM', 'MO', 'MDLZ', 'CL', 'KHC'],\n",
    "        'Healthcare': ['UNH', 'JNJ', 'LLY', 'ABBV', 'MRK', 'PFE', 'TMO', 'ABT', 'DHR', 'CVS', 'AMGN'],\n",
    "        'Financial Services': ['BRK-B', 'JPM', 'V', 'MA', 'BAC', 'WFC', 'MS', 'GS', 'SPGI', 'BLK', 'C'],\n",
    "        'Industrials': ['BA', 'UNP', 'HON', 'UPS', 'RTX', 'CAT', 'LMT', 'DE', 'GE', 'MMM'],\n",
    "        'Energy': ['XOM', 'CVX', 'COP', 'SLB', 'EOG', 'MPC', 'PSX', 'VLO', 'OXY', 'HAL'],\n",
    "        'Basic Materials': ['LIN', 'APD', 'SHW', 'ECL', 'DD', 'NEM', 'FCX', 'NUE'],\n",
    "        'Real Estate': ['AMT', 'PLD', 'CCI', 'EQIX', 'PSA', 'SPG', 'WELL', 'DLR', 'O', 'VICI'],\n",
    "        'Utilities': ['NEE', 'DUK', 'SO', 'D', 'AEP', 'EXC', 'SRE', 'PCG', 'XEL']\n",
    "    }\n",
    "    \n",
    "    # Get candidate list\n",
    "    candidates = sector_peers.get(target_sector, [])\n",
    "    \n",
    "    if not candidates:\n",
    "        print(f\"Warning: No predefined peers for sector '{target_sector}'\")\n",
    "        print(\"Using manual peer list or defaulting to similar companies\\n\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Screening {len(candidates)} candidates in {target_sector} sector...\")\n",
    "    \n",
    "    # Filter peers based on criteria\n",
    "    valid_peers = []\n",
    "    peer_data = []\n",
    "    \n",
    "    for peer_symbol in candidates:\n",
    "        if peer_symbol == symbol:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            peer = yf.Ticker(peer_symbol)\n",
    "            peer_info = peer.info\n",
    "            \n",
    "            peer_mc = peer_info.get('marketCap', 0)\n",
    "            \n",
    "            # Skip if no market cap data\n",
    "            if not peer_mc or peer_mc == 0:\n",
    "                continue\n",
    "            \n",
    "            # RELAXED Market cap filter: within 0.1x to 10x of target (was 0.3x to 3x)\n",
    "            mc_ratio = peer_mc / target_market_cap if target_market_cap > 0 else 0\n",
    "            \n",
    "            if 0.1 <= mc_ratio <= 10.0:\n",
    "                valid_peers.append(peer_symbol)\n",
    "                peer_data.append({\n",
    "                    'symbol': peer_symbol,\n",
    "                    'market_cap': peer_mc,\n",
    "                    'mc_ratio': mc_ratio\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Sort by market cap similarity and take top N\n",
    "    peer_data_df = pd.DataFrame(peer_data)\n",
    "    if not peer_data_df.empty:\n",
    "        peer_data_df['mc_distance'] = abs(peer_data_df['mc_ratio'] - 1.0)\n",
    "        peer_data_df = peer_data_df.sort_values('mc_distance').head(max_peers)\n",
    "        valid_peers = peer_data_df['symbol'].tolist()\n",
    "    \n",
    "    print(f\"\\nSelected {len(valid_peers)} peer companies:\")\n",
    "    print(\"-\" * 80)\n",
    "    for peer_symbol in valid_peers:\n",
    "        peer_info = next(p for p in peer_data if p['symbol'] == peer_symbol)\n",
    "        print(f\"  {peer_symbol}: Market Cap ${peer_info['market_cap']:,.0f} ({peer_info['mc_ratio']:.2f}x)\")\n",
    "    print()\n",
    "    \n",
    "    return valid_peers\n",
    "\n",
    "# ============================================================\n",
    "# PART 2: COLLECT PEER FINANCIAL DATA\n",
    "# ============================================================\n",
    "\n",
    "def collect_peer_data(symbol, peer_list):\n",
    "    \"\"\"\n",
    "    Collect financial metrics for target company and peers\n",
    "    \n",
    "    Returns: DataFrame with all companies and their metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COLLECTING PEER FINANCIAL DATA\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    all_companies = [symbol] + peer_list\n",
    "    data_list = []\n",
    "    \n",
    "    for ticker_symbol in all_companies:\n",
    "        try:\n",
    "            print(f\"Fetching data for {ticker_symbol}...\")\n",
    "            ticker = yf.Ticker(ticker_symbol)\n",
    "            info = ticker.info\n",
    "            \n",
    "            # Get financial statements\n",
    "            try:\n",
    "                cf_df = ticker.quarterly_cashflow.T.sort_index()\n",
    "                bs_df = ticker.quarterly_balance_sheet.T.sort_index()\n",
    "                is_df = ticker.quarterly_financials.T.sort_index()\n",
    "            except:\n",
    "                print(f\"  Warning: Could not fetch financial statements for {ticker_symbol}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate TTM metrics\n",
    "            revenue_list = []\n",
    "            for i in range(min(4, len(is_df))):\n",
    "                rev = is_df.iloc[-(i+1)].get('Total Revenue')\n",
    "                if pd.notna(rev):\n",
    "                    revenue_list.append(rev)\n",
    "            ttm_revenue = sum(revenue_list) if revenue_list else None\n",
    "            \n",
    "            ni_list = []\n",
    "            for i in range(min(4, len(is_df))):\n",
    "                ni = is_df.iloc[-(i+1)].get('Net Income')\n",
    "                if pd.notna(ni):\n",
    "                    ni_list.append(ni)\n",
    "            ttm_net_income = sum(ni_list) if ni_list else None\n",
    "            \n",
    "            ebitda_list = []\n",
    "            for i in range(min(4, len(is_df))):\n",
    "                ebitda = is_df.iloc[-(i+1)].get('EBITDA')\n",
    "                if pd.notna(ebitda):\n",
    "                    ebitda_list.append(ebitda)\n",
    "            ttm_ebitda = sum(ebitda_list) if ebitda_list else None\n",
    "            \n",
    "            fcf_list = []\n",
    "            for i in range(min(4, len(cf_df))):\n",
    "                ocf = cf_df.iloc[-(i+1)].get('Operating Cash Flow')\n",
    "                capex = cf_df.iloc[-(i+1)].get('Capital Expenditure', 0)\n",
    "                if pd.notna(ocf):\n",
    "                    fcf = ocf - abs(capex if pd.notna(capex) else 0)\n",
    "                    fcf_list.append(fcf)\n",
    "            ttm_fcf = sum(fcf_list) if fcf_list else None\n",
    "            \n",
    "            # Balance Sheet metrics\n",
    "            total_equity = bs_df.iloc[-1].get('Stockholders Equity')\n",
    "            total_assets = bs_df.iloc[-1].get('Total Assets')\n",
    "            total_debt = bs_df.iloc[-1].get('Total Debt', 0)\n",
    "            cash = bs_df.iloc[-1].get('Cash And Cash Equivalents', 0)\n",
    "            \n",
    "            # Calculate growth rates (YoY)\n",
    "            revenue_growth = None\n",
    "            if len(revenue_list) >= 4:\n",
    "                recent_rev = sum(revenue_list[:4])\n",
    "                try:\n",
    "                    old_revenue_list = []\n",
    "                    for i in range(4, min(8, len(is_df))):\n",
    "                        old_rev = is_df.iloc[-(i+1)].get('Total Revenue')\n",
    "                        if pd.notna(old_rev):\n",
    "                            old_revenue_list.append(old_rev)\n",
    "                    \n",
    "                    if old_revenue_list:\n",
    "                        old_rev = sum(old_revenue_list[:4])\n",
    "                        revenue_growth = ((recent_rev - old_rev) / old_rev * 100) if old_rev else None\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Get market data\n",
    "            market_cap = info.get('marketCap')\n",
    "            current_price = info.get('currentPrice') or info.get('regularMarketPrice')\n",
    "            shares_outstanding = info.get('sharesOutstanding')\n",
    "            beta = info.get('beta')\n",
    "            \n",
    "            # Calculate valuation ratios\n",
    "            pe_ratio = info.get('trailingPE')\n",
    "            pb_ratio = market_cap / total_equity if (market_cap and total_equity and total_equity > 0) else None\n",
    "            ps_ratio = market_cap / ttm_revenue if (market_cap and ttm_revenue and ttm_revenue > 0) else None\n",
    "            \n",
    "            # EV/EBITDA\n",
    "            enterprise_value = market_cap + total_debt - cash if market_cap else None\n",
    "            ev_ebitda = enterprise_value / ttm_ebitda if (enterprise_value and ttm_ebitda and ttm_ebitda > 0) else None\n",
    "            \n",
    "            # PEG ratio\n",
    "            peg_ratio = pe_ratio / revenue_growth if (pe_ratio and revenue_growth and revenue_growth > 0) else None\n",
    "            \n",
    "            # Profitability metrics\n",
    "            net_margin = (ttm_net_income / ttm_revenue * 100) if (ttm_net_income and ttm_revenue and ttm_revenue > 0) else None\n",
    "            ebitda_margin = (ttm_ebitda / ttm_revenue * 100) if (ttm_ebitda and ttm_revenue and ttm_revenue > 0) else None\n",
    "            roe = (ttm_net_income / total_equity * 100) if (ttm_net_income and total_equity and total_equity > 0) else None\n",
    "            roa = (ttm_net_income / total_assets * 100) if (ttm_net_income and total_assets and total_assets > 0) else None\n",
    "            \n",
    "            # FCF Yield\n",
    "            fcf_yield = (ttm_fcf / market_cap * 100) if (ttm_fcf and market_cap and market_cap > 0) else None\n",
    "            \n",
    "            # Compile data\n",
    "            company_data = {\n",
    "                'Symbol': ticker_symbol,\n",
    "                'Market Cap': market_cap,\n",
    "                'Price': current_price,\n",
    "                'Revenue (TTM)': ttm_revenue,\n",
    "                'Net Income (TTM)': ttm_net_income,\n",
    "                'EBITDA (TTM)': ttm_ebitda,\n",
    "                'FCF (TTM)': ttm_fcf,\n",
    "                'Total Equity': total_equity,\n",
    "                'Total Debt': total_debt,\n",
    "                'Beta': beta,\n",
    "                'P/E': pe_ratio,\n",
    "                'P/B': pb_ratio,\n",
    "                'P/S': ps_ratio,\n",
    "                'EV/EBITDA': ev_ebitda,\n",
    "                'PEG': peg_ratio,\n",
    "                'Revenue Growth (%)': revenue_growth,\n",
    "                'Net Margin (%)': net_margin,\n",
    "                'EBITDA Margin (%)': ebitda_margin,\n",
    "                'ROE (%)': roe,\n",
    "                'ROA (%)': roa,\n",
    "                'FCF Yield (%)': fcf_yield\n",
    "            }\n",
    "            \n",
    "            data_list.append(company_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {ticker_symbol}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    peer_df = pd.DataFrame(data_list)\n",
    "    \n",
    "    print(f\"\\n✓ Successfully collected data for {len(peer_df)} companies\\n\")\n",
    "    \n",
    "    return peer_df\n",
    "\n",
    "# ============================================================\n",
    "# PART 3: PERCENTILE RANKINGS\n",
    "# ============================================================\n",
    "\n",
    "def calculate_percentile_rankings(peer_df, target_symbol):\n",
    "    \"\"\"\n",
    "    Calculate where the target company ranks vs peers on key metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PERCENTILE RANKINGS FOR {target_symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    target_data = peer_df[peer_df['Symbol'] == target_symbol].iloc[0]\n",
    "    \n",
    "    # Metrics where HIGHER is better\n",
    "    higher_is_better = ['Revenue Growth (%)', 'Net Margin (%)', 'EBITDA Margin (%)', \n",
    "                        'ROE (%)', 'ROA (%)', 'FCF Yield (%)']\n",
    "    \n",
    "    # Metrics where LOWER is better (valuation multiples)\n",
    "    lower_is_better = ['P/E', 'P/B', 'P/S', 'EV/EBITDA', 'PEG']\n",
    "    \n",
    "    rankings = {}\n",
    "    \n",
    "    print(f\"{'Metric':<25} {'Value':<12} {'Percentile':<12} {'Interpretation'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in higher_is_better + lower_is_better:\n",
    "        if metric not in peer_df.columns:\n",
    "            continue\n",
    "            \n",
    "        target_value = target_data[metric]\n",
    "        \n",
    "        if pd.isna(target_value):\n",
    "            continue\n",
    "        \n",
    "        # Calculate percentile\n",
    "        valid_values = peer_df[metric].dropna()\n",
    "        \n",
    "        if len(valid_values) < 2:\n",
    "            continue\n",
    "        \n",
    "        if metric in higher_is_better:\n",
    "            percentile = stats.percentileofscore(valid_values, target_value, kind='rank')\n",
    "            interpretation = \"Better\" if percentile >= 75 else \"Worse\" if percentile <= 25 else \"Average\"\n",
    "        else:\n",
    "            percentile = 100 - stats.percentileofscore(valid_values, target_value, kind='rank')\n",
    "            interpretation = \"Attractive\" if percentile >= 75 else \"Expensive\" if percentile <= 25 else \"Fair\"\n",
    "        \n",
    "        rankings[metric] = {\n",
    "            'value': target_value,\n",
    "            'percentile': percentile,\n",
    "            'interpretation': interpretation\n",
    "        }\n",
    "        \n",
    "        print(f\"{metric:<25} {target_value:>10.2f}  {percentile:>10.1f}%  {interpretation}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "# ============================================================\n",
    "# PART 4: IMPROVED REGRESSION-BASED VALUATION\n",
    "# ============================================================\n",
    "\n",
    "def regression_based_valuation(peer_df, target_symbol):\n",
    "    \"\"\"\n",
    "    Use regression to predict fair P/E and EV/EBITDA based on fundamentals\n",
    "    IMPROVED: Falls back to simpler models and peer averages if insufficient data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"REGRESSION-BASED FAIR VALUE ANALYSIS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    target_data = peer_df[peer_df['Symbol'] == target_symbol].iloc[0]\n",
    "    current_price = target_data['Price']\n",
    "    \n",
    "    # ============ P/E Model ============\n",
    "    print(\"1. P/E Multiple Valuation\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Try full regression first\n",
    "    pe_data = peer_df[peer_df['Symbol'] != target_symbol].copy()\n",
    "    pe_data = pe_data.dropna(subset=['P/E', 'ROE (%)', 'Revenue Growth (%)', 'Beta'])\n",
    "    \n",
    "    predicted_price_pe = None\n",
    "    \n",
    "    if len(pe_data) >= 3:  # REDUCED from 5 to 3\n",
    "        try:\n",
    "            X = pe_data[['ROE (%)', 'Revenue Growth (%)', 'Beta']].values\n",
    "            y = pe_data['P/E'].values\n",
    "            \n",
    "            model_pe = LinearRegression()\n",
    "            model_pe.fit(X, y)\n",
    "            \n",
    "            if pd.notna(target_data['ROE (%)']) and pd.notna(target_data['Revenue Growth (%)']) and pd.notna(target_data['Beta']):\n",
    "                X_target = np.array([[\n",
    "                    target_data['ROE (%)'],\n",
    "                    target_data['Revenue Growth (%)'],\n",
    "                    target_data['Beta']\n",
    "                ]])\n",
    "                \n",
    "                predicted_pe = model_pe.predict(X_target)[0]\n",
    "                actual_pe = target_data['P/E']\n",
    "                \n",
    "                # Calculate implied price\n",
    "                ttm_eps = target_data['Net Income (TTM)'] / (target_data['Market Cap'] / target_data['Price'])\n",
    "                predicted_price_pe = predicted_pe * ttm_eps\n",
    "                \n",
    "                print(f\"✓ Regression Model (3 variables)\")\n",
    "                print(f\"  P/E = {model_pe.intercept_:.2f} + {model_pe.coef_[0]:.3f}*ROE + {model_pe.coef_[1]:.3f}*Growth + {model_pe.coef_[2]:.3f}*Beta\")\n",
    "                print(f\"  Predicted P/E: {predicted_pe:.2f}\")\n",
    "                print(f\"  Actual P/E: {actual_pe:.2f}\")\n",
    "                print(f\"  Implied Price: ${predicted_price_pe:.2f}\")\n",
    "                print(f\"  Current Price: ${current_price:.2f}\")\n",
    "                print(f\"  Upside: {((predicted_price_pe - current_price) / current_price * 100):+.1f}%\\n\")\n",
    "                \n",
    "                results['pe_model'] = {\n",
    "                    'predicted_pe': predicted_pe,\n",
    "                    'actual_pe': actual_pe,\n",
    "                    'implied_price': predicted_price_pe,\n",
    "                    'current_price': current_price\n",
    "                }\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # FALLBACK 1: Use peer average P/E if regression failed\n",
    "    if predicted_price_pe is None:\n",
    "        peer_pe_avg = peer_df[peer_df['Symbol'] != target_symbol]['P/E'].mean()\n",
    "        if pd.notna(peer_pe_avg) and pd.notna(target_data['Net Income (TTM)']):\n",
    "            ttm_eps = target_data['Net Income (TTM)'] / (target_data['Market Cap'] / target_data['Price'])\n",
    "            predicted_price_pe = peer_pe_avg * ttm_eps\n",
    "            \n",
    "            print(f\"✓ Peer Average P/E Method (Regression insufficient data)\")\n",
    "            print(f\"  Peer Average P/E: {peer_pe_avg:.2f}\")\n",
    "            print(f\"  Implied Price: ${predicted_price_pe:.2f}\")\n",
    "            print(f\"  Current Price: ${current_price:.2f}\")\n",
    "            print(f\"  Upside: {((predicted_price_pe - current_price) / current_price * 100):+.1f}%\\n\")\n",
    "            \n",
    "            results['pe_model'] = {\n",
    "                'predicted_pe': peer_pe_avg,\n",
    "                'actual_pe': target_data['P/E'],\n",
    "                'implied_price': predicted_price_pe,\n",
    "                'current_price': current_price,\n",
    "                'method': 'peer_average'\n",
    "            }\n",
    "    \n",
    "    # ============ EV/EBITDA Model ============\n",
    "    print(\"2. EV/EBITDA Multiple Valuation\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    ev_data = peer_df[peer_df['Symbol'] != target_symbol].copy()\n",
    "    ev_data = ev_data.dropna(subset=['EV/EBITDA', 'EBITDA Margin (%)', 'Revenue Growth (%)', 'ROE (%)'])\n",
    "    \n",
    "    predicted_price_ev = None\n",
    "    \n",
    "    if len(ev_data) >= 3:  # REDUCED from 5 to 3\n",
    "        try:\n",
    "            X = ev_data[['EBITDA Margin (%)', 'Revenue Growth (%)', 'ROE (%)']].values\n",
    "            y = ev_data['EV/EBITDA'].values\n",
    "            \n",
    "            model_ev = LinearRegression()\n",
    "            model_ev.fit(X, y)\n",
    "            \n",
    "            if pd.notna(target_data['EBITDA Margin (%)']) and pd.notna(target_data['Revenue Growth (%)']) and pd.notna(target_data['ROE (%)']):\n",
    "                X_target = np.array([[\n",
    "                    target_data['EBITDA Margin (%)'],\n",
    "                    target_data['Revenue Growth (%)'],\n",
    "                    target_data['ROE (%)']\n",
    "                ]])\n",
    "                \n",
    "                predicted_ev_ebitda = model_ev.predict(X_target)[0]\n",
    "                actual_ev_ebitda = target_data['EV/EBITDA']\n",
    "                \n",
    "                # Calculate implied price\n",
    "                implied_ev = predicted_ev_ebitda * target_data['EBITDA (TTM)']\n",
    "                \n",
    "                ticker = yf.Ticker(target_symbol)\n",
    "                bs_df = ticker.quarterly_balance_sheet.T.sort_index()\n",
    "                total_debt = bs_df.iloc[-1].get('Total Debt', 0) or 0\n",
    "                cash = bs_df.iloc[-1].get('Cash And Cash Equivalents', 0) or 0\n",
    "                \n",
    "                implied_equity_value = implied_ev - total_debt + cash\n",
    "                shares = target_data['Market Cap'] / target_data['Price']\n",
    "                predicted_price_ev = implied_equity_value / shares\n",
    "                \n",
    "                print(f\"✓ Regression Model (3 variables)\")\n",
    "                print(f\"  EV/EBITDA = {model_ev.intercept_:.2f} + {model_ev.coef_[0]:.3f}*EBITDA_Margin + {model_ev.coef_[1]:.3f}*Growth + {model_ev.coef_[2]:.3f}*ROE\")\n",
    "                print(f\"  Predicted EV/EBITDA: {predicted_ev_ebitda:.2f}\")\n",
    "                print(f\"  Actual EV/EBITDA: {actual_ev_ebitda:.2f}\")\n",
    "                print(f\"  Implied Price: ${predicted_price_ev:.2f}\")\n",
    "                print(f\"  Current Price: ${current_price:.2f}\")\n",
    "                print(f\"  Upside: {((predicted_price_ev - current_price) / current_price * 100):+.1f}%\\n\")\n",
    "                \n",
    "                results['ev_model'] = {\n",
    "                    'predicted_ev_ebitda': predicted_ev_ebitda,\n",
    "                    'actual_ev_ebitda': actual_ev_ebitda,\n",
    "                    'implied_price': predicted_price_ev,\n",
    "                    'current_price': current_price\n",
    "                }\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # FALLBACK 2: Use peer average EV/EBITDA\n",
    "    if predicted_price_ev is None:\n",
    "        peer_ev_avg = peer_df[peer_df['Symbol'] != target_symbol]['EV/EBITDA'].mean()\n",
    "        if pd.notna(peer_ev_avg) and pd.notna(target_data['EBITDA (TTM)']):\n",
    "            implied_ev = peer_ev_avg * target_data['EBITDA (TTM)']\n",
    "            \n",
    "            ticker = yf.Ticker(target_symbol)\n",
    "            bs_df = ticker.quarterly_balance_sheet.T.sort_index()\n",
    "            total_debt = bs_df.iloc[-1].get('Total Debt', 0) or 0\n",
    "            cash = bs_df.iloc[-1].get('Cash And Cash Equivalents', 0) or 0\n",
    "            \n",
    "            implied_equity_value = implied_ev - total_debt + cash\n",
    "            shares = target_data['Market Cap'] / target_data['Price']\n",
    "            predicted_price_ev = implied_equity_value / shares\n",
    "            \n",
    "            print(f\"✓ Peer Average EV/EBITDA Method (Regression insufficient data)\")\n",
    "            print(f\"  Peer Average EV/EBITDA: {peer_ev_avg:.2f}\")\n",
    "            print(f\"  Implied Price: ${predicted_price_ev:.2f}\")\n",
    "            print(f\"  Current Price: ${current_price:.2f}\")\n",
    "            print(f\"  Upside: {((predicted_price_ev - current_price) / current_price * 100):+.1f}%\\n\")\n",
    "            \n",
    "            results['ev_model'] = {\n",
    "                'predicted_ev_ebitda': peer_ev_avg,\n",
    "                'actual_ev_ebitda': target_data['EV/EBITDA'],\n",
    "                'implied_price': predicted_price_ev,\n",
    "                'current_price': current_price,\n",
    "                'method': 'peer_average'\n",
    "            }\n",
    "    \n",
    "    # ============ Combined Fair Value ============\n",
    "    prices = []\n",
    "    if 'pe_model' in results:\n",
    "        prices.append(results['pe_model']['implied_price'])\n",
    "    if 'ev_model' in results:\n",
    "        prices.append(results['ev_model']['implied_price'])\n",
    "    \n",
    "    if prices:\n",
    "        avg_implied_price = np.mean(prices)\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"COMBINED FAIR VALUE\")\n",
    "        print(\"=\"*80)\n",
    "        if 'pe_model' in results:\n",
    "            print(f\"P/E Model Fair Price: ${results['pe_model']['implied_price']:.2f}\")\n",
    "        if 'ev_model' in results:\n",
    "            print(f\"EV/EBITDA Model Fair Price: ${results['ev_model']['implied_price']:.2f}\")\n",
    "        print(f\"Average Fair Price: ${avg_implied_price:.2f}\")\n",
    "        print(f\"Current Price: ${current_price:.2f}\")\n",
    "        print(f\"Implied Upside/Downside: {((avg_implied_price - current_price) / current_price * 100):+.1f}%\\n\")\n",
    "        \n",
    "        results['combined_fair_price'] = avg_implied_price\n",
    "    else:\n",
    "        print(\"⚠️ Could not calculate valuation models - insufficient peer data\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============================================================\n",
    "# PART 5: COMPREHENSIVE PEER ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "def comprehensive_peer_analysis(symbol, peer_list=None, max_peers=15):\n",
    "    \"\"\"\n",
    "    Complete peer analysis framework\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMPREHENSIVE PEER ANALYSIS FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Step 1: Select peers if not provided\n",
    "    if peer_list is None:\n",
    "        peer_list = get_peer_companies(symbol, max_peers=max_peers)\n",
    "    \n",
    "    if not peer_list:\n",
    "        print(\"Error: No valid peer companies found\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Collect data\n",
    "    peer_df = collect_peer_data(symbol, peer_list)\n",
    "    \n",
    "    if peer_df.empty or len(peer_df) < 2:\n",
    "        print(\"Error: Insufficient peer data collected\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Percentile rankings\n",
    "    rankings = calculate_percentile_rankings(peer_df, symbol)\n",
    "    \n",
    "    # Step 4: Regression-based valuation\n",
    "    regression_results = regression_based_valuation(peer_df, symbol)\n",
    "    \n",
    "    # Step 5: Summary comparison table\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PEER COMPARISON TABLE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    display_cols = ['Symbol', 'Market Cap', 'P/E', 'P/B', 'EV/EBITDA', 'PEG',\n",
    "                    'Revenue Growth (%)', 'Net Margin (%)', 'ROE (%)', 'FCF Yield (%)']\n",
    "    \n",
    "    display_df = peer_df[display_cols].copy()\n",
    "    display_df['Market Cap'] = display_df['Market Cap'].apply(lambda x: f\"${x/1e9:.1f}B\" if pd.notna(x) else \"N/A\")\n",
    "    display_df['Symbol'] = display_df['Symbol'].apply(lambda x: f\">>> {x} <<<\" if x == symbol else x)\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # Export to CSV\n",
    "    peer_df.to_csv(f'{symbol}_peer_analysis.csv', index=False)\n",
    "    print(f\"✓ Peer analysis exported to {symbol}_peer_analysis.csv\\n\")\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'peer_data': peer_df,\n",
    "        'rankings': rankings,\n",
    "        'regression_results': regression_results,\n",
    "        'peer_list': peer_list\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"GOOG\"\n",
    "    \n",
    "    # Run analysis\n",
    "    results = comprehensive_peer_analysis(symbol, max_peers=15)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PEER ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nKey Findings:\")\n",
    "        print(f\"- Analyzed {len(results['peer_list'])} peer companies\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # FINAL PREDICTED STOCK PRICE\n",
    "        # ============================================================\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(\"FINAL PREDICTED STOCK PRICE\")\n",
    "        print(\"=\" * 40 + \"\\n\")\n",
    "        \n",
    "        current_price = results['regression_results'].get('pe_model', {}).get('current_price')\n",
    "        \n",
    "        if 'combined_fair_price' in results['regression_results']:\n",
    "            predicted_price = results['regression_results']['combined_fair_price']\n",
    "            upside = ((predicted_price - current_price) / current_price * 100) if current_price else 0\n",
    "            \n",
    "            print(f\"  Stock Symbol: {symbol}\")\n",
    "            print(f\"  Current Price: ${current_price:.2f}\")\n",
    "            print(f\"  PREDICTED PRICE: ${predicted_price:.2f}\")\n",
    "            print(f\"  Expected Return: {upside:+.1f}%\")\n",
    "            \n",
    "            if upside > 15:\n",
    "                print(f\"  💡 Recommendation: STRONG BUY\")\n",
    "            elif upside > 5:\n",
    "                print(f\"  💡 Recommendation: BUY\")\n",
    "            elif upside > -5:\n",
    "                print(f\"  💡 Recommendation: HOLD\")\n",
    "            elif upside > -15:\n",
    "                print(f\"  💡 Recommendation: REDUCE\")\n",
    "            else:\n",
    "                print(f\"  💡 Recommendation: SELL\")\n",
    "                \n",
    "        elif 'pe_model' in results['regression_results']:\n",
    "            predicted_price = results['regression_results']['pe_model']['implied_price']\n",
    "            upside = ((predicted_price - current_price) / current_price * 100) if current_price else 0\n",
    "            \n",
    "            print(f\"  Stock Symbol: {symbol}\")\n",
    "            print(f\"  Current Price: ${current_price:.2f}\")\n",
    "            print(f\"  PREDICTED PRICE: ${predicted_price:.2f}\")\n",
    "            print(f\"  Expected Return: {upside:+.1f}%\")\n",
    "            print(f\"  (Based on P/E model only)\")\n",
    "            \n",
    "        elif 'ev_model' in results['regression_results']:\n",
    "            predicted_price = results['regression_results']['ev_model']['implied_price']\n",
    "            upside = ((predicted_price - current_price) / current_price * 100) if current_price else 0\n",
    "            \n",
    "            print(f\"  Stock Symbol: {symbol}\")\n",
    "            print(f\"  Current Price: ${current_price:.2f}\")\n",
    "            print(f\"  PREDICTED PRICE: ${predicted_price:.2f}\")\n",
    "            print(f\"  Expected Return: {upside:+.1f}%\")\n",
    "            print(f\"  (Based on EV/EBITDA model only)\")\n",
    "        else:\n",
    "            print(f\"  ⚠️ Unable to calculate predicted price\")\n",
    "            print(f\"  Try adding more peer companies or checking data availability\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c88255ed-f8a9-468d-b794-21e4b8a29ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic\n",
      "  Downloading anthropic-0.77.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (2.12.5)\n",
      "Requirement already satisfied: sniffio in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in g:\\anaconda\\anaconda\\lib\\site-packages (from anthropic) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in g:\\anaconda\\anaconda\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in g:\\anaconda\\anaconda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in g:\\anaconda\\anaconda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in g:\\anaconda\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
      "Downloading anthropic-0.77.0-py3-none-any.whl (397 kB)\n",
      "   ---------------------------------------- 0.0/397.9 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/397.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 174.1/397.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 256.0/397.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 348.2/397.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 397.9/397.9 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: docstring-parser, anthropic\n",
      "Successfully installed anthropic-0.77.0 docstring-parser-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import anthropic\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# ============================================================\n",
    "# CATALYST ANALYSIS FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def get_recent_news(symbol: str, months_back: int = 3) -> List[Dict]:\n",
    "    \"\"\"Fetch recent news for a stock symbol.\"\"\"\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        news = ticker.news\n",
    "        \n",
    "        if not news:\n",
    "            print(f\"⚠️  No news found for {symbol}\")\n",
    "            return []\n",
    "        \n",
    "        cutoff_date = datetime.now() - timedelta(days=months_back * 30)\n",
    "        filtered_news = []\n",
    "        \n",
    "        for article in news[:50]:\n",
    "            try:\n",
    "                pub_date = datetime.fromtimestamp(article.get('providerPublishTime', 0))\n",
    "                if pub_date >= cutoff_date:\n",
    "                    filtered_news.append({\n",
    "                        'title': article.get('title', ''),\n",
    "                        'publisher': article.get('publisher', ''),\n",
    "                        'link': article.get('link', ''),\n",
    "                        'date': pub_date.strftime('%Y-%m-%d'),\n",
    "                        'timestamp': pub_date\n",
    "                    })\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return sorted(filtered_news, key=lambda x: x['timestamp'], reverse=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching news: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def identify_catalysts_with_llm(\n",
    "    symbol: str,\n",
    "    news_items: List[Dict],\n",
    "    financial_summary: str,\n",
    "    api_key: str\n",
    ") -> Dict:\n",
    "    \"\"\"Use Claude API to analyze news and identify key catalysts.\"\"\"\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    \n",
    "    news_text = \"\\n\\n\".join([\n",
    "        f\"[{item['date']}] {item['title']} ({item['publisher']})\"\n",
    "        for item in news_items[:20]\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are a financial analyst identifying investment catalysts for {symbol}.\n",
    "\n",
    "FINANCIAL SUMMARY:\n",
    "{financial_summary}\n",
    "\n",
    "RECENT NEWS:\n",
    "{news_text}\n",
    "\n",
    "Analyze the news and financials to identify catalysts. Return your analysis as a JSON object with this structure:\n",
    "{{\n",
    "  \"catalysts\": [\n",
    "    {{\n",
    "      \"type\": \"POSITIVE\" or \"NEGATIVE\" or \"NEUTRAL\",\n",
    "      \"category\": \"earnings\"|\"product\"|\"regulatory\"|\"management\"|\"market\"|\"partnership\"|\"other\",\n",
    "      \"description\": \"Brief description\",\n",
    "      \"impact_score\": number from -10 to +10,\n",
    "      \"timeframe\": \"short-term\"|\"medium-term\"|\"long-term\",\n",
    "      \"confidence\": \"high\"|\"medium\"|\"low\"\n",
    "    }}\n",
    "  ],\n",
    "  \"overall_sentiment\": \"bullish\"|\"neutral\"|\"bearish\",\n",
    "  \"key_risks\": [\"risk1\", \"risk2\"],\n",
    "  \"key_opportunities\": [\"opp1\", \"opp2\"]\n",
    "}}\n",
    "\n",
    "Focus on material catalysts that could significantly impact stock price. Be specific and evidence-based.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=2000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        response_text = message.content[0].text\n",
    "        json_start = response_text.find('{')\n",
    "        json_end = response_text.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = response_text[json_start:json_end]\n",
    "            return json.loads(json_str)\n",
    "        else:\n",
    "            print(\"⚠️  Could not parse LLM response\")\n",
    "            return {\"catalysts\": [], \"overall_sentiment\": \"neutral\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error calling Claude API: {str(e)}\")\n",
    "        return {\"catalysts\": [], \"overall_sentiment\": \"neutral\"}\n",
    "\n",
    "\n",
    "def calculate_catalyst_adjusted_price(\n",
    "    base_price: float,\n",
    "    catalysts: List[Dict],\n",
    "    current_price: float\n",
    ") -> Tuple[float, Dict]:\n",
    "    \"\"\"Calculate weighted price target incorporating catalysts.\"\"\"\n",
    "    if not catalysts:\n",
    "        return base_price, {\"base_price\": base_price, \"catalyst_adjustment_pct\": 0}\n",
    "    \n",
    "    confidence_weights = {\"high\": 1.0, \"medium\": 0.6, \"low\": 0.3}\n",
    "    timeframe_weights = {\"short-term\": 0.8, \"medium-term\": 1.0, \"long-term\": 0.5}\n",
    "    \n",
    "    total_impact = 0\n",
    "    for catalyst in catalysts:\n",
    "        impact = catalyst.get('impact_score', 0)\n",
    "        confidence = confidence_weights.get(catalyst.get('confidence', 'medium'), 0.6)\n",
    "        timeframe = timeframe_weights.get(catalyst.get('timeframe', 'medium-term'), 1.0)\n",
    "        total_impact += impact * confidence * timeframe\n",
    "    \n",
    "    # Convert impact to price adjustment (capped at ±20%)\n",
    "    adjustment_pct = np.clip(total_impact, -20, 20) / 100\n",
    "    \n",
    "    # Blend base price and current price (70% base, 30% current)\n",
    "    blended_base = base_price * 0.7 + current_price * 0.3\n",
    "    adjusted_price = blended_base * (1 + adjustment_pct)\n",
    "    \n",
    "    return adjusted_price, {\n",
    "        \"base_price\": base_price,\n",
    "        \"current_price\": current_price,\n",
    "        \"blended_base\": blended_base,\n",
    "        \"catalyst_adjustment_pct\": adjustment_pct * 100,\n",
    "        \"adjusted_price\": adjusted_price,\n",
    "        \"num_catalysts\": len(catalysts),\n",
    "        \"total_impact_score\": total_impact\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_investment_recommendation(\n",
    "    current_price: float,\n",
    "    target_price: float,\n",
    "    catalysts: List[Dict],\n",
    "    sentiment: str\n",
    ") -> Dict:\n",
    "    \"\"\"Generate investment recommendation based on all analysis.\"\"\"\n",
    "    upside = ((target_price - current_price) / current_price) * 100\n",
    "    \n",
    "    positive_catalysts = sum(1 for c in catalysts if c.get('type') == 'POSITIVE')\n",
    "    negative_catalysts = sum(1 for c in catalysts if c.get('type') == 'NEGATIVE')\n",
    "    \n",
    "    # Base recommendation from upside\n",
    "    if upside > 20:\n",
    "        base_rec = \"STRONG BUY\"\n",
    "        confidence = \"High\"\n",
    "    elif upside > 10:\n",
    "        base_rec = \"BUY\"\n",
    "        confidence = \"Medium-High\"\n",
    "    elif upside > -5:\n",
    "        base_rec = \"HOLD\"\n",
    "        confidence = \"Medium\"\n",
    "    elif upside > -15:\n",
    "        base_rec = \"REDUCE\"\n",
    "        confidence = \"Medium-High\"\n",
    "    else:\n",
    "        base_rec = \"SELL\"\n",
    "        confidence = \"High\"\n",
    "    \n",
    "    # Adjust based on catalysts and sentiment\n",
    "    if sentiment == \"bearish\" and negative_catalysts > positive_catalysts:\n",
    "        if base_rec == \"STRONG BUY\":\n",
    "            base_rec = \"BUY\"\n",
    "        elif base_rec == \"BUY\":\n",
    "            base_rec = \"HOLD\"\n",
    "    elif sentiment == \"bullish\" and positive_catalysts > negative_catalysts:\n",
    "        if base_rec == \"HOLD\":\n",
    "            base_rec = \"BUY\"\n",
    "        elif base_rec == \"BUY\":\n",
    "            base_rec = \"STRONG BUY\"\n",
    "    \n",
    "    reasons = [\n",
    "        f\"Price target implies {upside:+.1f}% upside/downside\",\n",
    "        f\"{positive_catalysts} positive catalyst(s) identified\" if positive_catalysts > 0 else None,\n",
    "        f\"{negative_catalysts} negative catalyst(s) identified\" if negative_catalysts > 0 else None,\n",
    "        f\"Overall market sentiment is {sentiment}\"\n",
    "    ]\n",
    "    reasons = [r for r in reasons if r]\n",
    "    \n",
    "    return {\n",
    "        \"recommendation\": base_rec,\n",
    "        \"confidence\": confidence,\n",
    "        \"target_price\": target_price,\n",
    "        \"current_price\": current_price,\n",
    "        \"expected_return\": upside,\n",
    "        \"reasoning\": reasons,\n",
    "        \"positive_catalysts\": positive_catalysts,\n",
    "        \"negative_catalysts\": negative_catalysts,\n",
    "        \"sentiment\": sentiment\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_investment_memo(\n",
    "    symbol: str,\n",
    "    recommendation_data: Dict,\n",
    "    catalyst_data: Dict,\n",
    "    company_info: Dict,\n",
    "    api_key: str\n",
    ") -> str:\n",
    "    \"\"\"Generate a professional investment memo using Claude API.\"\"\"\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    \n",
    "    context = f\"\"\"Generate a professional investment memo for {symbol} ({company_info.get('longName', symbol)}).\n",
    "\n",
    "COMPANY OVERVIEW:\n",
    "- Sector: {company_info.get('sector', 'N/A')}\n",
    "- Industry: {company_info.get('industry', 'N/A')}\n",
    "- Market Cap: ${company_info.get('marketCap', 0) / 1e9:.1f}B\n",
    "\n",
    "RECOMMENDATION:\n",
    "- Action: {recommendation_data['recommendation']}\n",
    "- Target Price: ${recommendation_data['target_price']:.2f}\n",
    "- Current Price: ${recommendation_data['current_price']:.2f}\n",
    "- Expected Return: {recommendation_data['expected_return']:.1f}%\n",
    "- Confidence: {recommendation_data['confidence']}\n",
    "\n",
    "CATALYSTS:\n",
    "{json.dumps(catalyst_data.get('catalysts', []), indent=2)}\n",
    "\n",
    "SENTIMENT: {catalyst_data.get('overall_sentiment', 'neutral')}\n",
    "\n",
    "KEY RISKS:\n",
    "{json.dumps(catalyst_data.get('key_risks', []), indent=2)}\n",
    "\n",
    "KEY OPPORTUNITIES:\n",
    "{json.dumps(catalyst_data.get('key_opportunities', []), indent=2)}\n",
    "\n",
    "Write a professional investment memo with these sections:\n",
    "1. Executive Summary\n",
    "2. Investment Recommendation\n",
    "3. Investment Thesis\n",
    "4. Catalysts Analysis\n",
    "5. Valuation\n",
    "6. Risk Factors\n",
    "7. Financial Health\n",
    "8. Conclusion\n",
    "\n",
    "Use professional financial language. Be specific with numbers. Format in clean Markdown.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=4000,\n",
    "            messages=[{\"role\": \"user\", \"content\": context}]\n",
    "        )\n",
    "        \n",
    "        return message.content[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating memo: {str(e)}\")\n",
    "        return f\"# Error Generating Investment Memo\\n\\nError: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b381f0d-97c1-4167-9c96-a2ffaade9168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google_genai in g:\\anaconda\\anaconda\\lib\\site-packages (1.56.0)\n",
      "Collecting google_genai\n",
      "  Downloading google_genai-1.61.0-py3-none-any.whl.metadata (53 kB)\n",
      "     ---------------------------------------- 0.0/53.1 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/53.1 kB ? eta -:--:--\n",
      "     --------------------- ---------------- 30.7/53.1 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 53.1/53.1 kB 343.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (4.12.0)\n",
      "Collecting google-auth<3.0.0,>=2.47.0 (from google-auth[requests]<3.0.0,>=2.47.0->google_genai)\n",
      "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (4.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in g:\\anaconda\\anaconda\\lib\\site-packages (from google_genai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in g:\\anaconda\\anaconda\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google_genai) (3.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google_genai) (0.2.8)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google_genai) (42.0.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google_genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in g:\\anaconda\\anaconda\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google_genai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in g:\\anaconda\\anaconda\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google_genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in g:\\anaconda\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google_genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google_genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google_genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google_genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in g:\\anaconda\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google_genai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\anaconda\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google_genai) (2.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in g:\\anaconda\\anaconda\\lib\\site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google_genai) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in g:\\anaconda\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google_genai) (0.4.8)\n",
      "Requirement already satisfied: pycparser in g:\\anaconda\\anaconda\\lib\\site-packages (from cffi>=1.12->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google_genai) (2.21)\n",
      "Downloading google_genai-1.61.0-py3-none-any.whl (721 kB)\n",
      "   ---------------------------------------- 0.0/721.9 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/721.9 kB 3.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 143.4/721.9 kB 2.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 317.4/721.9 kB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 430.1/721.9 kB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 532.5/721.9 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  716.8/721.9 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 721.9/721.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
      "   ---------------------------------------- 0.0/236.5 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 92.2/236.5 kB 5.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 122.9/236.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 174.1/236.5 kB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 174.1/236.5 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 236.5/236.5 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: google-auth, google_genai\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.45.0\n",
      "    Uninstalling google-auth-2.45.0:\n",
      "      Successfully uninstalled google-auth-2.45.0\n",
      "  Attempting uninstall: google_genai\n",
      "    Found existing installation: google-genai 1.56.0\n",
      "    Uninstalling google-genai-1.56.0:\n",
      "      Successfully uninstalled google-genai-1.56.0\n",
      "Successfully installed google-auth-2.48.0 google_genai-1.61.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51072fb1-0ae5-4318-b4ef-4bc0e545ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.188.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-generativeai) (2.48.0)\n",
      "Requirement already satisfied: protobuf in g:\\anaconda\\anaconda\\lib\\site-packages (from google-generativeai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in g:\\anaconda\\anaconda\\lib\\site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: tqdm in g:\\anaconda\\anaconda\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in g:\\anaconda\\anaconda\\lib\\site-packages (from google-generativeai) (4.15.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (42.0.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in g:\\anaconda\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.31.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in g:\\anaconda\\anaconda\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\anaconda\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in g:\\anaconda\\anaconda\\lib\\site-packages (from cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai) (1.16.0)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing<4,>=3.1 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in g:\\anaconda\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in g:\\anaconda\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\anaconda\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
      "Requirement already satisfied: pycparser in g:\\anaconda\\anaconda\\lib\\site-packages (from cffi>=1.12->cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai) (2.21)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading google_generativeai-0.8.6-py3-none-any.whl (155 kB)\n",
      "   ---------------------------------------- 0.0/155.1 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 30.7/155.1 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 41.0/155.1 kB 393.8 kB/s eta 0:00:01\n",
      "   -------------------- ------------------ 81.9/155.1 kB 657.6 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 112.6/155.1 kB 547.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 155.1/155.1 kB 579.4 kB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.0/1.3 MB 393.8 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.0/1.3 MB 393.8 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/1.3 MB 365.7 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.3 MB 302.7 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.3 MB 309.1 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 328.0 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.3 MB 343.4 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.1/1.3 MB 202.9 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.1/1.3 MB 202.9 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 195.3 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 195.3 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 195.3 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 195.3 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 174.9 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 174.9 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 168.8 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 168.8 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 168.8 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.3 MB 163.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.3 MB 163.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.3 MB 163.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.3 MB 161.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.3 MB 161.9 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.3/1.3 MB 171.0 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.3/1.3 MB 171.0 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.3/1.3 MB 167.2 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.3/1.3 MB 167.2 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.3/1.3 MB 167.2 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.3/1.3 MB 168.6 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 0.3/1.3 MB 174.4 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 0.3/1.3 MB 174.4 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 0.3/1.3 MB 174.4 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 0.3/1.3 MB 169.5 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 174.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 174.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 169.0 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 177.9 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 185.1 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 0.4/1.3 MB 183.1 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 0.4/1.3 MB 192.0 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.5/1.3 MB 198.4 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.5/1.3 MB 198.4 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.5/1.3 MB 199.3 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.5/1.3 MB 199.3 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.5/1.3 MB 199.3 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.5/1.3 MB 199.3 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.5/1.3 MB 188.4 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.5/1.3 MB 191.8 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.5/1.3 MB 191.8 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.5/1.3 MB 191.8 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 196.6 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 0.6/1.3 MB 198.5 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.3 MB 198.5 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.3 MB 197.7 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.3 MB 199.5 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.3 MB 199.5 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.3 MB 195.6 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.3 MB 195.6 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 0.6/1.3 MB 202.9 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 0.6/1.3 MB 205.2 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 0.6/1.3 MB 205.2 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 0.7/1.3 MB 207.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 0.7/1.3 MB 207.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 0.7/1.3 MB 209.1 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 0.7/1.3 MB 212.3 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.7/1.3 MB 212.4 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.7/1.3 MB 214.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.7/1.3 MB 214.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.8/1.3 MB 210.7 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 214.6 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 214.6 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.8/1.3 MB 213.9 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.8/1.3 MB 213.9 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.8/1.3 MB 216.7 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 0.8/1.3 MB 215.8 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 0.9/1.3 MB 218.5 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 0.9/1.3 MB 218.5 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 0.9/1.3 MB 217.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 0.9/1.3 MB 217.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 0.9/1.3 MB 215.9 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 0.9/1.3 MB 215.9 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 0.9/1.3 MB 216.8 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.3 MB 216.8 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.3 MB 213.7 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.9/1.3 MB 215.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.9/1.3 MB 215.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.9/1.3 MB 215.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.9/1.3 MB 215.3 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 210.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 178.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 199.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 199.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 199.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 199.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 193.7 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 193.7 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.1/1.3 MB 194.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.1/1.3 MB 193.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.3 MB 195.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.2/1.3 MB 194.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.2/1.3 MB 194.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.2/1.3 MB 194.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.2/1.3 MB 194.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.2/1.3 MB 193.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 194.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 194.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 194.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 194.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 194.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 194.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 187.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 190.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 190.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 190.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 187.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 187.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 187.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 186.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 186.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 186.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 184.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 184.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 184.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 184.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 184.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 184.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 184.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 184.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 180.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 179.7 kB/s eta 0:00:00\n",
      "Downloading google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "   ---------------------------------------- 0.0/173.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/173.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/173.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/173.9 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/173.9 kB 262.6 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 41.0/173.9 kB 219.4 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 41.0/173.9 kB 219.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/173.9 kB 234.9 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/173.9 kB 234.9 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/173.9 kB 234.9 kB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 71.7/173.9 kB 151.3 kB/s eta 0:00:01\n",
      "   -------------------- ------------------ 92.2/173.9 kB 194.6 kB/s eta 0:00:01\n",
      "   -------------------- ------------------ 92.2/173.9 kB 194.6 kB/s eta 0:00:01\n",
      "   -------------------- ------------------ 92.2/173.9 kB 194.6 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 102.4/173.9 kB 164.0 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 122.9/173.9 kB 180.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 122.9/173.9 kB 180.2 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 143.4/173.9 kB 185.4 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 143.4/173.9 kB 185.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 153.6/173.9 kB 180.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 163.8/173.9 kB 178.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 173.9/173.9 kB 183.9 kB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.188.0-py3-none-any.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.0/14.9 MB 281.8 kB/s eta 0:00:53\n",
      "   ---------------------------------------- 0.0/14.9 MB 281.8 kB/s eta 0:00:53\n",
      "   ---------------------------------------- 0.1/14.9 MB 297.7 kB/s eta 0:00:50\n",
      "   ---------------------------------------- 0.1/14.9 MB 262.6 kB/s eta 0:00:57\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 309.1 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.1/14.9 MB 171.7 kB/s eta 0:01:26\n",
      "   ---------------------------------------- 0.1/14.9 MB 193.8 kB/s eta 0:01:17\n",
      "   ---------------------------------------- 0.1/14.9 MB 193.8 kB/s eta 0:01:17\n",
      "   ---------------------------------------- 0.1/14.9 MB 193.8 kB/s eta 0:01:17\n",
      "   ---------------------------------------- 0.2/14.9 MB 194.1 kB/s eta 0:01:16\n",
      "    --------------------------------------- 0.2/14.9 MB 210.7 kB/s eta 0:01:10\n",
      "    --------------------------------------- 0.2/14.9 MB 210.7 kB/s eta 0:01:10\n",
      "    --------------------------------------- 0.2/14.9 MB 200.8 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 205.4 kB/s eta 0:01:12\n",
      "    --------------------------------------- 0.2/14.9 MB 205.4 kB/s eta 0:01:12\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.2/14.9 MB 200.2 kB/s eta 0:01:14\n",
      "    --------------------------------------- 0.3/14.9 MB 190.9 kB/s eta 0:01:17\n",
      "    --------------------------------------- 0.4/14.9 MB 212.3 kB/s eta 0:01:09\n",
      "    --------------------------------------- 0.4/14.9 MB 214.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 0.4/14.9 MB 218.5 kB/s eta 0:01:07\n",
      "   - -------------------------------------- 0.4/14.9 MB 218.5 kB/s eta 0:01:07\n",
      "   - -------------------------------------- 0.4/14.9 MB 214.7 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 0.4/14.9 MB 211.3 kB/s eta 0:01:09\n",
      "   - -------------------------------------- 0.5/14.9 MB 232.6 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/14.9 MB 246.4 kB/s eta 0:00:59\n",
      "   - -------------------------------------- 0.5/14.9 MB 246.4 kB/s eta 0:00:59\n",
      "   - -------------------------------------- 0.6/14.9 MB 285.1 kB/s eta 0:00:51\n",
      "   - -------------------------------------- 0.6/14.9 MB 291.3 kB/s eta 0:00:49\n",
      "   - -------------------------------------- 0.7/14.9 MB 297.0 kB/s eta 0:00:48\n",
      "   - -------------------------------------- 0.7/14.9 MB 302.1 kB/s eta 0:00:47\n",
      "   - -------------------------------------- 0.7/14.9 MB 302.1 kB/s eta 0:00:47\n",
      "   - -------------------------------------- 0.7/14.9 MB 301.2 kB/s eta 0:00:48\n",
      "   - -------------------------------------- 0.7/14.9 MB 303.9 kB/s eta 0:00:47\n",
      "   -- ------------------------------------- 0.8/14.9 MB 314.9 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.8/14.9 MB 327.7 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 0.8/14.9 MB 327.7 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 0.8/14.9 MB 327.7 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 0.8/14.9 MB 327.7 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 0.8/14.9 MB 327.7 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 0.8/14.9 MB 327.7 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 0.8/14.9 MB 299.3 kB/s eta 0:00:47\n",
      "   -- ------------------------------------- 0.8/14.9 MB 301.6 kB/s eta 0:00:47\n",
      "   -- ------------------------------------- 0.9/14.9 MB 302.2 kB/s eta 0:00:47\n",
      "   -- ------------------------------------- 0.9/14.9 MB 308.0 kB/s eta 0:00:46\n",
      "   -- ------------------------------------- 0.9/14.9 MB 308.0 kB/s eta 0:00:46\n",
      "   -- ------------------------------------- 0.9/14.9 MB 313.9 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 1.0/14.9 MB 336.2 kB/s eta 0:00:42\n",
      "   -- ------------------------------------- 1.0/14.9 MB 339.6 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 1.0/14.9 MB 339.6 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 1.0/14.9 MB 339.6 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 1.0/14.9 MB 339.6 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 1.1/14.9 MB 326.1 kB/s eta 0:00:43\n",
      "   -- ------------------------------------- 1.1/14.9 MB 333.9 kB/s eta 0:00:42\n",
      "   --- ------------------------------------ 1.2/14.9 MB 364.4 kB/s eta 0:00:38\n",
      "   --- ------------------------------------ 1.3/14.9 MB 374.6 kB/s eta 0:00:37\n",
      "   --- ------------------------------------ 1.4/14.9 MB 392.0 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 1.4/14.9 MB 402.7 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.4/14.9 MB 407.9 kB/s eta 0:00:33\n",
      "   --- ------------------------------------ 1.4/14.9 MB 407.9 kB/s eta 0:00:33\n",
      "   --- ------------------------------------ 1.4/14.9 MB 407.9 kB/s eta 0:00:33\n",
      "   --- ------------------------------------ 1.5/14.9 MB 397.7 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.5/14.9 MB 393.7 kB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 1.5/14.9 MB 397.6 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.5/14.9 MB 392.2 kB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 1.6/14.9 MB 400.7 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.6/14.9 MB 409.6 kB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 1.7/14.9 MB 424.8 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.7/14.9 MB 426.7 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 1.7/14.9 MB 425.9 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 429.4 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 429.4 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 422.2 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 422.2 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 422.2 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 414.0 kB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 422.0 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 1.9/14.9 MB 419.9 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 442.2 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 444.5 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 445.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 443.6 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 443.6 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 443.6 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 443.6 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 429.8 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 427.0 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 429.9 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 427.9 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 428.0 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 426.0 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 426.0 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 2.2/14.9 MB 422.1 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 2.2/14.9 MB 421.0 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 2.2/14.9 MB 419.2 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 2.2/14.9 MB 420.1 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 2.2/14.9 MB 421.4 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 2.3/14.9 MB 422.8 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 2.3/14.9 MB 424.8 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 2.3/14.9 MB 423.0 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 2.3/14.9 MB 422.0 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 2.4/14.9 MB 434.5 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 2.5/14.9 MB 440.6 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 2.5/14.9 MB 440.5 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 2.5/14.9 MB 440.5 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 2.5/14.9 MB 438.7 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 2.5/14.9 MB 438.7 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 2.6/14.9 MB 441.6 kB/s eta 0:00:28\n",
      "   ------ --------------------------------- 2.6/14.9 MB 441.6 kB/s eta 0:00:28\n",
      "   ------ --------------------------------- 2.6/14.9 MB 441.6 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 2.6/14.9 MB 436.4 kB/s eta 0:00:29\n",
      "   ------- -------------------------------- 2.7/14.9 MB 445.4 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 2.7/14.9 MB 448.1 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 2.8/14.9 MB 452.0 kB/s eta 0:00:27\n",
      "   ------- -------------------------------- 2.8/14.9 MB 458.5 kB/s eta 0:00:27\n",
      "   ------- -------------------------------- 2.9/14.9 MB 458.9 kB/s eta 0:00:27\n",
      "   ------- -------------------------------- 2.9/14.9 MB 464.6 kB/s eta 0:00:26\n",
      "   ------- -------------------------------- 2.9/14.9 MB 464.6 kB/s eta 0:00:26\n",
      "   ------- -------------------------------- 2.9/14.9 MB 461.6 kB/s eta 0:00:26\n",
      "   ------- -------------------------------- 3.0/14.9 MB 460.8 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 3.0/14.9 MB 466.5 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 3.1/14.9 MB 471.0 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 3.1/14.9 MB 470.8 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 3.1/14.9 MB 473.2 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.2/14.9 MB 472.3 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.2/14.9 MB 475.1 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.3/14.9 MB 480.9 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.3/14.9 MB 480.2 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.3/14.9 MB 479.9 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.3/14.9 MB 479.9 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.3/14.9 MB 476.8 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.3/14.9 MB 476.5 kB/s eta 0:00:25\n",
      "   --------- ------------------------------ 3.4/14.9 MB 482.1 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.5/14.9 MB 486.1 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.5/14.9 MB 486.4 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.5/14.9 MB 486.4 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.5/14.9 MB 486.4 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.5/14.9 MB 477.8 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.5/14.9 MB 477.8 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 483.8 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 483.6 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 483.6 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 483.6 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 475.9 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 475.6 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 475.1 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.6/14.9 MB 472.9 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.7/14.9 MB 475.9 kB/s eta 0:00:24\n",
      "   --------- ------------------------------ 3.7/14.9 MB 475.1 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.7/14.9 MB 478.4 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 475.9 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 475.9 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 474.8 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 471.4 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 473.8 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 472.3 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 3.9/14.9 MB 479.6 kB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 3.9/14.9 MB 479.6 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 4.1/14.9 MB 496.8 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 501.1 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 501.7 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 499.5 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 499.5 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 496.1 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.3/14.9 MB 498.4 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.3/14.9 MB 499.2 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.3/14.9 MB 498.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 499.8 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 500.6 kB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 500.6 kB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 500.6 kB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 495.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 493.8 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 493.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 4.5/14.9 MB 494.4 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 4.5/14.9 MB 494.9 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.5/14.9 MB 494.9 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.6/14.9 MB 497.9 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.6/14.9 MB 497.9 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.6/14.9 MB 495.7 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.6/14.9 MB 495.4 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.6/14.9 MB 495.4 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.6/14.9 MB 492.1 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.7/14.9 MB 495.0 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.7/14.9 MB 495.8 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.8/14.9 MB 496.9 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.8/14.9 MB 497.4 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.8/14.9 MB 497.4 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 4.8/14.9 MB 497.4 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 4.8/14.9 MB 493.9 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 4.8/14.9 MB 493.3 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 4.9/14.9 MB 493.9 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 4.9/14.9 MB 493.1 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 4.9/14.9 MB 496.7 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.0/14.9 MB 496.6 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.0/14.9 MB 497.4 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.1/14.9 MB 500.9 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.1/14.9 MB 501.4 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.1/14.9 MB 500.6 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.1/14.9 MB 501.3 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 5.2/14.9 MB 504.0 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.2/14.9 MB 504.5 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.2/14.9 MB 503.2 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.2/14.9 MB 503.2 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.2/14.9 MB 499.8 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.2/14.9 MB 499.8 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.3/14.9 MB 497.6 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.3/14.9 MB 498.1 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.3/14.9 MB 498.0 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 5.4/14.9 MB 501.3 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 5.5/14.9 MB 507.5 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 5.5/14.9 MB 508.3 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 5.5/14.9 MB 507.3 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 5.6/14.9 MB 509.8 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.6/14.9 MB 511.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.6/14.9 MB 511.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.6/14.9 MB 508.2 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.6/14.9 MB 508.2 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.6/14.9 MB 508.2 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.7/14.9 MB 504.4 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.7/14.9 MB 508.8 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 5.8/14.9 MB 510.9 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 5.8/14.9 MB 510.9 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 5.8/14.9 MB 510.9 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 5.8/14.9 MB 505.0 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 5.8/14.9 MB 504.9 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 5.8/14.9 MB 505.8 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 5.9/14.9 MB 512.3 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.0/14.9 MB 514.2 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.0/14.9 MB 515.0 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.0/14.9 MB 515.0 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.0/14.9 MB 512.7 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.1/14.9 MB 511.8 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.1/14.9 MB 511.4 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.1/14.9 MB 512.8 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 6.2/14.9 MB 513.5 kB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 6.2/14.9 MB 517.5 kB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 6.2/14.9 MB 517.5 kB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 6.3/14.9 MB 517.1 kB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 6.3/14.9 MB 518.4 kB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 6.4/14.9 MB 520.4 kB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 6.4/14.9 MB 522.8 kB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 6.5/14.9 MB 524.3 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.5/14.9 MB 524.5 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.5/14.9 MB 522.8 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.5/14.9 MB 522.8 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.5/14.9 MB 522.0 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 521.7 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 522.8 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 522.0 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 523.0 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 6.7/14.9 MB 521.9 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.7/14.9 MB 522.5 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.7/14.9 MB 522.1 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.8/14.9 MB 522.9 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.8/14.9 MB 522.9 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.8/14.9 MB 520.7 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.8/14.9 MB 521.1 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.8/14.9 MB 521.6 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 6.9/14.9 MB 521.9 kB/s eta 0:00:16\n",
      "   ------------------ --------------------- 7.0/14.9 MB 527.4 kB/s eta 0:00:15\n",
      "   ------------------ --------------------- 7.0/14.9 MB 526.3 kB/s eta 0:00:15\n",
      "   ------------------ --------------------- 7.0/14.9 MB 528.2 kB/s eta 0:00:15\n",
      "   ------------------ --------------------- 7.0/14.9 MB 526.4 kB/s eta 0:00:15\n",
      "   ------------------ --------------------- 7.0/14.9 MB 526.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.1/14.9 MB 526.6 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.1/14.9 MB 526.6 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.1/14.9 MB 526.6 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.1/14.9 MB 525.6 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.2/14.9 MB 530.3 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.2/14.9 MB 530.1 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.2/14.9 MB 530.1 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 528.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 526.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 526.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 526.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 522.5 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 522.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.3/14.9 MB 522.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 521.5 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 522.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 522.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 7.4/14.9 MB 519.0 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 7.4/14.9 MB 493.6 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 7.6/14.9 MB 501.7 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 7.7/14.9 MB 508.1 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 8.0/14.9 MB 523.6 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.0/14.9 MB 524.4 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.0/14.9 MB 524.0 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.0/14.9 MB 523.8 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.0/14.9 MB 522.3 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.1/14.9 MB 521.5 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.1/14.9 MB 521.2 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 8.1/14.9 MB 521.6 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 8.1/14.9 MB 520.7 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.2/14.9 MB 522.5 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.2/14.9 MB 524.2 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.3/14.9 MB 526.8 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.3/14.9 MB 527.7 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.3/14.9 MB 527.7 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 525.2 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 524.9 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 524.9 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 522.8 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 522.6 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 522.6 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.5/14.9 MB 524.0 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 8.5/14.9 MB 523.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 524.5 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 524.5 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 524.5 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 524.5 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 524.5 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 518.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.6/14.9 MB 496.7 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.7/14.9 MB 499.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.7/14.9 MB 499.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.7/14.9 MB 497.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 8.8/14.9 MB 502.5 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 9.1/14.9 MB 518.8 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 9.1/14.9 MB 519.6 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 9.2/14.9 MB 519.0 kB/s eta 0:00:11\n",
      "   ------------------------ --------------- 9.2/14.9 MB 519.1 kB/s eta 0:00:11\n",
      "   ------------------------ --------------- 9.2/14.9 MB 519.1 kB/s eta 0:00:11\n",
      "   ------------------------ --------------- 9.2/14.9 MB 519.1 kB/s eta 0:00:11\n",
      "   ------------------------ --------------- 9.2/14.9 MB 514.8 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 9.3/14.9 MB 516.9 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 9.3/14.9 MB 518.2 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 9.4/14.9 MB 523.3 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 9.5/14.9 MB 525.3 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 9.6/14.9 MB 529.7 kB/s eta 0:00:10\n",
      "   ------------------------- -------------- 9.6/14.9 MB 531.0 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.7/14.9 MB 532.7 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.7/14.9 MB 533.4 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.8/14.9 MB 533.3 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.8/14.9 MB 533.5 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.8/14.9 MB 533.5 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.8/14.9 MB 531.5 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 9.9/14.9 MB 532.9 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 10.0/14.9 MB 537.2 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 10.0/14.9 MB 537.9 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 10.0/14.9 MB 536.7 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 10.1/14.9 MB 539.2 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.1/14.9 MB 537.5 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.2/14.9 MB 540.5 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.2/14.9 MB 541.7 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.2/14.9 MB 541.7 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.2/14.9 MB 539.7 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.3/14.9 MB 539.7 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.3/14.9 MB 539.7 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.3/14.9 MB 541.5 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.3/14.9 MB 553.4 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.3/14.9 MB 553.4 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.4/14.9 MB 552.5 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 10.4/14.9 MB 554.8 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 10.4/14.9 MB 555.8 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 10.4/14.9 MB 558.6 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.5/14.9 MB 574.8 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.5/14.9 MB 574.8 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.5/14.9 MB 572.3 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.5/14.9 MB 572.3 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.6/14.9 MB 569.3 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.6/14.9 MB 567.8 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.6/14.9 MB 569.3 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 572.8 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 573.3 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 570.8 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 570.8 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 571.3 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 10.8/14.9 MB 569.3 kB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 10.8/14.9 MB 568.3 kB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 10.8/14.9 MB 566.8 kB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 10.9/14.9 MB 572.3 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 11.0/14.9 MB 573.3 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 11.1/14.9 MB 589.8 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 11.2/14.9 MB 590.4 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 11.2/14.9 MB 589.8 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 11.3/14.9 MB 596.8 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 597.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 597.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 594.1 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 594.1 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 589.3 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 589.3 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 586.6 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 585.6 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.4/14.9 MB 583.0 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 11.5/14.9 MB 583.0 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.5/14.9 MB 583.0 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.6/14.9 MB 580.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.6/14.9 MB 579.4 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.6/14.9 MB 578.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.6/14.9 MB 576.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.6/14.9 MB 576.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.6/14.9 MB 575.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.7/14.9 MB 578.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.7/14.9 MB 580.4 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.7/14.9 MB 580.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.8/14.9 MB 579.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.8/14.9 MB 579.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.8/14.9 MB 577.9 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.8/14.9 MB 576.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.8/14.9 MB 576.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.8/14.9 MB 573.3 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.9/14.9 MB 574.3 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.9/14.9 MB 574.3 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.9/14.9 MB 571.3 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 11.9/14.9 MB 571.3 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 568.3 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 568.3 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 566.3 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 11.9/14.9 MB 564.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 12.0/14.9 MB 538.4 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 12.1/14.9 MB 544.7 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 12.1/14.9 MB 544.7 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 12.4/14.9 MB 566.3 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 569.3 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 569.3 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 566.8 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 566.8 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 566.8 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 566.8 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 561.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 561.0 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 561.0 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.5/14.9 MB 559.1 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.6/14.9 MB 561.0 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.6/14.9 MB 561.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 12.6/14.9 MB 560.0 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 558.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 558.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 556.7 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 555.3 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 555.3 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 555.3 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 552.5 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 552.5 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 550.6 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 550.6 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 551.6 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 551.6 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 553.4 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.9/14.9 MB 552.0 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.9/14.9 MB 550.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.9/14.9 MB 548.8 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.9/14.9 MB 548.8 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 12.9/14.9 MB 547.0 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 13.0/14.9 MB 547.9 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.0/14.9 MB 546.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.0/14.9 MB 546.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.0/14.9 MB 546.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.0/14.9 MB 546.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.0/14.9 MB 546.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.0/14.9 MB 546.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 539.3 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 539.3 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 539.3 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 535.8 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 536.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 534.0 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 534.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 534.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 534.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 534.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 531.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 531.0 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 531.0 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 529.7 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 528.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 528.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 526.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 500.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 500.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 500.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 500.2 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.5/14.9 MB 504.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 13.6/14.9 MB 494.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 495.2 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 494.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 13.8/14.9 MB 481.0 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 14.1/14.9 MB 490.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 14.1/14.9 MB 491.5 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.2/14.9 MB 492.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.2/14.9 MB 491.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 490.0 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 488.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 488.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 487.5 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 485.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 485.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.3/14.9 MB 483.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.4/14.9 MB 482.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.4/14.9 MB 482.5 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.4/14.9 MB 482.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.4/14.9 MB 483.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.4/14.9 MB 483.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 482.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.5/14.9 MB 474.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.9 MB 473.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.9 MB 474.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.9 MB 474.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 476.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 476.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 476.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 476.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 474.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 473.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 473.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 473.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 471.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 471.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 472.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 471.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 471.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 469.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 469.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 468.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 468.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 468.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 470.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 468.9 kB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.3.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "   ---------------------------------------- 0.0/297.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/297.5 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/297.5 kB 445.2 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 92.2/297.5 kB 585.1 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/297.5 kB 658.7 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/297.5 kB 700.2 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 184.3/297.5 kB 619.5 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 204.8/297.5 kB 623.6 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 204.8/297.5 kB 623.6 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 204.8/297.5 kB 623.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 286.7/297.5 kB 590.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 297.5/297.5 kB 557.8 kB/s eta 0:00:00\n",
      "Downloading httplib2-0.31.2-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.1 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 30.7/91.1 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 61.4/91.1 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 61.4/91.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 81.9/91.1 kB 459.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 81.9/91.1 kB 459.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 91.1/91.1 kB 398.3 kB/s eta 0:00:00\n",
      "Downloading proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/50.2 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 41.0/50.2 kB 326.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 50.2/50.2 kB 366.7 kB/s eta 0:00:00\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.0/4.7 MB 495.5 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/4.7 MB 469.7 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/4.7 MB 393.8 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.1/4.7 MB 492.8 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/4.7 MB 492.8 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.2/4.7 MB 553.5 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/4.7 MB 530.7 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/4.7 MB 573.4 kB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.3/4.7 MB 562.4 kB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.3/4.7 MB 528.9 kB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.3/4.7 MB 617.1 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.4/4.7 MB 656.2 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.4/4.7 MB 656.2 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.4/4.7 MB 656.2 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.4/4.7 MB 656.2 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.4/4.7 MB 535.4 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 558.8 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 586.8 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.6/4.7 MB 599.0 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.6/4.7 MB 603.0 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.6/4.7 MB 624.6 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.7/4.7 MB 626.5 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.7/4.7 MB 618.6 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.7/4.7 MB 612.1 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.7/4.7 MB 621.1 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.8/4.7 MB 607.1 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.8/4.7 MB 608.4 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.8/4.7 MB 594.7 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.7 MB 604.5 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.7 MB 612.5 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.7 MB 599.9 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.7 MB 582.9 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.7 MB 582.9 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.7 MB 566.4 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.9/4.7 MB 557.7 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.9/4.7 MB 557.7 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.0/4.7 MB 544.2 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.0/4.7 MB 544.2 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.0/4.7 MB 544.2 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.0/4.7 MB 509.3 kB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.0/4.7 MB 509.3 kB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.0/4.7 MB 491.5 kB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.0/4.7 MB 491.5 kB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.0/4.7 MB 491.5 kB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.0/4.7 MB 470.2 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.1/4.7 MB 478.8 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.1/4.7 MB 480.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.1/4.7 MB 480.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.1/4.7 MB 476.4 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.1/4.7 MB 471.3 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.2/4.7 MB 479.0 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.2/4.7 MB 479.0 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.2/4.7 MB 479.0 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.2/4.7 MB 462.5 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.2/4.7 MB 462.5 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.3/4.7 MB 464.9 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 1.3/4.7 MB 464.9 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 474.0 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 474.0 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 474.0 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 474.0 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 448.5 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 448.5 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.4/4.7 MB 448.1 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 1.4/4.7 MB 455.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 1.5/4.7 MB 467.2 kB/s eta 0:00:07\n",
      "   ------------ --------------------------- 1.5/4.7 MB 472.3 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 1.6/4.7 MB 486.1 kB/s eta 0:00:07\n",
      "   -------------- ------------------------- 1.7/4.7 MB 506.4 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 1.7/4.7 MB 506.1 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 1.8/4.7 MB 520.1 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 1.8/4.7 MB 533.3 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 1.9/4.7 MB 534.4 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 1.9/4.7 MB 534.4 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.0/4.7 MB 553.3 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.0/4.7 MB 553.3 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.0/4.7 MB 547.5 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.0/4.7 MB 547.5 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.0/4.7 MB 547.5 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 537.2 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 537.2 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 537.2 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 537.2 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 513.8 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 513.8 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 2.3/4.7 MB 541.7 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 2.3/4.7 MB 540.5 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 2.3/4.7 MB 538.9 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 2.3/4.7 MB 540.6 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 2.3/4.7 MB 541.1 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.4/4.7 MB 536.0 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.4/4.7 MB 537.4 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.4/4.7 MB 534.4 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.5/4.7 MB 542.4 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.5/4.7 MB 546.5 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.6/4.7 MB 552.0 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 2.6/4.7 MB 554.9 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 2.7/4.7 MB 560.0 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 2.7/4.7 MB 563.0 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 2.8/4.7 MB 573.2 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 2.8/4.7 MB 573.2 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 2.8/4.7 MB 572.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 2.8/4.7 MB 572.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 2.9/4.7 MB 576.5 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 2.9/4.7 MB 576.7 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 3.0/4.7 MB 577.7 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.0/4.7 MB 578.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 3.1/4.7 MB 583.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 3.1/4.7 MB 583.2 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 3.1/4.7 MB 588.1 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 3.2/4.7 MB 592.3 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 3.2/4.7 MB 591.4 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 3.2/4.7 MB 589.9 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 3.3/4.7 MB 594.2 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 3.3/4.7 MB 596.1 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 3.4/4.7 MB 597.1 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 3.4/4.7 MB 603.1 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 3.5/4.7 MB 606.9 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 3.5/4.7 MB 609.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.5/4.7 MB 609.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.6/4.7 MB 610.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.6/4.7 MB 610.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.6/4.7 MB 607.4 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.7/4.7 MB 610.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.7/4.7 MB 613.2 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.7/4.7 MB 614.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.8/4.7 MB 610.4 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.8/4.7 MB 610.6 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.8/4.7 MB 612.7 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.8/4.7 MB 612.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.9/4.7 MB 615.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 4.0/4.7 MB 620.0 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 4.0/4.7 MB 620.4 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 4.0/4.7 MB 620.6 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 4.1/4.7 MB 624.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 4.1/4.7 MB 618.2 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 4.1/4.7 MB 622.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 626.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.2/4.7 MB 626.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.2/4.7 MB 623.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.3/4.7 MB 622.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.3/4.7 MB 625.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.4/4.7 MB 630.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.4/4.7 MB 634.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.7 MB 637.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.7 MB 635.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.7 MB 632.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.7 MB 632.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.6/4.7 MB 632.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.6/4.7 MB 632.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.6/4.7 MB 624.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  4.6/4.7 MB 628.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  4.7/4.7 MB 633.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  4.7/4.7 MB 629.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 624.6 kB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.8 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/434.8 kB 960.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 61.4/434.8 kB 656.4 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 71.7/434.8 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 153.6/434.8 kB 833.5 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 194.6/434.8 kB 841.6 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 256.0/434.8 kB 923.9 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 286.7/434.8 kB 883.3 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 317.4/434.8 kB 853.3 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 358.4/434.8 kB 855.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 389.1/434.8 kB 807.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 434.8/434.8 kB 822.8 kB/s eta 0:00:00\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.8 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 61.4/122.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 71.7/122.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 71.7/122.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- --- 112.6/122.8 kB 656.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 122.8/122.8 kB 598.6 kB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, pyparsing, protobuf, grpcio, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.29.0 google-api-python-client-2.188.0 google-auth-httplib2-0.3.0 google-generativeai-0.8.6 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.2 proto-plus-1.27.0 protobuf-5.29.5 pyparsing-3.3.2 uritemplate-4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.5 which is incompatible.\n",
      "streamlit 1.32.0 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc0c283f-44f0-4f64-90a0-d01bf0c11c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Investment Analysis Pipeline - Gemini Version\n",
    "Uses Google's Gemini API instead of Anthropic Claude\n",
    "\n",
    "INSTALLATION REQUIRED:\n",
    "Run this command first:\n",
    "    pip install google-generativeai\n",
    "\n",
    "or if using conda:\n",
    "    conda install -c conda-forge google-generativeai\n",
    "\"\"\"\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def get_recent_news(symbol: str, months_back: int = 3) -> List[Dict]:\n",
    "    \"\"\"Fetch recent news for a stock symbol.\"\"\"\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        news = ticker.news\n",
    "        \n",
    "        if not news:\n",
    "            print(f\"Warning: No news found for {symbol}\")\n",
    "            return []\n",
    "        \n",
    "        cutoff_date = datetime.now() - timedelta(days=months_back * 30)\n",
    "        filtered_news = []\n",
    "        \n",
    "        for article in news[:50]:\n",
    "            try:\n",
    "                pub_date = datetime.fromtimestamp(article.get('providerPublishTime', 0))\n",
    "                if pub_date >= cutoff_date:\n",
    "                    filtered_news.append({\n",
    "                        'title': article.get('title', ''),\n",
    "                        'publisher': article.get('publisher', ''),\n",
    "                        'link': article.get('link', ''),\n",
    "                        'date': pub_date.strftime('%Y-%m-%d'),\n",
    "                        'timestamp': pub_date\n",
    "                    })\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return sorted(filtered_news, key=lambda x: x['timestamp'], reverse=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def identify_catalysts_with_gemini(\n",
    "    symbol: str,\n",
    "    news_items: List[Dict],\n",
    "    financial_summary: str,\n",
    "    api_key: str\n",
    ") -> Dict:\n",
    "    \"\"\"Use Gemini API to analyze news and identify key catalysts.\"\"\"\n",
    "    \n",
    "    if not news_items:\n",
    "        print(\"Warning: No news items to analyze. Skipping catalyst identification.\")\n",
    "        return {\n",
    "            \"catalysts\": [],\n",
    "            \"overall_sentiment\": \"neutral\",\n",
    "            \"key_risks\": [\"Limited news coverage available\"],\n",
    "            \"key_opportunities\": []\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Configure Gemini\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Gemini client: {str(e)}\")\n",
    "        print(\"Please check your API key at https://makersuite.google.com/app/apikey\")\n",
    "        return {\"catalysts\": [], \"overall_sentiment\": \"neutral\", \"key_risks\": [], \"key_opportunities\": []}\n",
    "    \n",
    "    news_text = \"\\n\\n\".join([\n",
    "        f\"[{item['date']}] {item['title']} ({item['publisher']})\"\n",
    "        for item in news_items[:20]\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are a financial analyst identifying investment catalysts for {symbol}.\n",
    "\n",
    "FINANCIAL SUMMARY:\n",
    "{financial_summary}\n",
    "\n",
    "RECENT NEWS:\n",
    "{news_text}\n",
    "\n",
    "Analyze the news and financials to identify catalysts. Return your analysis as a JSON object with this structure:\n",
    "{{\n",
    "  \"catalysts\": [\n",
    "    {{\n",
    "      \"type\": \"POSITIVE\" or \"NEGATIVE\" or \"NEUTRAL\",\n",
    "      \"category\": \"earnings\"|\"product\"|\"regulatory\"|\"management\"|\"market\"|\"partnership\"|\"other\",\n",
    "      \"description\": \"Brief description\",\n",
    "      \"impact_score\": number from -10 to +10,\n",
    "      \"timeframe\": \"short-term\"|\"medium-term\"|\"long-term\",\n",
    "      \"confidence\": \"high\"|\"medium\"|\"low\"\n",
    "    }}\n",
    "  ],\n",
    "  \"overall_sentiment\": \"bullish\"|\"neutral\"|\"bearish\",\n",
    "  \"key_risks\": [\"risk1\", \"risk2\"],\n",
    "  \"key_opportunities\": [\"opp1\", \"opp2\"]\n",
    "}}\n",
    "\n",
    "Focus on material catalysts that could significantly impact stock price. Be specific and evidence-based.\n",
    "Return ONLY valid JSON, no additional text or markdown formatting.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        response_text = response.text\n",
    "        \n",
    "        # Clean up response text\n",
    "        response_text = response_text.strip()\n",
    "        \n",
    "        # Remove markdown code blocks if present\n",
    "        if response_text.startswith('```json'):\n",
    "            response_text = response_text[7:]\n",
    "        if response_text.startswith('```'):\n",
    "            response_text = response_text[3:]\n",
    "        if response_text.endswith('```'):\n",
    "            response_text = response_text[:-3]\n",
    "        \n",
    "        response_text = response_text.strip()\n",
    "        \n",
    "        # Find JSON object\n",
    "        json_start = response_text.find('{')\n",
    "        json_end = response_text.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = response_text[json_start:json_end]\n",
    "            result = json.loads(json_str)\n",
    "            return result\n",
    "        else:\n",
    "            print(\"Warning: Could not parse Gemini response as JSON\")\n",
    "            return {\"catalysts\": [], \"overall_sentiment\": \"neutral\", \"key_risks\": [], \"key_opportunities\": []}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {str(e)}\")\n",
    "        print(\"\\nPlease verify:\")\n",
    "        print(\"1. Your API key is correct\")\n",
    "        print(\"2. Gemini API is enabled for your project\")\n",
    "        print(\"3. You have available quota\")\n",
    "        return {\"catalysts\": [], \"overall_sentiment\": \"neutral\", \"key_risks\": [], \"key_opportunities\": []}\n",
    "\n",
    "\n",
    "def calculate_catalyst_adjusted_price(\n",
    "    base_price: float,\n",
    "    catalysts: List[Dict],\n",
    "    current_price: float\n",
    ") -> Tuple[float, Dict]:\n",
    "    \"\"\"Calculate weighted price target incorporating catalysts.\"\"\"\n",
    "    if not catalysts:\n",
    "        return base_price, {\n",
    "            \"base_price\": base_price,\n",
    "            \"current_price\": current_price,\n",
    "            \"blended_base\": base_price,\n",
    "            \"catalyst_adjustment_pct\": 0,\n",
    "            \"adjusted_price\": base_price,\n",
    "            \"num_catalysts\": 0,\n",
    "            \"total_impact_score\": 0\n",
    "        }\n",
    "    \n",
    "    confidence_weights = {\"high\": 1.0, \"medium\": 0.6, \"low\": 0.3}\n",
    "    timeframe_weights = {\"short-term\": 0.8, \"medium-term\": 1.0, \"long-term\": 0.5}\n",
    "    \n",
    "    total_impact = 0\n",
    "    for catalyst in catalysts:\n",
    "        impact = catalyst.get('impact_score', 0)\n",
    "        confidence = confidence_weights.get(catalyst.get('confidence', 'medium'), 0.6)\n",
    "        timeframe = timeframe_weights.get(catalyst.get('timeframe', 'medium-term'), 1.0)\n",
    "        total_impact += impact * confidence * timeframe\n",
    "    \n",
    "    adjustment_pct = np.clip(total_impact, -20, 20) / 100\n",
    "    blended_base = base_price * 0.7 + current_price * 0.3\n",
    "    adjusted_price = blended_base * (1 + adjustment_pct)\n",
    "    \n",
    "    return adjusted_price, {\n",
    "        \"base_price\": base_price,\n",
    "        \"current_price\": current_price,\n",
    "        \"blended_base\": blended_base,\n",
    "        \"catalyst_adjustment_pct\": adjustment_pct * 100,\n",
    "        \"adjusted_price\": adjusted_price,\n",
    "        \"num_catalysts\": len(catalysts),\n",
    "        \"total_impact_score\": total_impact\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_investment_recommendation(\n",
    "    current_price: float,\n",
    "    target_price: float,\n",
    "    catalysts: List[Dict],\n",
    "    sentiment: str\n",
    ") -> Dict:\n",
    "    \"\"\"Generate investment recommendation based on all analysis.\"\"\"\n",
    "    upside = ((target_price - current_price) / current_price) * 100\n",
    "    \n",
    "    positive_catalysts = sum(1 for c in catalysts if c.get('type') == 'POSITIVE')\n",
    "    negative_catalysts = sum(1 for c in catalysts if c.get('type') == 'NEGATIVE')\n",
    "    \n",
    "    if upside > 20:\n",
    "        base_rec = \"STRONG BUY\"\n",
    "        confidence = \"High\"\n",
    "    elif upside > 10:\n",
    "        base_rec = \"BUY\"\n",
    "        confidence = \"Medium-High\"\n",
    "    elif upside > -5:\n",
    "        base_rec = \"HOLD\"\n",
    "        confidence = \"Medium\"\n",
    "    elif upside > -15:\n",
    "        base_rec = \"REDUCE\"\n",
    "        confidence = \"Medium-High\"\n",
    "    else:\n",
    "        base_rec = \"SELL\"\n",
    "        confidence = \"High\"\n",
    "    \n",
    "    if sentiment == \"bearish\" and negative_catalysts > positive_catalysts:\n",
    "        if base_rec == \"STRONG BUY\":\n",
    "            base_rec = \"BUY\"\n",
    "        elif base_rec == \"BUY\":\n",
    "            base_rec = \"HOLD\"\n",
    "    elif sentiment == \"bullish\" and positive_catalysts > negative_catalysts:\n",
    "        if base_rec == \"HOLD\":\n",
    "            base_rec = \"BUY\"\n",
    "        elif base_rec == \"BUY\":\n",
    "            base_rec = \"STRONG BUY\"\n",
    "    \n",
    "    reasons = [\n",
    "        f\"Price target implies {upside:+.1f}% upside/downside\",\n",
    "        f\"{positive_catalysts} positive catalyst(s) identified\" if positive_catalysts > 0 else None,\n",
    "        f\"{negative_catalysts} negative catalyst(s) identified\" if negative_catalysts > 0 else None,\n",
    "        f\"Overall market sentiment is {sentiment}\"\n",
    "    ]\n",
    "    reasons = [r for r in reasons if r]\n",
    "    \n",
    "    return {\n",
    "        \"recommendation\": base_rec,\n",
    "        \"confidence\": confidence,\n",
    "        \"target_price\": target_price,\n",
    "        \"current_price\": current_price,\n",
    "        \"expected_return\": upside,\n",
    "        \"reasoning\": reasons,\n",
    "        \"positive_catalysts\": positive_catalysts,\n",
    "        \"negative_catalysts\": negative_catalysts,\n",
    "        \"sentiment\": sentiment\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_investment_memo_with_gemini(\n",
    "    symbol: str,\n",
    "    recommendation_data: Dict,\n",
    "    catalyst_data: Dict,\n",
    "    company_info: Dict,\n",
    "    api_key: str\n",
    ") -> str:\n",
    "    \"\"\"Generate a professional investment memo using Gemini API.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "    except Exception as e:\n",
    "        return f\"# Error: Unable to generate memo\\n\\nInvalid API key. Please check your Gemini API key.\\n\\nError: {str(e)}\"\n",
    "    \n",
    "    context = f\"\"\"Generate a professional investment memo for {symbol} ({company_info.get('longName', symbol)}).\n",
    "\n",
    "COMPANY OVERVIEW:\n",
    "- Sector: {company_info.get('sector', 'N/A')}\n",
    "- Industry: {company_info.get('industry', 'N/A')}\n",
    "- Market Cap: ${company_info.get('marketCap', 0) / 1e9:.1f}B\n",
    "\n",
    "RECOMMENDATION:\n",
    "- Action: {recommendation_data['recommendation']}\n",
    "- Target Price: ${recommendation_data['target_price']:.2f}\n",
    "- Current Price: ${recommendation_data['current_price']:.2f}\n",
    "- Expected Return: {recommendation_data['expected_return']:.1f}%\n",
    "- Confidence: {recommendation_data['confidence']}\n",
    "\n",
    "CATALYSTS:\n",
    "{json.dumps(catalyst_data.get('catalysts', []), indent=2)}\n",
    "\n",
    "SENTIMENT: {catalyst_data.get('overall_sentiment', 'neutral')}\n",
    "\n",
    "KEY RISKS:\n",
    "{json.dumps(catalyst_data.get('key_risks', []), indent=2)}\n",
    "\n",
    "KEY OPPORTUNITIES:\n",
    "{json.dumps(catalyst_data.get('key_opportunities', []), indent=2)}\n",
    "\n",
    "KEY FINANCIAL METRICS:\n",
    "- P/E Ratio: {company_info.get('trailingPE', 'N/A')}\n",
    "- Forward P/E: {company_info.get('forwardPE', 'N/A')}\n",
    "- Profit Margin: {company_info.get('profitMargins', 'N/A')}\n",
    "- ROE: {company_info.get('returnOnEquity', 'N/A')}\n",
    "\n",
    "Write a professional investment memo with these sections:\n",
    "1. Executive Summary\n",
    "2. Investment Recommendation\n",
    "3. Investment Thesis (3-5 key points)\n",
    "4. Catalysts Analysis\n",
    "5. Valuation\n",
    "6. Risk Factors\n",
    "7. Financial Health\n",
    "8. Conclusion\n",
    "\n",
    "Use professional financial language. Be specific with numbers. Format in clean Markdown.\n",
    "Do not use any emoji or special characters, use plain text only.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(context)\n",
    "        return response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"# Error Generating Investment Memo\\n\\nError: {str(e)}\"\n",
    "\n",
    "\n",
    "def complete_investment_analysis(\n",
    "    symbol: str,\n",
    "    gemini_api_key: str,\n",
    "    news_months_back: int = 3,\n",
    "    base_fair_value: Optional[float] = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run complete investment analysis pipeline using Gemini.\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock ticker\n",
    "        gemini_api_key: Your Google Gemini API key\n",
    "        news_months_back: Months of news to analyze\n",
    "        base_fair_value: Optional base valuation from your peer analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"COMPLETE INVESTMENT ANALYSIS FOR {symbol}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Initialize\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    company_info = ticker.info\n",
    "    current_price = company_info.get('currentPrice', company_info.get('regularMarketPrice', 0))\n",
    "    \n",
    "    if current_price == 0:\n",
    "        print(\"Error: Could not fetch current price\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"Company: {company_info.get('longName', symbol)}\")\n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    print(f\"Market Cap: ${company_info.get('marketCap', 0) / 1e9:.1f}B\\n\")\n",
    "    \n",
    "    # Step 1: Get News\n",
    "    print(\"Step 1: Fetching recent news...\")\n",
    "    news_items = get_recent_news(symbol, news_months_back)\n",
    "    print(f\"   Found {len(news_items)} recent articles\\n\")\n",
    "    \n",
    "    # Step 2: Identify Catalysts\n",
    "    print(\"Step 2: Identifying catalysts with Gemini AI...\")\n",
    "    financial_summary = f\"\"\"\n",
    "Current Price: ${current_price:.2f}\n",
    "Market Cap: ${company_info.get('marketCap', 0) / 1e9:.1f}B\n",
    "P/E Ratio: {company_info.get('trailingPE', 'N/A')}\n",
    "Forward P/E: {company_info.get('forwardPE', 'N/A')}\n",
    "Profit Margin: {company_info.get('profitMargins', 'N/A')}\n",
    "ROE: {company_info.get('returnOnEquity', 'N/A')}\n",
    "\"\"\"\n",
    "    \n",
    "    catalyst_data = identify_catalysts_with_gemini(\n",
    "        symbol, news_items, financial_summary, gemini_api_key\n",
    "    )\n",
    "    \n",
    "    num_catalysts = len(catalyst_data.get('catalysts', []))\n",
    "    print(f\"   Identified {num_catalysts} catalysts\")\n",
    "    print(f\"   Overall sentiment: {catalyst_data.get('overall_sentiment', 'neutral').upper()}\\n\")\n",
    "    \n",
    "    # Step 3: Calculate Price Target\n",
    "    print(\"Step 3: Calculating catalyst-adjusted price target...\")\n",
    "    \n",
    "    # Use provided base value or calculate simple valuation\n",
    "    if base_fair_value is not None:\n",
    "        base_price = base_fair_value\n",
    "    else:\n",
    "        pe_ratio = company_info.get('forwardPE', company_info.get('trailingPE', 20))\n",
    "        eps = company_info.get('trailingEps', current_price / pe_ratio)\n",
    "        base_price = eps * pe_ratio * 1.1\n",
    "    \n",
    "    adjusted_price, price_breakdown = calculate_catalyst_adjusted_price(\n",
    "        base_price, catalyst_data.get('catalysts', []), current_price\n",
    "    )\n",
    "    \n",
    "    print(f\"   Base Valuation: ${price_breakdown['base_price']:.2f}\")\n",
    "    print(f\"   Catalyst Adjustment: {price_breakdown['catalyst_adjustment_pct']:+.1f}%\")\n",
    "    print(f\"   Final Target Price: ${adjusted_price:.2f}\\n\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "865b71a0-944a-4e6a-a75c-97e4d6844f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL INTEGRATED VALUATION FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "MODEL INPUTS:\n",
      "------------------------------------------------------------\n",
      "DCF (Management-adjusted weighted average): $324.78\n",
      "Peer Analysis (Comparative valuation):      $311.64\n",
      "Current Market Price:                       $338.53\n",
      "\n",
      "ADAPTIVE WEIGHTING RESULT:\n",
      "------------------------------------------------------------\n",
      "Relative difference between models: 3.9%\n",
      "Weighting method: Equal weights (high agreement between models)\n",
      "DCF weight: 50%\n",
      "Peer weight: 50%\n",
      "\n",
      "FINAL PREDICTED PRICE: $318.21\n",
      "Expected return: -6.0%\n",
      "Recommendation: REDUCE\n",
      "\n",
      "================================================================================\n",
      "WEIGHTING SCHEME COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Scheme          DCF Weight   Peer Weight  Price        Upside      \n",
      "---------------------------------------------------------------\n",
      "dcf_dominant    70         % 30         % $320.84      -5.2%\n",
      "balanced        60         % 40         % $319.52      -5.6%\n",
      "equal           50         % 50         % $318.21      -6.0%\n",
      "market_aware    55         % 45         % $318.87      -5.8%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "✓ Results exported to GOOG_integrated_valuation.csv\n",
      "✓ Weighting comparison exported to GOOG_weighting_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_final_price(weighted_fair_value, predicted_price, current_price):\n",
    "    \"\"\"\n",
    "    Calculate final predicted price with adaptive weights based on model agreement\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate relative difference between two model predictions\n",
    "    price_diff = abs(weighted_fair_value - predicted_price)\n",
    "    relative_diff = price_diff / current_price if current_price > 0 else 0\n",
    "    \n",
    "    # Determine weights based on agreement level\n",
    "    if relative_diff < 0.05:  # Less than 5% difference - high agreement\n",
    "        w1, w2 = 0.5, 0.5  # Equal weights\n",
    "        weighting_method = \"Equal weights (high agreement between models)\"\n",
    "    \n",
    "    elif relative_diff < 0.15:  # 5-15% difference - moderate agreement\n",
    "        w1, w2 = 0.6, 0.4  # Slight preference for DCF\n",
    "        weighting_method = \"Slight DCF preference (moderate agreement)\"\n",
    "    \n",
    "    else:  # More than 15% difference - significant disagreement\n",
    "        # Check which model is closer to current market price\n",
    "        dcf_distance = abs(weighted_fair_value - current_price)\n",
    "        peer_distance = abs(predicted_price - current_price)\n",
    "        \n",
    "        if dcf_distance < peer_distance:\n",
    "            w1, w2 = 0.7, 0.3  # DCF closer to market price\n",
    "            weighting_method = \"Strong DCF preference (DCF closer to current market price)\"\n",
    "        else:\n",
    "            w1, w2 = 0.4, 0.6  # Peer analysis closer to market price\n",
    "            weighting_method = \"Strong peer preference (peer analysis closer to current market price)\"\n",
    "    \n",
    "    # Calculate final price\n",
    "    final_price = w1 * weighted_fair_value + w2 * predicted_price\n",
    "    \n",
    "    return {\n",
    "        'final_price': final_price,\n",
    "        'dcf_weight': w1,\n",
    "        'peer_weight': w2,\n",
    "        'weighting_method': weighting_method,\n",
    "        'relative_difference_pct': relative_diff * 100,\n",
    "        'dcf_value': weighted_fair_value,\n",
    "        'peer_value': predicted_price\n",
    "    }\n",
    "\n",
    "\n",
    "# Alternative: Fixed weighting approach\n",
    "def calculate_final_price_fixed(weighted_fair_value, predicted_price, weighting_scheme='balanced'):\n",
    "    \"\"\"\n",
    "    Calculate final price using fixed weighting schemes\n",
    "    \"\"\"\n",
    "    \n",
    "    weighting_schemes = {\n",
    "        'dcf_dominant': (0.7, 0.3),     # Strong preference for DCF\n",
    "        'balanced': (0.6, 0.4),         # Balanced with slight DCF preference\n",
    "        'equal': (0.5, 0.5),            # Equal weights\n",
    "        'market_aware': (0.55, 0.45),   # Slight market adjustment\n",
    "    }\n",
    "    \n",
    "    w1, w2 = weighting_schemes.get(weighting_scheme, (0.6, 0.4))\n",
    "    final_price = w1 * weighted_fair_value + w2 * predicted_price\n",
    "    \n",
    "    return {\n",
    "        'final_price': final_price,\n",
    "        'dcf_weight': w1,\n",
    "        'peer_weight': w2,\n",
    "        'weighting_scheme': weighting_scheme\n",
    "    }\n",
    "\n",
    "\n",
    "# Complete integration function\n",
    "def integrate_all_valuations(symbol, weighted_fair_value, predicted_price):\n",
    "    \"\"\"\n",
    "    Main function to integrate all valuation models\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FINAL INTEGRATED VALUATION FOR {symbol}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Get current price\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        info = ticker.info\n",
    "        current_price = info.get('currentPrice', info.get('regularMarketPrice'))\n",
    "    except:\n",
    "        current_price = (weighted_fair_value + predicted_price) / 2\n",
    "        print(f\"⚠️ Could not fetch current price, using average: ${current_price:.2f}\")\n",
    "    \n",
    "    # Display input values\n",
    "    print(\"MODEL INPUTS:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"DCF (Management-adjusted weighted average): ${weighted_fair_value:.2f}\")\n",
    "    print(f\"Peer Analysis (Comparative valuation):      ${predicted_price:.2f}\")\n",
    "    print(f\"Current Market Price:                       ${current_price:.2f}\")\n",
    "    \n",
    "    # Calculate using adaptive weighting\n",
    "    result = calculate_final_price(weighted_fair_value, predicted_price, current_price)\n",
    "    \n",
    "    print(f\"\\nADAPTIVE WEIGHTING RESULT:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Relative difference between models: {result['relative_difference_pct']:.1f}%\")\n",
    "    print(f\"Weighting method: {result['weighting_method']}\")\n",
    "    print(f\"DCF weight: {result['dcf_weight']*100:.0f}%\")\n",
    "    print(f\"Peer weight: {result['peer_weight']*100:.0f}%\")\n",
    "    print(f\"\\nFINAL PREDICTED PRICE: ${result['final_price']:.2f}\")\n",
    "    \n",
    "    # Calculate upside/downside\n",
    "    upside = ((result['final_price'] - current_price) / current_price) * 100 if current_price else 0\n",
    "    print(f\"Expected return: {upside:+.1f}%\")\n",
    "    \n",
    "    # Recommendation\n",
    "    if upside > 20:\n",
    "        recommendation = \"STRONG BUY\"\n",
    "    elif upside > 10:\n",
    "        recommendation = \"BUY\"\n",
    "    elif upside > -5:\n",
    "        recommendation = \"HOLD\"\n",
    "    elif upside > -15:\n",
    "        recommendation = \"REDUCE\"\n",
    "    else:\n",
    "        recommendation = \"SELL\"\n",
    "    \n",
    "    print(f\"Recommendation: {recommendation}\")\n",
    "    \n",
    "    # Compare different weighting schemes\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"WEIGHTING SCHEME COMPARISON\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    schemes = ['dcf_dominant', 'balanced', 'equal', 'market_aware']\n",
    "    comparison = []\n",
    "    \n",
    "    for scheme in schemes:\n",
    "        fixed_result = calculate_final_price_fixed(weighted_fair_value, predicted_price, scheme)\n",
    "        fixed_upside = ((fixed_result['final_price'] - current_price) / current_price) * 100 if current_price else 0\n",
    "        comparison.append({\n",
    "            'scheme': scheme,\n",
    "            'price': fixed_result['final_price'],\n",
    "            'upside': fixed_upside,\n",
    "            'dcf_weight': fixed_result['dcf_weight']*100,\n",
    "            'peer_weight': fixed_result['peer_weight']*100\n",
    "        })\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(f\"{'Scheme':<15} {'DCF Weight':<12} {'Peer Weight':<12} {'Price':<12} {'Upside':<12}\")\n",
    "    print(\"-\" * 63)\n",
    "    for comp in comparison:\n",
    "        print(f\"{comp['scheme']:<15} {comp['dcf_weight']:<11.0f}% {comp['peer_weight']:<11.0f}% \"\n",
    "              f\"${comp['price']:<11.2f} {comp['upside']:+.1f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Export results\n",
    "    export_results(symbol, result, comparison, current_price)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def export_results(symbol, adaptive_result, comparison_results, current_price):\n",
    "    \"\"\"\n",
    "    Export results to CSV\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_data = {\n",
    "        'Metric': [\n",
    "            'Current Price',\n",
    "            'DCF Fair Value',\n",
    "            'Peer Analysis Value', \n",
    "            'Adaptive Final Price',\n",
    "            'Expected Return (%)',\n",
    "            'Weighting Method',\n",
    "            'DCF Weight (%)',\n",
    "            'Peer Weight (%)',\n",
    "            'Analysis Date'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f\"${current_price:.2f}\",\n",
    "            f\"${adaptive_result['dcf_value']:.2f}\",\n",
    "            f\"${adaptive_result['peer_value']:.2f}\",\n",
    "            f\"${adaptive_result['final_price']:.2f}\",\n",
    "            f\"{((adaptive_result['final_price'] - current_price) / current_price * 100):+.1f}%\",\n",
    "            adaptive_result['weighting_method'],\n",
    "            f\"{adaptive_result['dcf_weight']*100:.1f}%\",\n",
    "            f\"{adaptive_result['peer_weight']*100:.1f}%\",\n",
    "            datetime.now().strftime('%Y-%m-%d')\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    # Export to CSV\n",
    "    summary_df.to_csv(f'{symbol}_integrated_valuation.csv', index=False)\n",
    "    comparison_df.to_csv(f'{symbol}_weighting_comparison.csv', index=False)\n",
    "    \n",
    "    print(f\"✓ Results exported to {symbol}_integrated_valuation.csv\")\n",
    "    print(f\"✓ Weighting comparison exported to {symbol}_weighting_comparison.csv\")\n",
    "\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"GOOG\"\n",
    "    \n",
    "    # These should come from your previous analyses\n",
    "    weighted_fair_value = 324.78  # From DCF with management quality adjustment\n",
    "    predicted_price = 311.64      # From peer analysis\n",
    "    \n",
    "    # Run integrated valuation\n",
    "    result = integrate_all_valuations(symbol, weighted_fair_value, predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4df1303b-1dfa-47a4-bf66-8c2963ae12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Generating investment recommendation...\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATION: HOLD\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FINAL INTEGRATED VALUATION FOR GOOG\n",
      "================================================================================\n",
      "\n",
      "MODEL INPUTS:\n",
      "------------------------------------------------------------\n",
      "DCF (Management-adjusted weighted average): $324.78\n",
      "Peer Analysis (Comparative valuation):      $311.64\n",
      "Current Market Price:                       $338.53\n",
      "\n",
      "ADAPTIVE WEIGHTING RESULT:\n",
      "------------------------------------------------------------\n",
      "Relative difference between models: 3.9%\n",
      "Weighting method: Equal weights (high agreement between models)\n",
      "DCF weight: 50%\n",
      "Peer weight: 50%\n",
      "\n",
      "FINAL PREDICTED PRICE: $318.21\n",
      "Expected return: -6.0%\n",
      "Recommendation: REDUCE\n",
      "\n",
      "================================================================================\n",
      "WEIGHTING SCHEME COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Scheme          DCF Weight   Peer Weight  Price        Upside      \n",
      "---------------------------------------------------------------\n",
      "dcf_dominant    70         % 30         % $320.84      -5.2%\n",
      "balanced        60         % 40         % $319.52      -5.6%\n",
      "equal           50         % 50         % $318.21      -6.0%\n",
      "market_aware    55         % 45         % $318.87      -5.8%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "✓ Results exported to GOOG_integrated_valuation.csv\n",
      "✓ Weighting comparison exported to GOOG_weighting_comparison.csv\n",
      "Target Price: $318.21\n",
      "Expected Return: -1.3%\n",
      "Confidence: Medium\n",
      "\n",
      "VALUATION COMPONENTS:\n",
      "------------------------------------------------------------\n",
      "• DCF Weighted Fair Value: $324.78\n",
      "• Peer Analysis Price: $311.64\n",
      "• Integrated Final Price: $318.21\n",
      "\n",
      "Key Reasoning:\n",
      "   - Price target implies -1.3% upside/downside\n",
      "   - Overall market sentiment is neutral\n",
      "\n",
      "Step 5: Generating professional investment memo with Gemini...\n",
      "   Investment memo saved: GOOG_investment_memo_20260201_092156.md\n",
      "   Detailed results saved: GOOG_analysis_results_20260201_092156.json\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'symbol': 'GOOG',\n",
       " 'company_name': 'Alphabet Inc.',\n",
       " 'analysis_date': '2026-02-01T09:21:56.747961',\n",
       " 'current_price': 338.53,\n",
       " 'target_price': 318.21,\n",
       " 'recommendation': {'recommendation': 'HOLD',\n",
       "  'confidence': 'Medium',\n",
       "  'target_price': 334.26312435999995,\n",
       "  'current_price': 338.53,\n",
       "  'expected_return': -1.2604128555814915,\n",
       "  'reasoning': ['Price target implies -1.3% upside/downside',\n",
       "   'Overall market sentiment is neutral'],\n",
       "  'positive_catalysts': 0,\n",
       "  'negative_catalysts': 0,\n",
       "  'sentiment': 'neutral'},\n",
       " 'catalysts': {'catalysts': [], 'overall_sentiment': 'neutral'},\n",
       " 'price_breakdown': {'base_price': 334.26312435999995,\n",
       "  'catalyst_adjustment_pct': 0},\n",
       " 'news_count': 0,\n",
       " 'valuation_components': {'dcf_value': 324.78,\n",
       "  'peer_value': 311.64,\n",
       "  'final_integrated_value': 318.21}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 0: Set Gemini API Key\n",
    "# ===============================\n",
    "GEMINI_API_KEY = \"*\"\n",
    "\n",
    "# ===============================\n",
    "# Step 4: Generate Investment Recommendation\n",
    "# ===============================\n",
    "print(\"Step 4: Generating investment recommendation...\")\n",
    "recommendation = generate_investment_recommendation(\n",
    "    current_price,\n",
    "    adjusted_price,  # Keep original logic\n",
    "    catalyst_data.get('catalysts', []),\n",
    "    catalyst_data.get('overall_sentiment', 'neutral')\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"RECOMMENDATION: {recommendation['recommendation']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ===============================\n",
    "# Step 4.5: Run Integrated Valuation to get final target price\n",
    "# ===============================\n",
    "adaptive_result = integrate_all_valuations(symbol, weighted_fair_value, predicted_price)\n",
    "final_target_price = adaptive_result['final_price']  # ← Use this as the real target price\n",
    "\n",
    "print(f\"Target Price: ${final_target_price:.2f}\")\n",
    "print(f\"Expected Return: {recommendation['expected_return']:+.1f}%\")\n",
    "print(f\"Confidence: {recommendation['confidence']}\")\n",
    "\n",
    "# Simple valuation breakdown\n",
    "print(\"\\nVALUATION COMPONENTS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"• DCF Weighted Fair Value: ${weighted_fair_value:.2f}\")\n",
    "print(f\"• Peer Analysis Price: ${predicted_price:.2f}\")\n",
    "print(f\"• Integrated Final Price: ${final_target_price:.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"Key Reasoning:\")\n",
    "for reason in recommendation['reasoning']:\n",
    "    print(f\"   - {reason}\")\n",
    "print()\n",
    "\n",
    "# ===============================\n",
    "# Step 5: Display Catalysts\n",
    "# ===============================\n",
    "if catalyst_data.get('catalysts'):\n",
    "    print(\"=\"*80)\n",
    "    print(\"KEY CATALYSTS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for i, catalyst in enumerate(catalyst_data.get('catalysts', []), 1):\n",
    "        prefix = \"[+]\" if catalyst['type'] == \"POSITIVE\" else \"[-]\" if catalyst['type'] == \"NEGATIVE\" else \"[~]\"\n",
    "        print(f\"{i}. {prefix} {catalyst['description']}\")\n",
    "        print(f\"   Type: {catalyst['type']} | Category: {catalyst['category']}\")\n",
    "        print(f\"   Impact: {catalyst['impact_score']:+.1f}/10 | {catalyst['timeframe']} | {catalyst['confidence']} confidence\\n\")\n",
    "\n",
    "# Display risks and opportunities\n",
    "if catalyst_data.get('key_risks'):\n",
    "    print(\"KEY RISKS:\")\n",
    "    for risk in catalyst_data['key_risks']:\n",
    "        print(f\"   - {risk}\")\n",
    "    print()\n",
    "\n",
    "if catalyst_data.get('key_opportunities'):\n",
    "    print(\"KEY OPPORTUNITIES:\")\n",
    "    for opp in catalyst_data['key_opportunities']:\n",
    "        print(f\"   - {opp}\")\n",
    "    print()\n",
    "\n",
    "# ===============================\n",
    "# Step 6: Generate Detailed Investment Memo using Gemini\n",
    "# ===============================\n",
    "print(\"Step 5: Generating professional investment memo with Gemini...\")\n",
    "\n",
    "def generate_detailed_investment_memo_with_gemini(symbol, recommendation, catalyst_data, company_info, api_key, \n",
    "                                                  weighted_fair_value, predicted_price, final_price):\n",
    "    \"\"\"\n",
    "    Generate a detailed investment memo (250-350 words)\n",
    "    \"\"\"\n",
    "    detailed_context = f\"\"\"Generate a professional investment memo for {symbol} ({company_info.get('longName', symbol)}).\n",
    "\n",
    "COMPANY OVERVIEW:\n",
    "- Sector: {company_info.get('sector', 'N/A')}\n",
    "- Industry: {company_info.get('industry', 'N/A')}\n",
    "- Market Cap: ${company_info.get('marketCap', 0) / 1e9:.1f}B\n",
    "- P/E Ratio: {company_info.get('trailingPE', 'N/A')}\n",
    "\n",
    "VALUATION METHODOLOGY:\n",
    "1. DCF Model (Intrinsic Value): ${weighted_fair_value:.2f}\n",
    "2. Peer Comparison (Relative Value): ${predicted_price:.2f}\n",
    "3. Integrated Result: ${final_price:.2f}\n",
    "\n",
    "RECOMMENDATION:\n",
    "- Action: {recommendation['recommendation']}\n",
    "- Target Price: ${final_price:.2f}  # ← use real final predicted price\n",
    "- Current Price: ${recommendation['current_price']:.2f}\n",
    "- Expected Return: {recommendation['expected_return']:.1f}%\n",
    "- Confidence: {recommendation['confidence']}\n",
    "\n",
    "CATALYSTS ({len(catalyst_data.get('catalysts', []))} identified):\n",
    "- Overall Sentiment: {catalyst_data.get('overall_sentiment', 'neutral').upper()}\n",
    "- Positive: {sum(1 for c in catalyst_data.get('catalysts', []) if c.get('type') == 'POSITIVE')}\n",
    "- Negative: {sum(1 for c in catalyst_data.get('catalysts', []) if c.get('type') == 'NEGATIVE')}\n",
    "\n",
    "Write a professional investment memo with sections:\n",
    "1. EXECUTIVE SUMMARY\n",
    "2. INVESTMENT THESIS\n",
    "3. VALUATION ANALYSIS\n",
    "4. CATALYSTS & RISKS\n",
    "5. FINANCIAL HEALTH\n",
    "6. RECOMMENDATION & ACTION PLAN\n",
    "\n",
    "Requirements:\n",
    "- Length: 250-350 words\n",
    "- Professional tone\n",
    "- Include numbers and valuation methodology\"\"\"\n",
    "\n",
    "    try:\n",
    "        import google.generativeai as genai\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        # Use a valid Gemini model\n",
    "        model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "\n",
    "        response = model.generate_content(\n",
    "            detailed_context,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_output_tokens\": 1500,\n",
    "                \"top_p\": 0.9\n",
    "            }\n",
    "        )\n",
    "        return response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating memo: {str(e)}\")\n",
    "        return f\"# Investment Memo for {symbol}\\n\\nError: {str(e)}\"\n",
    "\n",
    "# Call the function\n",
    "memo = generate_detailed_investment_memo_with_gemini(\n",
    "    symbol,\n",
    "    recommendation,\n",
    "    catalyst_data,\n",
    "    company_info,\n",
    "    GEMINI_API_KEY,\n",
    "    weighted_fair_value,\n",
    "    predicted_price,\n",
    "    final_target_price  # ← use real final predicted price here\n",
    ")\n",
    "\n",
    "# Save output\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "memo_filename = f\"{symbol}_investment_memo_{timestamp}.md\"\n",
    "with open(memo_filename, 'w') as f:\n",
    "    f.write(memo)\n",
    "print(f\"   Investment memo saved: {memo_filename}\")\n",
    "\n",
    "results = {\n",
    "    'symbol': symbol,\n",
    "    'company_name': company_info.get('longName', symbol),\n",
    "    'analysis_date': datetime.now().isoformat(),\n",
    "    'current_price': current_price,\n",
    "    'target_price': final_target_price,  # ← updated\n",
    "    'recommendation': recommendation,\n",
    "    'catalysts': catalyst_data,\n",
    "    'price_breakdown': price_breakdown,\n",
    "    'news_count': len(news_items),\n",
    "    'valuation_components': {\n",
    "        'dcf_value': weighted_fair_value,\n",
    "        'peer_value': predicted_price,\n",
    "        'final_integrated_value': final_target_price\n",
    "    }\n",
    "}\n",
    "\n",
    "results_filename = f\"{symbol}_analysis_results_{timestamp}.json\"\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "print(f\"   Detailed results saved: {results_filename}\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Return results dictionary\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68ebd0fd-0efd-4f4c-ab2f-6135cd894b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab34239-f6e2-46a0-9562-ca6b8d3c85cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
